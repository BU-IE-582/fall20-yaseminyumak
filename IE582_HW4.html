<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>IE582_HW4</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos pre { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
span.linenos { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
td.linenos pre.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE0LjkgMTcuNDVDMTYuMjUgMTcuNDUgMTcuMzUgMTYuMzUgMTcuMzUgMTVDMTcuMzUgMTMuNjUgMTYuMjUgMTIuNTUgMTQuOSAxMi41NUMxMy41NCAxMi41NSAxMi40NSAxMy42NSAxMi40NSAxNUMxMi40NSAxNi4zNSAxMy41NCAxNy40NSAxNC45IDE3LjQ1Wk0yMC4xIDE1LjY4TDIxLjU4IDE2Ljg0QzIxLjcxIDE2Ljk1IDIxLjc1IDE3LjEzIDIxLjY2IDE3LjI5TDIwLjI2IDE5LjcxQzIwLjE3IDE5Ljg2IDIwIDE5LjkyIDE5LjgzIDE5Ljg2TDE4LjA5IDE5LjE2QzE3LjczIDE5LjQ0IDE3LjMzIDE5LjY3IDE2LjkxIDE5Ljg1TDE2LjY0IDIxLjdDMTYuNjIgMjEuODcgMTYuNDcgMjIgMTYuMyAyMkgxMy41QzEzLjMyIDIyIDEzLjE4IDIxLjg3IDEzLjE1IDIxLjdMMTIuODkgMTkuODVDMTIuNDYgMTkuNjcgMTIuMDcgMTkuNDQgMTEuNzEgMTkuMTZMOS45NjAwMiAxOS44NkM5LjgxMDAyIDE5LjkyIDkuNjIwMDIgMTkuODYgOS41NDAwMiAxOS43MUw4LjE0MDAyIDE3LjI5QzguMDUwMDIgMTcuMTMgOC4wOTAwMiAxNi45NSA4LjIyMDAyIDE2Ljg0TDkuNzAwMDIgMTUuNjhMOS42NTAwMSAxNUw5LjcwMDAyIDE0LjMxTDguMjIwMDIgMTMuMTZDOC4wOTAwMiAxMy4wNSA4LjA1MDAyIDEyLjg2IDguMTQwMDIgMTIuNzFMOS41NDAwMiAxMC4yOUM5LjYyMDAyIDEwLjEzIDkuODEwMDIgMTAuMDcgOS45NjAwMiAxMC4xM0wxMS43MSAxMC44NEMxMi4wNyAxMC41NiAxMi40NiAxMC4zMiAxMi44OSAxMC4xNUwxMy4xNSA4LjI4OTk4QzEzLjE4IDguMTI5OTggMTMuMzIgNy45OTk5OCAxMy41IDcuOTk5OThIMTYuM0MxNi40NyA3Ljk5OTk4IDE2LjYyIDguMTI5OTggMTYuNjQgOC4yODk5OEwxNi45MSAxMC4xNUMxNy4zMyAxMC4zMiAxNy43MyAxMC41NiAxOC4wOSAxMC44NEwxOS44MyAxMC4xM0MyMCAxMC4wNyAyMC4xNyAxMC4xMyAyMC4yNiAxMC4yOUwyMS42NiAxMi43MUMyMS43NSAxMi44NiAyMS43MSAxMy4wNSAyMS41OCAxMy4xNkwyMC4xIDE0LjMxTDIwLjE1IDE1TDIwLjEgMTUuNjhaIi8+CiAgICA8cGF0aCBkPSJNNy4zMjk2NiA3LjQ0NDU0QzguMDgzMSA3LjAwOTU0IDguMzM5MzIgNi4wNTMzMiA3LjkwNDMyIDUuMjk5ODhDNy40NjkzMiA0LjU0NjQzIDYuNTA4MSA0LjI4MTU2IDUuNzU0NjYgNC43MTY1NkM1LjM5MTc2IDQuOTI2MDggNS4xMjY5NSA1LjI3MTE4IDUuMDE4NDkgNS42NzU5NEM0LjkxMDA0IDYuMDgwNzEgNC45NjY4MiA2LjUxMTk4IDUuMTc2MzQgNi44NzQ4OEM1LjYxMTM0IDcuNjI4MzIgNi41NzYyMiA3Ljg3OTU0IDcuMzI5NjYgNy40NDQ1NFpNOS42NTcxOCA0Ljc5NTkzTDEwLjg2NzIgNC45NTE3OUMxMC45NjI4IDQuOTc3NDEgMTEuMDQwMiA1LjA3MTMzIDExLjAzODIgNS4xODc5M0wxMS4wMzg4IDYuOTg4OTNDMTEuMDQ1NSA3LjEwMDU0IDEwLjk2MTYgNy4xOTUxOCAxMC44NTUgNy4yMTA1NEw5LjY2MDAxIDcuMzgwODNMOS4yMzkxNSA4LjEzMTg4TDkuNjY5NjEgOS4yNTc0NUM5LjcwNzI5IDkuMzYyNzEgOS42NjkzNCA5LjQ3Njk5IDkuNTc0MDggOS41MzE5OUw4LjAxNTIzIDEwLjQzMkM3LjkxMTMxIDEwLjQ5MiA3Ljc5MzM3IDEwLjQ2NzcgNy43MjEwNSAxMC4zODI0TDYuOTg3NDggOS40MzE4OEw2LjEwOTMxIDkuNDMwODNMNS4zNDcwNCAxMC4zOTA1QzUuMjg5MDkgMTAuNDcwMiA1LjE3MzgzIDEwLjQ5MDUgNS4wNzE4NyAxMC40MzM5TDMuNTEyNDUgOS41MzI5M0MzLjQxMDQ5IDkuNDc2MzMgMy4zNzY0NyA5LjM1NzQxIDMuNDEwNzUgOS4yNTY3OUwzLjg2MzQ3IDguMTQwOTNMMy42MTc0OSA3Ljc3NDg4TDMuNDIzNDcgNy4zNzg4M0wyLjIzMDc1IDcuMjEyOTdDMi4xMjY0NyA3LjE5MjM1IDIuMDQwNDkgNy4xMDM0MiAyLjA0MjQ1IDYuOTg2ODJMMi4wNDE4NyA1LjE4NTgyQzIuMDQzODMgNS4wNjkyMiAyLjExOTA5IDQuOTc5NTggMi4yMTcwNCA0Ljk2OTIyTDMuNDIwNjUgNC43OTM5M0wzLjg2NzQ5IDQuMDI3ODhMMy40MTEwNSAyLjkxNzMxQzMuMzczMzcgMi44MTIwNCAzLjQxMTMxIDIuNjk3NzYgMy41MTUyMyAyLjYzNzc2TDUuMDc0MDggMS43Mzc3NkM1LjE2OTM0IDEuNjgyNzYgNS4yODcyOSAxLjcwNzA0IDUuMzU5NjEgMS43OTIzMUw2LjExOTE1IDIuNzI3ODhMNi45ODAwMSAyLjczODkzTDcuNzI0OTYgMS43ODkyMkM3Ljc5MTU2IDEuNzA0NTggNy45MTU0OCAxLjY3OTIyIDguMDA4NzkgMS43NDA4Mkw5LjU2ODIxIDIuNjQxODJDOS42NzAxNyAyLjY5ODQyIDkuNzEyODUgMi44MTIzNCA5LjY4NzIzIDIuOTA3OTdMOS4yMTcxOCA0LjAzMzgzTDkuNDYzMTYgNC4zOTk4OEw5LjY1NzE4IDQuNzk1OTNaIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">

<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="IE-582-HW4">IE 582 HW4<a class="anchor-link" href="#IE-582-HW4">&#182;</a></h1>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="I.-Data-Selection">I. Data Selection<a class="anchor-link" href="#I.-Data-Selection">&#182;</a></h2>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>1) Absenteeism at Work Data Set</p>
<ul>
<li>Target is to find the absenteeism time in hours </li>
<li>Associated Tasks: Classification, Clustering</li>
<li>Number of attributes: 21 </li>
<li>Attribute Characteristics: Integer, Real </li>
<li>Number of instances: 740</li>
</ul>
<p><a href="https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work">https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work</a></p>
<p>2) Online News Popularity Data Set</p>
<ul>
<li>Target is to find the number of shares</li>
<li>Associated Tasks: Classification, Regression</li>
<li>Number of attributes: 61 </li>
<li>Attribute Characteristics: Integer, Real </li>
<li>Number of instances: 39797</li>
</ul>
<p><a href="https://archive.ics.uci.edu/ml/datasets/online+news+popularity">https://archive.ics.uci.edu/ml/datasets/online+news+popularity</a></p>
<p>3) Drug Consumption (quantified) Data Set</p>
<ul>
<li>Target is to predict the time drug consumed </li>
<li>Associated Tasks: Classification</li>
<li>Number of attributes: 32 </li>
<li>Attribute Characteristics: Real </li>
<li>Number of instances: 143153</li>
</ul>
<p><a href="http://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29">http://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29</a></p>
<p>4) Sports articles for objectivity analysis Data Set</p>
<ul>
<li>Target is to find whether a article is objective or not</li>
<li>Associated Tasks: Classification</li>
<li>Number of attributes: 59</li>
<li>Attribute Characteristics: Integer</li>
<li>Number of instances: 1000</li>
</ul>
<p><a href="http://archive.ics.uci.edu/ml/datasets/Sports+articles+for+objectivity+analysis">http://archive.ics.uci.edu/ml/datasets/Sports+articles+for+objectivity+analysis</a></p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Data-Set-1:--Absenteeism-at-Work-Data-Set">Data Set 1:  Absenteeism at Work Data Set<a class="anchor-link" href="#Data-Set-1:--Absenteeism-at-Work-Data-Set">&#182;</a></h3>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<ol>
<li>Individual identification (ID)</li>
<li>Reason for absence (ICD)</li>
<li>Month of absence</li>
<li>Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))</li>
<li>Seasons (summer (1), autumn (2), winter (3), spring (4))</li>
<li>Transportation expense</li>
<li>Distance from Residence to Work (kilometers)</li>
<li>Service time</li>
<li>Age</li>
<li>Work load Average/day</li>
<li>Hit target</li>
<li>Disciplinary failure (yes=1; no=0)</li>
<li>Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))</li>
<li>Son (number of children)</li>
<li>Social drinker (yes=1; no=0)</li>
<li>Social smoker (yes=1; no=0)</li>
<li>Pet (number of pet)</li>
<li>Weight</li>
<li>Height</li>
<li>Body mass index</li>
<li>Absenteeism time in hours (target)</li>
</ol>
<p>Attributes 2,3,4,5,12,13,15,16 are categorical</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[216]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">setwd</span><span class="p">(</span><span class="s">&quot;C:/Users/lenovo/Desktop/IE582/HW4&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="s">&quot;readxl&quot;</span><span class="p">)</span>
<span class="n">data1</span><span class="o">=</span><span class="nf">read_excel</span><span class="p">(</span><span class="s">&quot;DataSet1/Absenteeism.xls&quot;</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">data1</span><span class="o">$</span><span class="n">ID</span> <span class="o">&lt;-</span> <span class="kc">NULL</span>
<span class="nf">names</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">gsub</span><span class="p">(</span><span class="s">&quot; &quot;</span><span class="p">,</span> <span class="s">&quot;.&quot;</span><span class="p">,</span> <span class="nf">names</span><span class="p">(</span><span class="n">data1</span><span class="p">))</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">data1</span><span class="p">)[</span><span class="nf">colnames</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span> <span class="o">==</span> <span class="s">&quot;Absenteeism.time.in.hours&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="s">&quot;AbsenteeismTimeInHours&quot;</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">data1</span><span class="p">)[</span><span class="nf">colnames</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span> <span class="o">==</span> <span class="s">&quot;Work.load.Average/day&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="s">&quot;Workload&quot;</span>

<span class="nf">head</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>Reason.for.absence</th><th scope=col>Month.of.absence</th><th scope=col>Day.of.the.week</th><th scope=col>Seasons</th><th scope=col>Transportation.expense</th><th scope=col>Distance.from.Residence.to.Work</th><th scope=col>Service.time</th><th scope=col>Age</th><th scope=col>Workload</th><th scope=col>Hit.target</th><th scope=col>Disciplinary.failure</th><th scope=col>Education</th><th scope=col>Son</th><th scope=col>Social.drinker</th><th scope=col>Social.smoker</th><th scope=col>Pet</th><th scope=col>Weight</th><th scope=col>Height</th><th scope=col>Body.mass.index</th><th scope=col>AbsenteeismTimeInHours</th></tr></thead>
<tbody>
	<tr><td>26    </td><td>7     </td><td>3     </td><td>1     </td><td>289   </td><td>36    </td><td>13    </td><td>33    </td><td>239554</td><td>97    </td><td>0     </td><td>1     </td><td>2     </td><td>1     </td><td>0     </td><td>1     </td><td>90    </td><td>172   </td><td>30    </td><td>4     </td></tr>
	<tr><td> 0    </td><td>7     </td><td>3     </td><td>1     </td><td>118   </td><td>13    </td><td>18    </td><td>50    </td><td>239554</td><td>97    </td><td>1     </td><td>1     </td><td>1     </td><td>1     </td><td>0     </td><td>0     </td><td>98    </td><td>178   </td><td>31    </td><td>0     </td></tr>
	<tr><td>23    </td><td>7     </td><td>4     </td><td>1     </td><td>179   </td><td>51    </td><td>18    </td><td>38    </td><td>239554</td><td>97    </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>89    </td><td>170   </td><td>31    </td><td>2     </td></tr>
	<tr><td> 7    </td><td>7     </td><td>5     </td><td>1     </td><td>279   </td><td> 5    </td><td>14    </td><td>39    </td><td>239554</td><td>97    </td><td>0     </td><td>1     </td><td>2     </td><td>1     </td><td>1     </td><td>0     </td><td>68    </td><td>168   </td><td>24    </td><td>4     </td></tr>
	<tr><td>23    </td><td>7     </td><td>5     </td><td>1     </td><td>289   </td><td>36    </td><td>13    </td><td>33    </td><td>239554</td><td>97    </td><td>0     </td><td>1     </td><td>2     </td><td>1     </td><td>0     </td><td>1     </td><td>90    </td><td>172   </td><td>30    </td><td>2     </td></tr>
	<tr><td>23    </td><td>7     </td><td>6     </td><td>1     </td><td>179   </td><td>51    </td><td>18    </td><td>38    </td><td>239554</td><td>97    </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>89    </td><td>170   </td><td>31    </td><td>2     </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[281]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">str</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:	740 obs. of  20 variables:
 $ Reason.for.absence             : Factor w/ 28 levels &#34;0&#34;,&#34;1&#34;,&#34;2&#34;,&#34;3&#34;,..: 26 1 23 8 23 23 22 23 20 22 ...
 $ Month.of.absence               : Factor w/ 13 levels &#34;0&#34;,&#34;1&#34;,&#34;2&#34;,&#34;3&#34;,..: 8 8 8 8 8 8 8 8 8 8 ...
 $ Day.of.the.week                : Factor w/ 5 levels &#34;2&#34;,&#34;3&#34;,&#34;4&#34;,&#34;5&#34;,..: 2 2 3 4 4 5 5 5 1 1 ...
 $ Seasons                        : Factor w/ 4 levels &#34;1&#34;,&#34;2&#34;,&#34;3&#34;,&#34;4&#34;: 1 1 1 1 1 1 1 1 1 1 ...
 $ Transportation.expense         : num  289 118 179 279 289 179 361 260 155 235 ...
 $ Distance.from.Residence.to.Work: num  36 13 51 5 36 51 52 50 12 11 ...
 $ Service.time                   : num  13 18 18 14 13 18 3 11 14 14 ...
 $ Age                            : num  33 50 38 39 33 38 28 36 34 37 ...
 $ Workload                       : num  239554 239554 239554 239554 239554 ...
 $ Hit.target                     : num  97 97 97 97 97 97 97 97 97 97 ...
 $ Disciplinary.failure           : Factor w/ 2 levels &#34;0&#34;,&#34;1&#34;: 1 2 1 1 1 1 1 1 1 1 ...
 $ Education                      : Factor w/ 4 levels &#34;1&#34;,&#34;2&#34;,&#34;3&#34;,&#34;4&#34;: 1 1 1 1 1 1 1 1 1 3 ...
 $ Son                            : num  2 1 0 2 2 0 1 4 2 1 ...
 $ Social.drinker                 : Factor w/ 2 levels &#34;0&#34;,&#34;1&#34;: 2 2 2 2 2 2 2 2 2 1 ...
 $ Social.smoker                  : Factor w/ 2 levels &#34;0&#34;,&#34;1&#34;: 1 1 1 2 1 1 1 1 1 1 ...
 $ Pet                            : num  1 0 0 0 1 0 4 0 0 1 ...
 $ Weight                         : num  90 98 89 68 90 89 80 65 95 88 ...
 $ Height                         : num  172 178 170 168 172 170 172 168 196 172 ...
 $ Body.mass.index                : num  30 31 31 24 30 31 27 23 25 29 ...
 $ AbsenteeismTimeInHours         : num  4 0 2 4 2 2 8 4 40 8 ...
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[282]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">names</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">11</span><span class="p">,</span><span class="m">12</span><span class="p">,</span><span class="m">14</span><span class="p">,</span><span class="m">15</span><span class="p">)</span>
<span class="n">data1</span><span class="p">[,</span><span class="n">names</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="nf">lapply</span><span class="p">(</span><span class="n">data1</span><span class="p">[,</span><span class="n">names</span><span class="p">]</span> <span class="p">,</span> <span class="n">factor</span><span class="p">)</span>
<span class="nf">str</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:	740 obs. of  20 variables:
 $ Reason.for.absence             : Factor w/ 28 levels &#34;0&#34;,&#34;1&#34;,&#34;2&#34;,&#34;3&#34;,..: 26 1 23 8 23 23 22 23 20 22 ...
 $ Month.of.absence               : Factor w/ 13 levels &#34;0&#34;,&#34;1&#34;,&#34;2&#34;,&#34;3&#34;,..: 8 8 8 8 8 8 8 8 8 8 ...
 $ Day.of.the.week                : Factor w/ 5 levels &#34;2&#34;,&#34;3&#34;,&#34;4&#34;,&#34;5&#34;,..: 2 2 3 4 4 5 5 5 1 1 ...
 $ Seasons                        : Factor w/ 4 levels &#34;1&#34;,&#34;2&#34;,&#34;3&#34;,&#34;4&#34;: 1 1 1 1 1 1 1 1 1 1 ...
 $ Transportation.expense         : num  289 118 179 279 289 179 361 260 155 235 ...
 $ Distance.from.Residence.to.Work: num  36 13 51 5 36 51 52 50 12 11 ...
 $ Service.time                   : num  13 18 18 14 13 18 3 11 14 14 ...
 $ Age                            : num  33 50 38 39 33 38 28 36 34 37 ...
 $ Workload                       : num  239554 239554 239554 239554 239554 ...
 $ Hit.target                     : num  97 97 97 97 97 97 97 97 97 97 ...
 $ Disciplinary.failure           : Factor w/ 2 levels &#34;0&#34;,&#34;1&#34;: 1 2 1 1 1 1 1 1 1 1 ...
 $ Education                      : Factor w/ 4 levels &#34;1&#34;,&#34;2&#34;,&#34;3&#34;,&#34;4&#34;: 1 1 1 1 1 1 1 1 1 3 ...
 $ Son                            : num  2 1 0 2 2 0 1 4 2 1 ...
 $ Social.drinker                 : Factor w/ 2 levels &#34;0&#34;,&#34;1&#34;: 2 2 2 2 2 2 2 2 2 1 ...
 $ Social.smoker                  : Factor w/ 2 levels &#34;0&#34;,&#34;1&#34;: 1 1 1 2 1 1 1 1 1 1 ...
 $ Pet                            : num  1 0 0 0 1 0 4 0 0 1 ...
 $ Weight                         : num  90 98 89 68 90 89 80 65 95 88 ...
 $ Height                         : num  172 178 170 168 172 170 172 168 196 172 ...
 $ Body.mass.index                : num  30 31 31 24 30 31 27 23 25 29 ...
 $ AbsenteeismTimeInHours         : num  4 0 2 4 2 2 8 4 40 8 ...
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[283]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">any</span><span class="p">(</span><span class="nf">is.na</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span><span class="o">==</span><span class="kc">TRUE</span><span class="p">)</span> <span class="c1">##controlling if there is any missing value</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
FALSE
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[284]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">colnames</span><span class="p">(</span><span class="n">data1</span><span class="p">)[</span><span class="nf">colnames</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span> <span class="o">==</span> <span class="s">&quot;Absenteeism time in hours&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="s">&quot;AbsenteeismTimeInHours&quot;</span>
<span class="nf">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[285]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">sample</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data1</span><span class="p">),</span> <span class="n">size</span> <span class="o">=</span> <span class="nf">floor</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span><span class="o">*</span><span class="m">0.77</span><span class="p">),</span> <span class="n">replace</span> <span class="o">=</span> <span class="bp">F</span><span class="p">)</span>
<span class="n">train1</span> <span class="o">&lt;-</span> <span class="n">data1</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
<span class="n">test1</span>  <span class="o">&lt;-</span> <span class="n">data1</span><span class="p">[</span><span class="o">-</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[286]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">folds1</span> <span class="o">&lt;-</span> <span class="nf">createMultiFolds</span><span class="p">(</span><span class="n">train1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="n">times</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
<span class="n">control1</span><span class="o">&lt;-</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">verboseIter</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">folds2</span><span class="p">,</span><span class="n">allowParallel</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[287]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">lasso_grid1</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">lambda</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">400</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">3</span><span class="p">)))</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">reg1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">AbsenteeismTimeInHours</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;glmnet&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">lasso_grid1</span><span class="p">,</span> 
                 <span class="n">trControl</span><span class="o">=</span> <span class="n">control1</span><span class="p">,</span> <span class="n">preProcess</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span><span class="s">&quot;scale&quot;</span><span class="p">))</span>

<span class="n">lasso_pred1</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">reg1</span><span class="p">,</span><span class="n">test1</span><span class="p">)</span>

<span class="n">lasso_error1</span> <span class="o">&lt;-</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span> <span class="n">lasso_pred1</span><span class="p">)</span>
<span class="n">lasso_error1</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold01.Rep1: alpha=1, lambda=400 
+ Fold02.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold02.Rep1: alpha=1, lambda=400 
+ Fold03.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold03.Rep1: alpha=1, lambda=400 
+ Fold04.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold04.Rep1: alpha=1, lambda=400 
+ Fold05.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold05.Rep1: alpha=1, lambda=400 
+ Fold06.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3, Reason.for.absence17&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold06.Rep1: alpha=1, lambda=400 
+ Fold07.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold07.Rep1: alpha=1, lambda=400 
+ Fold08.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold08.Rep1: alpha=1, lambda=400 
+ Fold09.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold09.Rep1: alpha=1, lambda=400 
+ Fold10.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>- Fold10.Rep1: alpha=1, lambda=400 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
&#34;There were missing values in resampled performance measures.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Aggregating results
Selecting tuning parameters
Fitting alpha = 1, lambda = 1 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :
&#34;These variables have zero variances: Reason.for.absence2, Reason.for.absence3&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
18.473738572537
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">rpart</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;rpart.plot&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">rpart.plot</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>package &#39;rpart.plot&#39; successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\lenovo\AppData\Local\Temp\RtmpmY4E4B\downloaded_packages
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message:
&#34;package &#39;rpart.plot&#39; was built under R version 3.6.3&#34;</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[288]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt_grid1</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.005</span><span class="p">,</span><span class="m">0.01</span><span class="p">))</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">dt1.1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">AbsenteeismTimeInHours</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train1</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid1</span><span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control2</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">)))</span>
<span class="n">dt_pred1.1</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt1.1</span><span class="p">,</span><span class="n">test1</span><span class="p">)</span>
<span class="n">dt_error1.1</span> <span class="o">=</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span><span class="n">dt_pred1.1</span><span class="p">)</span>
<span class="n">dt_error1.1</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.001 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
19.3638824046817
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[233]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt1.2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">AbsenteeismTimeInHours</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train1</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid1</span><span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control2</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">)))</span>

<span class="n">dt_pred1.2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt1.2</span><span class="p">,</span><span class="n">test1</span><span class="p">)</span>
<span class="n">dt_error1.2</span> <span class="o">=</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span><span class="n">dt_pred1.2</span><span class="p">)</span>
<span class="n">dt_error1.1</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.001 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
11.5216340636867
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[234]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt1.3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">AbsenteeismTimeInHours</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train1</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid1</span><span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control2</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">8</span><span class="p">)))</span>
<span class="n">dt_pred1.3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt1.3</span><span class="p">,</span><span class="n">test1</span><span class="p">)</span>

<span class="n">dt_error1.3</span><span class="o">=</span><span class="nf">RMSE</span><span class="p">(</span><span class="n">test1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span><span class="n">dt_pred1.3</span><span class="p">)</span>
<span class="n">dt_error1.3</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.001 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
10.402010381273
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[235]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;cowplot&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">cowplot</span><span class="p">)</span>
<span class="nf">require</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message:
&#34;package &#39;cowplot&#39; is in use and will not be installed&#34;</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[236]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">forest_grid1</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">6</span><span class="p">)</span> <span class="p">,</span><span class="n">min.node.size</span><span class="o">=</span><span class="m">5</span><span class="p">,</span> <span class="n">splitrule</span> <span class="o">=</span> <span class="s">&quot;variance&quot;</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">rf1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">AbsenteeismTimeInHours</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;ranger&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">forest_grid1</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span> <span class="n">control1</span><span class="p">)</span>
<span class="n">rf_pred1</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">rf1</span><span class="p">,</span><span class="n">test1</span><span class="p">)</span>
<span class="n">rf_error1</span> <span class="o">=</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span><span class="n">rf_pred1</span><span class="p">)</span>
<span class="n">rf_error1</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold01.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold01.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold01.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold01.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold01.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold02.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold02.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold02.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold02.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold02.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold02.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold03.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold03.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold03.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold03.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold03.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold03.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold04.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold04.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold04.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold04.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold04.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold04.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold05.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold05.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold05.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold05.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold05.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold05.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold06.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold06.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold06.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold06.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold06.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold06.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold07.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold07.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold07.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold07.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold07.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold07.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold08.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold08.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold08.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold08.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold08.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold08.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold09.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold09.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold09.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold09.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold09.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold09.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold10.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold10.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold10.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold10.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold10.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold10.Rep1: mtry=6, min.node.size=5, splitrule=variance 
Aggregating results
Selecting tuning parameters
Fitting mtry = 4, splitrule = variance, min.node.size = 5 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
10.3952072410887
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;gbm&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span>
<span class="nf">require</span><span class="p">(</span><span class="n">gbm</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>package &#39;gbm&#39; successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\lenovo\AppData\Local\Temp\RtmpmY4E4B\downloaded_packages
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Loading required package: lattice
Loading required package: ggplot2

Attaching package: &#39;ggplot2&#39;

The following object is masked from &#39;package:randomForest&#39;:

    margin

Loading required package: gbm
Warning message:
&#34;package &#39;gbm&#39; was built under R version 3.6.3&#34;Loaded gbm 2.1.8
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[237]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">grid_sgb1</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">300</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.02</span><span class="p">),</span> <span class="n">n.minobsinnode</span><span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">sgb1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">AbsenteeismTimeInHours</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">grid_sgb1</span> <span class="p">,</span> <span class="n">trControl</span><span class="o">=</span> <span class="n">control1</span><span class="p">)</span>

<span class="n">sgb_pred1</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sgb1</span><span class="p">,</span><span class="n">test1</span><span class="p">)</span>
<span class="n">sgb_error1</span> <span class="o">&lt;-</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test1</span><span class="o">$</span><span class="n">AbsenteeismTimeInHours</span><span class="p">,</span><span class="n">sgb_pred1</span><span class="p">)</span>
<span class="n">sgb_error1</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      181.3577             nan     0.0100    0.0907
     2      181.2154             nan     0.0100    0.1345
     3      181.0818             nan     0.0100    0.1177
     4      180.9666             nan     0.0100    0.0572
     5      180.9200             nan     0.0100   -0.0393
     6      180.7520             nan     0.0100    0.0499
     7      180.5614             nan     0.0100   -0.0343
     8      180.4443             nan     0.0100    0.0593
     9      180.3651             nan     0.0100    0.0576
    10      180.2625             nan     0.0100    0.0252
    20      178.7273             nan     0.0100    0.0446
    40      176.6285             nan     0.0100    0.0001
    60      174.5452             nan     0.0100    0.0664
    80      172.3585             nan     0.0100   -0.0333
   100      170.8317             nan     0.0100   -0.0400
   120      169.3149             nan     0.0100    0.0586
   140      167.9993             nan     0.0100   -0.0098
   160      166.9131             nan     0.0100   -0.0106
   180      165.7727             nan     0.0100   -0.0086
   200      164.7032             nan     0.0100    0.0539
   220      163.8121             nan     0.0100   -0.0446
   240      162.7498             nan     0.0100   -0.0313
   260      162.0457             nan     0.0100   -0.0183
   280      161.2511             nan     0.0100   -0.0604
   300      160.5101             nan     0.0100   -0.0607

- Fold01.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      181.2616             nan     0.0100    0.0805
     2      180.8333             nan     0.0100    0.2625
     3      180.4198             nan     0.0100    0.3397
     4      180.1512             nan     0.0100    0.0183
     5      179.7555             nan     0.0100    0.2049
     6      179.4388             nan     0.0100    0.0898
     7      179.0647             nan     0.0100    0.0670
     8      178.5910             nan     0.0100    0.3423
     9      178.2475             nan     0.0100   -0.0635
    10      177.8687             nan     0.0100    0.2603
    20      175.3569             nan     0.0100    0.0018
    40      170.4822             nan     0.0100    0.0242
    60      166.8528             nan     0.0100   -0.0109
    80      163.4765             nan     0.0100    0.0051
   100      160.4976             nan     0.0100   -0.1098
   120      157.9266             nan     0.0100   -0.0176
   140      155.3424             nan     0.0100   -0.0891
   160      153.2787             nan     0.0100   -0.0420
   180      150.9984             nan     0.0100   -0.0792
   200      148.4591             nan     0.0100   -0.0168
   220      146.9422             nan     0.0100   -0.1170
   240      145.5012             nan     0.0100   -0.0410
   260      143.8954             nan     0.0100   -0.0581
   280      142.4641             nan     0.0100   -0.0489
   300      141.2637             nan     0.0100    0.0223

- Fold01.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      181.0741             nan     0.0100    0.2078
     2      180.7266             nan     0.0100    0.0972
     3      180.4592             nan     0.0100    0.0716
     4      180.0018             nan     0.0100    0.2602
     5      179.6488             nan     0.0100    0.3471
     6      179.3571             nan     0.0100    0.1157
     7      178.7952             nan     0.0100    0.3174
     8      178.3619             nan     0.0100    0.3792
     9      177.9983             nan     0.0100    0.0776
    10      177.4677             nan     0.0100    0.0742
    20      173.8495             nan     0.0100    0.0662
    40      167.7069             nan     0.0100   -0.0049
    60      162.8007             nan     0.0100    0.0341
    80      158.5667             nan     0.0100   -0.0992
   100      154.3593             nan     0.0100   -0.0115
   120      151.1636             nan     0.0100   -0.0868
   140      148.4706             nan     0.0100   -0.0113
   160      146.2662             nan     0.0100   -0.0716
   180      143.9829             nan     0.0100   -0.0496
   200      141.9388             nan     0.0100   -0.1220
   220      140.1955             nan     0.0100   -0.0400
   240      138.1653             nan     0.0100   -0.2544
   260      136.5946             nan     0.0100   -0.1483
   280      134.5074             nan     0.0100    0.0563
   300      132.9926             nan     0.0100   -0.1366

- Fold01.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      181.1868             nan     0.0200    0.2782
     2      180.9982             nan     0.0200    0.1297
     3      180.6929             nan     0.0200    0.2738
     4      180.3383             nan     0.0200    0.2199
     5      179.9652             nan     0.0200    0.1447
     6      179.6727             nan     0.0200    0.1073
     7      179.4285             nan     0.0200    0.1036
     8      179.2708             nan     0.0200   -0.0332
     9      178.9917             nan     0.0200    0.1932
    10      178.7436             nan     0.0200    0.2150
    20      176.3233             nan     0.0200    0.1517
    40      171.6820             nan     0.0200   -0.1910
    60      169.2734             nan     0.0200    0.0329
    80      166.9026             nan     0.0200   -0.0117
   100      164.7912             nan     0.0200   -0.0397
   120      163.1168             nan     0.0200    0.0129
   140      161.4195             nan     0.0200   -0.0398
   160      160.3331             nan     0.0200   -0.1045
   180      158.9508             nan     0.0200   -0.0426
   200      158.1420             nan     0.0200   -0.0243
   220      157.1990             nan     0.0200   -0.2370
   240      156.2057             nan     0.0200   -0.1365
   260      155.4382             nan     0.0200   -0.0503
   280      154.7289             nan     0.0200   -0.0872
   300      154.1049             nan     0.0200   -0.1021

- Fold01.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      180.8835             nan     0.0200    0.5362
     2      180.2131             nan     0.0200    0.4110
     3      179.5914             nan     0.0200    0.1876
     4      178.8897             nan     0.0200    0.4191
     5      178.3541             nan     0.0200   -0.0955
     6      177.8441             nan     0.0200    0.2656
     7      176.9507             nan     0.0200    0.4241
     8      176.1113             nan     0.0200    0.4855
     9      175.2884             nan     0.0200    0.4960
    10      174.8651             nan     0.0200    0.0942
    20      169.9535             nan     0.0200    0.0374
    40      162.2250             nan     0.0200    0.2070
    60      156.7272             nan     0.0200    0.0102
    80      152.3153             nan     0.0200   -0.0362
   100      148.6821             nan     0.0200   -0.2337
   120      145.6507             nan     0.0200   -0.2220
   140      142.6602             nan     0.0200   -0.2029
   160      140.2032             nan     0.0200   -0.0201
   180      137.9928             nan     0.0200   -0.1948
   200      135.4364             nan     0.0200   -0.0943
   220      133.3076             nan     0.0200   -0.1879
   240      131.5748             nan     0.0200   -0.2103
   260      130.0010             nan     0.0200   -0.2380
   280      128.2165             nan     0.0200   -0.1752
   300      126.7353             nan     0.0200   -0.1207

- Fold01.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      180.5838             nan     0.0200    0.5975
     2      179.4843             nan     0.0200    0.9600
     3      178.9133             nan     0.0200    0.3587
     4      178.0051             nan     0.0200   -0.0286
     5      177.4748             nan     0.0200    0.5417
     6      176.6243             nan     0.0200    0.3734
     7      175.5415             nan     0.0200    0.5458
     8      174.6666             nan     0.0200    0.2863
     9      174.1069             nan     0.0200    0.2601
    10      173.4142             nan     0.0200    0.3096
    20      167.6642             nan     0.0200    0.1845
    40      157.7131             nan     0.0200   -0.1207
    60      150.9890             nan     0.0200   -0.1605
    80      146.0384             nan     0.0200   -0.1013
   100      141.3684             nan     0.0200   -0.2441
   120      137.2582             nan     0.0200    0.0480
   140      133.5452             nan     0.0200   -0.1490
   160      130.4602             nan     0.0200   -0.1916
   180      128.0092             nan     0.0200   -0.1493
   200      125.5212             nan     0.0200   -0.1248
   220      123.7252             nan     0.0200   -0.1669
   240      121.7633             nan     0.0200   -0.3575
   260      119.7829             nan     0.0200   -0.1321
   280      117.8946             nan     0.0200   -0.2092
   300      115.9252             nan     0.0200   -0.2641

- Fold01.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      180.9011             nan     0.0500    0.6032
     2      180.2496             nan     0.0500    0.2272
     3      179.3590             nan     0.0500    0.5428
     4      178.6005             nan     0.0500    0.5478
     5      177.8565             nan     0.0500    0.2171
     6      177.5264             nan     0.0500   -0.1128
     7      176.5998             nan     0.0500    0.5361
     8      175.9575             nan     0.0500    0.3363
     9      175.6166             nan     0.0500   -0.1154
    10      174.8295             nan     0.0500    0.0476
    20      170.4981             nan     0.0500    0.1994
    40      165.1320             nan     0.0500   -0.1252
    60      160.8245             nan     0.0500   -0.1143
    80      158.2446             nan     0.0500    0.1684
   100      156.1168             nan     0.0500   -0.0106
   120      154.7070             nan     0.0500    0.0566
   140      153.0836             nan     0.0500   -0.3033
   160      151.5872             nan     0.0500   -0.1679
   180      150.9493             nan     0.0500   -0.5883
   200      150.0529             nan     0.0500   -0.1359
   220      149.3917             nan     0.0500   -0.1402
   240      148.9358             nan     0.0500   -0.2160
   260      148.4970             nan     0.0500   -0.0476
   280      148.0337             nan     0.0500   -0.2368
   300      147.8370             nan     0.0500   -0.2091

- Fold01.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      179.3073             nan     0.0500    0.7104
     2      177.9706             nan     0.0500    1.1578
     3      176.2340             nan     0.0500    1.2849
     4      175.0749             nan     0.0500    0.6900
     5      174.2908             nan     0.0500    0.5535
     6      173.2671             nan     0.0500    0.4898
     7      172.0306             nan     0.0500    0.3404
     8      171.3620             nan     0.0500    0.3754
     9      170.6127             nan     0.0500   -0.0865
    10      169.7486             nan     0.0500    0.2043
    20      160.4749             nan     0.0500   -0.0050
    40      150.1930             nan     0.0500    0.1494
    60      143.4666             nan     0.0500   -1.0400
    80      138.0655             nan     0.0500   -0.3354
   100      132.4693             nan     0.0500   -0.3972
   120      129.0928             nan     0.0500   -0.4580
   140      125.5599             nan     0.0500   -0.4996
   160      122.8344             nan     0.0500   -0.6185
   180      119.2881             nan     0.0500   -0.4073
   200      116.8401             nan     0.0500   -0.2901
   220      115.1541             nan     0.0500   -0.5160
   240      112.6822             nan     0.0500   -0.4431
   260      110.3921             nan     0.0500   -0.3406
   280      108.8659             nan     0.0500   -0.2920
   300      107.2612             nan     0.0500   -0.3120

- Fold01.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      179.3714             nan     0.0500    0.9776
     2      177.4739             nan     0.0500    1.0132
     3      175.4217             nan     0.0500    0.7065
     4      173.4386             nan     0.0500    0.2490
     5      170.9799             nan     0.0500    0.4619
     6      169.3397             nan     0.0500    1.1313
     7      168.1631             nan     0.0500    0.2106
     8      166.9898             nan     0.0500    0.2539
     9      165.5732             nan     0.0500   -0.7253
    10      164.2269             nan     0.0500    0.6972
    20      154.9125             nan     0.0500   -0.3417
    40      141.3646             nan     0.0500   -0.2502
    60      132.8692             nan     0.0500    0.5347
    80      125.5337             nan     0.0500   -1.0284
   100      119.6633             nan     0.0500   -0.3943
   120      115.5489             nan     0.0500   -0.5292
   140      111.9118             nan     0.0500   -0.6219
   160      106.5810             nan     0.0500   -0.1486
   180      103.8325             nan     0.0500   -0.6103
   200      100.4997             nan     0.0500   -0.6787
   220       97.0197             nan     0.0500   -0.4851
   240       94.3860             nan     0.0500   -0.4120
   260       91.2155             nan     0.0500   -0.9253
   280       89.0168             nan     0.0500   -0.3990
   300       86.5334             nan     0.0500   -0.5913

- Fold01.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.9215             nan     0.0100   -0.0126
     2      196.8097             nan     0.0100    0.0364
     3      196.5866             nan     0.0100   -0.0191
     4      196.4448             nan     0.0100    0.1121
     5      196.3040             nan     0.0100    0.1317
     6      196.1657             nan     0.0100    0.1027
     7      196.0175             nan     0.0100    0.0692
     8      195.8705             nan     0.0100    0.0078
     9      195.7344             nan     0.0100    0.0545
    10      195.6312             nan     0.0100    0.0509
    20      194.3774             nan     0.0100   -0.0607
    40      191.8376             nan     0.0100    0.1201
    60      189.7436             nan     0.0100    0.0170
    80      187.7299             nan     0.0100   -0.0345
   100      186.2395             nan     0.0100    0.0659
   120      184.9135             nan     0.0100    0.0456
   140      183.4534             nan     0.0100   -0.0514
   160      182.0516             nan     0.0100   -0.0085
   180      180.6980             nan     0.0100   -0.0357
   200      179.4138             nan     0.0100    0.0116
   220      178.2809             nan     0.0100   -0.0226
   240      177.2202             nan     0.0100   -0.0466
   260      176.3592             nan     0.0100   -0.0488
   280      175.4544             nan     0.0100   -0.0511
   300      174.7081             nan     0.0100   -0.1319

- Fold02.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.7509             nan     0.0100    0.1413
     2      196.3087             nan     0.0100    0.1753
     3      195.8462             nan     0.0100    0.1899
     4      195.6006             nan     0.0100    0.1298
     5      195.2170             nan     0.0100    0.0415
     6      194.9326             nan     0.0100    0.2336
     7      194.6543             nan     0.0100    0.1472
     8      194.3458             nan     0.0100   -0.0026
     9      194.1464             nan     0.0100    0.0219
    10      193.8623             nan     0.0100    0.0576
    20      191.1887             nan     0.0100    0.0361
    40      185.8774             nan     0.0100    0.0517
    60      181.3124             nan     0.0100   -0.0539
    80      177.5696             nan     0.0100    0.0263
   100      174.3281             nan     0.0100   -0.0185
   120      171.0597             nan     0.0100   -0.0136
   140      167.6553             nan     0.0100   -0.0099
   160      165.3492             nan     0.0100   -0.0274
   180      163.1829             nan     0.0100   -0.0023
   200      160.3244             nan     0.0100   -0.1345
   220      158.3603             nan     0.0100   -0.0872
   240      156.1058             nan     0.0100   -0.0380
   260      154.7326             nan     0.0100   -0.0751
   280      152.9271             nan     0.0100   -0.1008
   300      151.4899             nan     0.0100   -0.0862

- Fold02.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.7384             nan     0.0100   -0.0345
     2      196.3248             nan     0.0100    0.1615
     3      195.8209             nan     0.0100    0.2371
     4      195.2329             nan     0.0100    0.1988
     5      194.7869             nan     0.0100    0.0458
     6      194.2764             nan     0.0100    0.2143
     7      193.7951             nan     0.0100   -0.0220
     8      193.4469             nan     0.0100    0.2331
     9      193.1125             nan     0.0100    0.1861
    10      192.6321             nan     0.0100    0.0107
    20      188.8634             nan     0.0100    0.0663
    40      182.7424             nan     0.0100    0.1634
    60      176.8009             nan     0.0100   -0.0697
    80      172.7896             nan     0.0100    0.0282
   100      168.4999             nan     0.0100   -0.0080
   120      165.1611             nan     0.0100   -0.0433
   140      162.0754             nan     0.0100    0.1025
   160      159.2660             nan     0.0100   -0.0599
   180      156.4272             nan     0.0100   -0.0815
   200      153.8816             nan     0.0100   -0.0504
   220      151.0711             nan     0.0100   -0.0851
   240      148.9472             nan     0.0100   -0.1348
   260      146.9223             nan     0.0100   -0.0598
   280      144.9838             nan     0.0100   -0.1630
   300      143.1773             nan     0.0100   -0.1186

- Fold02.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.8730             nan     0.0200    0.2076
     2      196.7444             nan     0.0200   -0.0434
     3      196.5556             nan     0.0200   -0.0452
     4      196.3622             nan     0.0200   -0.0024
     5      196.2358             nan     0.0200    0.0809
     6      195.9227             nan     0.0200    0.2013
     7      195.6319             nan     0.0200   -0.1437
     8      195.3264             nan     0.0200    0.1573
     9      195.1186             nan     0.0200    0.2294
    10      194.8761             nan     0.0200   -0.2290
    20      192.9914             nan     0.0200    0.1494
    40      188.3499             nan     0.0200   -0.0501
    60      184.7521             nan     0.0200    0.0754
    80      181.7422             nan     0.0200   -0.0173
   100      179.3367             nan     0.0200   -0.0728
   120      177.4235             nan     0.0200   -0.0693
   140      175.6651             nan     0.0200   -0.0986
   160      174.5283             nan     0.0200   -0.0337
   180      173.2248             nan     0.0200   -0.0553
   200      172.0432             nan     0.0200    0.0187
   220      170.8054             nan     0.0200    0.0448
   240      169.8637             nan     0.0200   -0.1781
   260      168.9637             nan     0.0200   -0.1468
   280      168.1939             nan     0.0200   -0.1886
   300      167.2870             nan     0.0200   -0.2028

- Fold02.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.3098             nan     0.0200    0.1608
     2      195.6209             nan     0.0200    0.1335
     3      194.9308             nan     0.0200    0.6056
     4      194.3413             nan     0.0200    0.1403
     5      193.6622             nan     0.0200    0.2065
     6      192.8848             nan     0.0200   -0.1775
     7      192.3997             nan     0.0200   -0.0508
     8      191.8738             nan     0.0200    0.4649
     9      191.3626             nan     0.0200    0.3920
    10      191.0630             nan     0.0200    0.1441
    20      185.7267             nan     0.0200    0.2790
    40      177.5614             nan     0.0200   -0.0733
    60      170.3964             nan     0.0200   -0.1104
    80      164.8860             nan     0.0200   -0.2382
   100      160.7728             nan     0.0200   -0.1860
   120      156.9101             nan     0.0200   -0.0399
   140      153.7312             nan     0.0200   -0.1866
   160      150.5735             nan     0.0200   -0.1726
   180      147.3159             nan     0.0200   -0.2390
   200      144.4841             nan     0.0200   -0.2660
   220      142.4149             nan     0.0200   -0.1852
   240      140.7422             nan     0.0200   -0.1944
   260      138.9089             nan     0.0200   -0.0393
   280      136.8927             nan     0.0200   -0.3488
   300      135.3541             nan     0.0200   -0.2613

- Fold02.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.0300             nan     0.0200    0.1931
     2      195.0263             nan     0.0200    0.3326
     3      194.0730             nan     0.0200   -0.0417
     4      193.3166             nan     0.0200    0.5033
     5      192.5783             nan     0.0200    0.5463
     6      191.9430             nan     0.0200    0.3750
     7      191.0857             nan     0.0200    0.3824
     8      190.5217             nan     0.0200    0.2330
     9      190.1979             nan     0.0200   -0.0138
    10      189.6413             nan     0.0200   -0.0980
    20      182.9281             nan     0.0200    0.3483
    40      171.5894             nan     0.0200    0.1285
    60      165.0002             nan     0.0200   -0.1708
    80      158.4526             nan     0.0200   -0.3306
   100      153.1931             nan     0.0200   -0.2918
   120      148.7299             nan     0.0200   -0.2318
   140      144.4444             nan     0.0200   -0.1334
   160      140.6393             nan     0.0200   -0.3288
   180      137.7612             nan     0.0200   -0.3612
   200      134.4995             nan     0.0200   -0.4788
   220      131.4538             nan     0.0200   -0.1880
   240      128.8218             nan     0.0200   -0.3869
   260      126.1292             nan     0.0200   -0.4449
   280      123.2954             nan     0.0200   -0.3612
   300      121.3667             nan     0.0200   -0.1522

- Fold02.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.7547             nan     0.0500    0.1917
     2      196.1378             nan     0.0500    0.4123
     3      195.2410             nan     0.0500    0.4357
     4      194.2907             nan     0.0500   -0.5884
     5      193.7929             nan     0.0500   -0.4767
     6      193.0183             nan     0.0500    0.3850
     7      192.3319             nan     0.0500    0.5299
     8      191.6859             nan     0.0500    0.4195
     9      191.3343             nan     0.0500   -0.2484
    10      190.9651             nan     0.0500    0.2048
    20      186.5542             nan     0.0500    0.1480
    40      179.2035             nan     0.0500   -0.0380
    60      174.9383             nan     0.0500   -0.2047
    80      171.1792             nan     0.0500   -0.0358
   100      169.0753             nan     0.0500   -0.3499
   120      166.9238             nan     0.0500   -0.1857
   140      165.4957             nan     0.0500   -0.3339
   160      164.0846             nan     0.0500   -0.4255
   180      162.9520             nan     0.0500   -0.4296
   200      162.0915             nan     0.0500   -0.2802
   220      161.0033             nan     0.0500   -0.3752
   240      160.2891             nan     0.0500   -0.1980
   260      159.8260             nan     0.0500   -0.1807
   280      159.5652             nan     0.0500   -0.3805
   300      158.7416             nan     0.0500   -0.0468

- Fold02.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      194.2873             nan     0.0500   -0.4560
     2      192.7210             nan     0.0500    0.6330
     3      190.9670             nan     0.0500    1.0595
     4      189.2960             nan     0.0500    0.1563
     5      187.7991             nan     0.0500    0.2900
     6      186.2705             nan     0.0500   -0.7332
     7      184.7958             nan     0.0500    0.2027
     8      183.4266             nan     0.0500    1.0003
     9      182.1735             nan     0.0500   -0.5522
    10      180.8368             nan     0.0500    0.1091
    20      172.2401             nan     0.0500   -0.2385
    40      161.5592             nan     0.0500   -0.6373
    60      153.3143             nan     0.0500   -1.0193
    80      146.8632             nan     0.0500   -0.4565
   100      141.8744             nan     0.0500   -1.0299
   120      137.3531             nan     0.0500   -0.4848
   140      133.2980             nan     0.0500   -0.5513
   160      130.3942             nan     0.0500   -0.5803
   180      127.3967             nan     0.0500   -0.6100
   200      125.0693             nan     0.0500   -0.2645
   220      122.7620             nan     0.0500   -0.4205
   240      120.1825             nan     0.0500   -0.3265
   260      118.0608             nan     0.0500   -0.3791
   280      115.9368             nan     0.0500   -0.4738
   300      114.4975             nan     0.0500   -0.2756

- Fold02.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 3: Reason.for.absence3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      195.4433             nan     0.0500    1.2645
     2      193.8415             nan     0.0500    1.2619
     3      191.3961             nan     0.0500    0.9923
     4      189.3926             nan     0.0500    0.4115
     5      187.4753             nan     0.0500    1.6240
     6      186.2294             nan     0.0500   -0.1922
     7      184.8774             nan     0.0500    0.5258
     8      182.9016             nan     0.0500   -0.0611
     9      180.9233             nan     0.0500   -0.5290
    10      179.6537             nan     0.0500   -0.1859
    20      166.6899             nan     0.0500    0.0297
    40      153.7193             nan     0.0500   -1.0050
    60      144.1787             nan     0.0500   -0.2205
    80      135.4505             nan     0.0500   -0.1781
   100      128.1144             nan     0.0500   -0.4768
   120      121.3042             nan     0.0500   -0.6767
   140      116.8612             nan     0.0500   -0.3103
   160      112.3871             nan     0.0500   -0.6739
   180      109.0376             nan     0.0500   -0.4642
   200      105.7431             nan     0.0500   -0.3423
   220      103.6236             nan     0.0500   -1.1659
   240      101.1478             nan     0.0500   -0.3401
   260       98.7806             nan     0.0500   -0.3621
   280       96.8688             nan     0.0500   -0.4764
   300       94.5483             nan     0.0500   -0.2352

- Fold02.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      188.2131             nan     0.0100    0.0987
     2      188.0297             nan     0.0100    0.1387
     3      187.9254             nan     0.0100   -0.0076
     4      187.7225             nan     0.0100   -0.0441
     5      187.5183             nan     0.0100    0.1199
     6      187.3351             nan     0.0100    0.1356
     7      187.1794             nan     0.0100    0.0354
     8      186.9768             nan     0.0100    0.1268
     9      186.8084             nan     0.0100    0.1531
    10      186.5724             nan     0.0100    0.0430
    20      185.0106             nan     0.0100    0.0919
    40      182.0385             nan     0.0100    0.0304
    60      179.8568             nan     0.0100   -0.0056
    80      177.5712             nan     0.0100    0.0265
   100      175.6909             nan     0.0100    0.0717
   120      173.9690             nan     0.0100    0.0157
   140      172.3272             nan     0.0100    0.0441
   160      170.9523             nan     0.0100    0.0589
   180      169.7085             nan     0.0100   -0.0467
   200      168.6044             nan     0.0100   -0.1115
   220      167.4230             nan     0.0100   -0.0601
   240      166.3922             nan     0.0100    0.0316
   260      165.4425             nan     0.0100   -0.0862
   280      164.5012             nan     0.0100   -0.1332
   300      163.6627             nan     0.0100   -0.0166

- Fold03.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      187.7878             nan     0.0100    0.0657
     2      187.1616             nan     0.0100    0.4213
     3      186.7248             nan     0.0100    0.3272
     4      186.2547             nan     0.0100    0.1829
     5      185.9686             nan     0.0100    0.1206
     6      185.4990             nan     0.0100    0.2740
     7      185.1855             nan     0.0100    0.1864
     8      184.7988             nan     0.0100    0.0638
     9      184.4191             nan     0.0100    0.3760
    10      184.0591             nan     0.0100   -0.1146
    20      180.8621             nan     0.0100    0.1288
    40      175.0189             nan     0.0100    0.2210
    60      169.8778             nan     0.0100    0.0398
    80      166.3213             nan     0.0100   -0.0517
   100      163.2813             nan     0.0100    0.0066
   120      160.6997             nan     0.0100   -0.0618
   140      157.7141             nan     0.0100   -0.0420
   160      155.6997             nan     0.0100   -0.0492
   180      153.4268             nan     0.0100   -0.0687
   200      151.6681             nan     0.0100   -0.0826
   220      149.8868             nan     0.0100   -0.0212
   240      148.0857             nan     0.0100   -0.0907
   260      146.6723             nan     0.0100   -0.0339
   280      145.0045             nan     0.0100   -0.0169
   300      143.7086             nan     0.0100   -0.0403

- Fold03.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      187.7571             nan     0.0100    0.3716
     2      187.3264             nan     0.0100    0.3581
     3      186.7859             nan     0.0100    0.4833
     4      186.4543             nan     0.0100    0.0718
     5      185.9960             nan     0.0100    0.3160
     6      185.5007             nan     0.0100    0.1429
     7      185.1594             nan     0.0100    0.2823
     8      184.7614             nan     0.0100    0.1842
     9      184.2823             nan     0.0100    0.4332
    10      183.7522             nan     0.0100    0.1671
    20      179.1684             nan     0.0100    0.1937
    40      171.7335             nan     0.0100    0.0203
    60      166.4658             nan     0.0100   -0.0366
    80      161.9894             nan     0.0100   -0.0810
   100      157.9147             nan     0.0100   -0.0353
   120      154.5897             nan     0.0100   -0.0936
   140      151.4705             nan     0.0100   -0.0819
   160      148.5108             nan     0.0100   -0.0077
   180      146.2253             nan     0.0100   -0.1183
   200      143.8572             nan     0.0100   -0.0499
   220      141.7801             nan     0.0100   -0.0796
   240      139.1810             nan     0.0100   -0.2125
   260      137.6471             nan     0.0100   -0.0842
   280      135.7188             nan     0.0100   -0.0366
   300      133.7489             nan     0.0100   -0.1685

- Fold03.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      188.0226             nan     0.0200    0.0245
     2      187.7554             nan     0.0200    0.0468
     3      187.3879             nan     0.0200    0.2262
     4      186.9575             nan     0.0200    0.1284
     5      186.4105             nan     0.0200    0.2315
     6      186.0552             nan     0.0200    0.2724
     7      185.7492             nan     0.0200    0.1446
     8      185.5837             nan     0.0200    0.1505
     9      185.3568             nan     0.0200    0.1646
    10      185.0541             nan     0.0200    0.0837
    20      182.4164             nan     0.0200    0.1266
    40      177.3049             nan     0.0200    0.1211
    60      172.9539             nan     0.0200    0.0232
    80      170.1177             nan     0.0200   -0.0191
   100      167.9526             nan     0.0200   -0.1482
   120      165.7085             nan     0.0200   -0.0379
   140      164.1410             nan     0.0200   -0.2167
   160      162.9791             nan     0.0200   -0.4089
   180      162.0272             nan     0.0200   -0.1222
   200      160.7819             nan     0.0200   -0.0081
   220      159.8470             nan     0.0200    0.0530
   240      158.7007             nan     0.0200   -0.2967
   260      157.9175             nan     0.0200   -0.1281
   280      157.1917             nan     0.0200   -0.1173
   300      156.5641             nan     0.0200   -0.0536

- Fold03.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      187.9226             nan     0.0200    0.1549
     2      186.9918             nan     0.0200    0.3373
     3      185.9489             nan     0.0200    0.7341
     4      185.3482             nan     0.0200    0.3931
     5      184.6450             nan     0.0200    0.4770
     6      183.6791             nan     0.0200    0.3782
     7      182.8306             nan     0.0200   -0.1310
     8      182.1105             nan     0.0200    0.3115
     9      181.6374             nan     0.0200    0.0399
    10      180.7391             nan     0.0200    0.5049
    20      174.7954             nan     0.0200    0.0577
    40      167.3411             nan     0.0200   -0.0791
    60      161.7271             nan     0.0200    0.1677
    80      156.9969             nan     0.0200   -0.1056
   100      152.6762             nan     0.0200   -0.1032
   120      148.5747             nan     0.0200   -0.1579
   140      144.9896             nan     0.0200   -0.2080
   160      142.1975             nan     0.0200   -0.3313
   180      139.4307             nan     0.0200   -0.0629
   200      136.9017             nan     0.0200   -0.1771
   220      134.8778             nan     0.0200   -0.2310
   240      133.1181             nan     0.0200   -0.0415
   260      131.6624             nan     0.0200   -0.1831
   280      130.2489             nan     0.0200   -0.1142
   300      128.4647             nan     0.0200   -0.1960

- Fold03.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      186.9535             nan     0.0200    0.7059
     2      185.5746             nan     0.0200    0.5895
     3      184.5181             nan     0.0200    0.8267
     4      183.9870             nan     0.0200    0.2992
     5      183.4296             nan     0.0200    0.3043
     6      182.1208             nan     0.0200    0.5648
     7      181.3212             nan     0.0200    0.5463
     8      180.2146             nan     0.0200    0.5562
     9      179.3710             nan     0.0200    0.2175
    10      178.3950             nan     0.0200    0.1796
    20      171.7744             nan     0.0200   -0.1602
    40      160.8640             nan     0.0200    0.0420
    60      153.1860             nan     0.0200    0.1613
    80      148.3167             nan     0.0200   -0.2571
   100      143.8114             nan     0.0200   -0.1947
   120      139.5699             nan     0.0200   -0.2425
   140      135.8005             nan     0.0200   -0.2738
   160      131.4884             nan     0.0200   -0.0191
   180      128.7347             nan     0.0200   -0.1872
   200      126.5691             nan     0.0200   -0.1949
   220      124.1114             nan     0.0200   -0.1842
   240      121.1049             nan     0.0200   -0.3146
   260      118.9301             nan     0.0200   -0.1975
   280      116.9009             nan     0.0200   -0.2561
   300      115.1936             nan     0.0200   -0.3522

- Fold03.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      187.7110             nan     0.0500    0.6600
     2      186.6356             nan     0.0500    0.3241
     3      185.9120             nan     0.0500    0.2621
     4      185.1869             nan     0.0500    0.2584
     5      184.4421             nan     0.0500   -0.0119
     6      183.6818             nan     0.0500    0.6068
     7      182.7588             nan     0.0500    0.4929
     8      182.1668             nan     0.0500    0.0259
     9      181.9268             nan     0.0500   -0.3920
    10      181.2571             nan     0.0500    0.4716
    20      175.1888             nan     0.0500    0.3032
    40      168.4455             nan     0.0500   -0.2676
    60      163.9929             nan     0.0500    0.0416
    80      161.7265             nan     0.0500   -0.2190
   100      159.4063             nan     0.0500   -0.3583
   120      157.8763             nan     0.0500   -0.6355
   140      156.3064             nan     0.0500   -0.3776
   160      155.0537             nan     0.0500   -0.3443
   180      154.0411             nan     0.0500   -0.3119
   200      153.6877             nan     0.0500   -0.1563
   220      153.1461             nan     0.0500   -0.1338
   240      152.4381             nan     0.0500   -0.2233
   260      152.0171             nan     0.0500   -0.0502
   280      151.3348             nan     0.0500   -0.8911
   300      150.5731             nan     0.0500   -0.2339

- Fold03.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      186.5195             nan     0.0500   -0.0151
     2      184.2687             nan     0.0500    1.7794
     3      182.2141             nan     0.0500    1.6943
     4      180.8213             nan     0.0500    0.7859
     5      179.1959             nan     0.0500    1.0539
     6      178.2118             nan     0.0500    0.0314
     7      176.5540             nan     0.0500    0.5037
     8      175.2840             nan     0.0500    0.6399
     9      174.0636             nan     0.0500    1.1119
    10      173.0278             nan     0.0500    0.0554
    20      163.2183             nan     0.0500    0.3945
    40      150.9374             nan     0.0500    0.6517
    60      142.1325             nan     0.0500   -0.2594
    80      137.2955             nan     0.0500   -0.6877
   100      132.9780             nan     0.0500   -0.3568
   120      130.3234             nan     0.0500   -0.8349
   140      126.7241             nan     0.0500   -0.4339
   160      123.4121             nan     0.0500   -0.7718
   180      120.3247             nan     0.0500   -0.0946
   200      117.7432             nan     0.0500   -0.2767
   220      115.7534             nan     0.0500    0.0087
   240      113.5827             nan     0.0500   -0.3579
   260      112.0068             nan     0.0500   -0.2838
   280      109.9923             nan     0.0500   -0.6677
   300      108.0211             nan     0.0500   -0.2745

- Fold03.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      186.0702             nan     0.0500    0.3152
     2      183.0846             nan     0.0500    1.9008
     3      180.5381             nan     0.0500    2.2460
     4      178.9761             nan     0.0500    1.0466
     5      176.5385             nan     0.0500    1.2390
     6      174.9698             nan     0.0500    1.5044
     7      173.5048             nan     0.0500    1.0279
     8      172.0397             nan     0.0500    0.4975
     9      171.6405             nan     0.0500   -0.1871
    10      170.3641             nan     0.0500    0.1710
    20      159.9602             nan     0.0500   -0.1634
    40      147.6343             nan     0.0500   -0.0037
    60      138.4054             nan     0.0500   -0.6360
    80      130.5804             nan     0.0500   -0.7463
   100      124.5596             nan     0.0500   -0.3780
   120      118.7498             nan     0.0500   -0.7895
   140      113.9018             nan     0.0500   -0.4714
   160      109.8343             nan     0.0500   -0.7025
   180      105.7143             nan     0.0500   -0.6061
   200      103.0359             nan     0.0500   -0.6095
   220      100.1497             nan     0.0500   -0.7613
   240       96.4825             nan     0.0500   -0.9302
   260       93.8047             nan     0.0500   -0.1225
   280       91.9572             nan     0.0500   -0.8696
   300       89.3804             nan     0.0500   -0.3909

- Fold03.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.7105             nan     0.0100   -0.0065
     2      202.6118             nan     0.0100   -0.0096
     3      202.4689             nan     0.0100   -0.0719
     4      202.3129             nan     0.0100    0.1299
     5      202.1551             nan     0.0100    0.1007
     6      202.0295             nan     0.0100   -0.0757
     7      201.8504             nan     0.0100   -0.0538
     8      201.7158             nan     0.0100    0.0107
     9      201.5799             nan     0.0100   -0.0033
    10      201.3415             nan     0.0100    0.0876
    20      200.1407             nan     0.0100    0.0905
    40      197.8443             nan     0.0100   -0.1659
    60      195.6890             nan     0.0100    0.0330
    80      193.7069             nan     0.0100    0.0696
   100      191.6259             nan     0.0100    0.0033
   120      189.8122             nan     0.0100    0.0514
   140      188.3453             nan     0.0100   -0.0555
   160      186.8513             nan     0.0100   -0.0287
   180      185.5313             nan     0.0100    0.0658
   200      184.2834             nan     0.0100   -0.0358
   220      183.2450             nan     0.0100    0.0157
   240      182.3564             nan     0.0100   -0.0359
   260      181.4336             nan     0.0100   -0.0805
   280      180.6367             nan     0.0100   -0.1247
   300      179.7787             nan     0.0100   -0.0331

- Fold04.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.3489             nan     0.0100    0.2397
     2      202.0675             nan     0.0100   -0.0297
     3      201.7943             nan     0.0100    0.0774
     4      201.4936             nan     0.0100    0.1300
     5      201.2080             nan     0.0100    0.1683
     6      200.6941             nan     0.0100    0.1800
     7      200.4471             nan     0.0100   -0.0486
     8      199.8150             nan     0.0100    0.2169
     9      199.4055             nan     0.0100   -0.0375
    10      199.0989             nan     0.0100    0.0031
    20      196.3120             nan     0.0100    0.0316
    40      190.7690             nan     0.0100    0.0972
    60      186.6239             nan     0.0100    0.0268
    80      181.8584             nan     0.0100   -0.0658
   100      177.9834             nan     0.0100    0.1181
   120      174.2787             nan     0.0100    0.0013
   140      171.3416             nan     0.0100    0.0993
   160      169.1229             nan     0.0100   -0.0762
   180      166.8517             nan     0.0100   -0.0543
   200      164.5463             nan     0.0100    0.0077
   220      162.3366             nan     0.0100   -0.1754
   240      160.5676             nan     0.0100    0.0617
   260      158.9994             nan     0.0100   -0.0943
   280      156.8306             nan     0.0100   -0.0553
   300      155.0833             nan     0.0100   -0.0846

- Fold04.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.3181             nan     0.0100    0.3541
     2      201.7799             nan     0.0100    0.1792
     3      201.1725             nan     0.0100    0.3108
     4      200.6168             nan     0.0100    0.1278
     5      200.2496             nan     0.0100    0.2568
     6      199.6587             nan     0.0100    0.2193
     7      199.3432             nan     0.0100    0.1417
     8      198.7865             nan     0.0100    0.2917
     9      198.1801             nan     0.0100    0.0250
    10      197.8937             nan     0.0100    0.0198
    20      193.8933             nan     0.0100    0.2234
    40      186.9520             nan     0.0100   -0.0073
    60      181.1469             nan     0.0100    0.0540
    80      176.0436             nan     0.0100   -0.0228
   100      171.3552             nan     0.0100   -0.1484
   120      167.3853             nan     0.0100    0.1371
   140      164.1197             nan     0.0100   -0.0441
   160      161.3619             nan     0.0100   -0.1815
   180      158.8069             nan     0.0100   -0.0769
   200      156.0521             nan     0.0100   -0.0649
   220      153.5651             nan     0.0100   -0.0562
   240      151.1621             nan     0.0100   -0.0910
   260      149.3553             nan     0.0100   -0.0119
   280      147.3728             nan     0.0100   -0.2626
   300      145.1846             nan     0.0100   -0.1399

- Fold04.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.5041             nan     0.0200    0.1149
     2      202.3211             nan     0.0200   -0.0218
     3      202.1135             nan     0.0200   -0.0551
     4      201.8954             nan     0.0200    0.1270
     5      201.7165             nan     0.0200    0.0893
     6      201.4233             nan     0.0200    0.0784
     7      201.0099             nan     0.0200    0.2176
     8      200.7085             nan     0.0200    0.1932
     9      200.4810             nan     0.0200    0.0091
    10      200.2269             nan     0.0200   -0.1400
    20      197.5493             nan     0.0200   -0.0489
    40      193.0518             nan     0.0200    0.1085
    60      189.4906             nan     0.0200    0.0239
    80      186.6823             nan     0.0200    0.0051
   100      184.1737             nan     0.0200   -0.0328
   120      182.0513             nan     0.0200    0.0186
   140      180.3298             nan     0.0200   -0.1587
   160      178.6429             nan     0.0200   -0.2414
   180      177.3434             nan     0.0200   -0.0646
   200      176.4233             nan     0.0200   -0.0904
   220      175.5912             nan     0.0200   -0.1068
   240      174.4400             nan     0.0200    0.0583
   260      173.6115             nan     0.0200   -0.1097
   280      172.8147             nan     0.0200   -0.0950
   300      171.7999             nan     0.0200   -0.0247

- Fold04.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.3859             nan     0.0200    0.4733
     2      201.7738             nan     0.0200    0.3009
     3      201.0414             nan     0.0200    0.4214
     4      200.4179             nan     0.0200   -0.0707
     5      199.9364             nan     0.0200    0.2880
     6      199.5923             nan     0.0200    0.0509
     7      199.2031             nan     0.0200    0.2719
     8      198.6543             nan     0.0200    0.0047
     9      198.0428             nan     0.0200    0.5584
    10      197.6310             nan     0.0200    0.4127
    20      192.1874             nan     0.0200   -0.1121
    40      183.7872             nan     0.0200   -0.0105
    60      176.2863             nan     0.0200    0.0277
    80      170.1685             nan     0.0200   -0.0319
   100      166.1430             nan     0.0200   -0.2688
   120      161.1262             nan     0.0200   -0.0603
   140      157.9887             nan     0.0200   -0.2378
   160      154.2825             nan     0.0200   -0.0937
   180      151.9054             nan     0.0200   -0.3196
   200      149.8925             nan     0.0200   -0.2683
   220      147.6508             nan     0.0200   -0.0584
   240      146.0364             nan     0.0200   -0.1035
   260      144.5714             nan     0.0200   -0.1736
   280      142.3640             nan     0.0200   -0.0647
   300      141.1909             nan     0.0200   -0.2887

- Fold04.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      201.8643             nan     0.0200    0.6009
     2      201.0277             nan     0.0200    0.3140
     3      199.7792             nan     0.0200    0.2396
     4      198.5839             nan     0.0200    0.6208
     5      198.1615             nan     0.0200    0.0116
     6      197.3096             nan     0.0200    0.5970
     7      196.4425             nan     0.0200    0.3809
     8      195.5599             nan     0.0200    0.3428
     9      194.9594             nan     0.0200    0.1634
    10      194.4562             nan     0.0200    0.0159
    20      187.9627             nan     0.0200   -0.0003
    40      176.8688             nan     0.0200   -0.0361
    60      169.1603             nan     0.0200   -0.1656
    80      162.3637             nan     0.0200   -0.5690
   100      157.4284             nan     0.0200   -0.1769
   120      153.1799             nan     0.0200   -0.1098
   140      148.8998             nan     0.0200   -0.2907
   160      145.2102             nan     0.0200   -0.0075
   180      141.8559             nan     0.0200   -0.3565
   200      138.3709             nan     0.0200   -0.1575
   220      135.2473             nan     0.0200   -0.3547
   240      132.7301             nan     0.0200   -0.0659
   260      129.9975             nan     0.0200   -0.2519
   280      128.2151             nan     0.0200   -0.2418
   300      125.3779             nan     0.0200   -0.1590

- Fold04.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      201.7415             nan     0.0500    0.7203
     2      201.2148             nan     0.0500    0.2698
     3      200.0909             nan     0.0500    0.3756
     4      199.5097             nan     0.0500   -0.1965
     5      198.9686             nan     0.0500   -0.2456
     6      198.2941             nan     0.0500    0.2759
     7      197.5172             nan     0.0500   -0.2208
     8      197.0936             nan     0.0500    0.2686
     9      196.4479             nan     0.0500   -0.2379
    10      195.8430             nan     0.0500   -0.4015
    20      191.0104             nan     0.0500    0.0550
    40      184.1173             nan     0.0500   -0.0353
    60      179.8446             nan     0.0500    0.0570
    80      176.5506             nan     0.0500   -0.3427
   100      173.7524             nan     0.0500   -0.2181
   120      172.1906             nan     0.0500   -0.3954
   140      170.5333             nan     0.0500   -0.4029
   160      169.2114             nan     0.0500   -0.4749
   180      167.7670             nan     0.0500   -0.1276
   200      166.7601             nan     0.0500   -0.8029
   220      166.0877             nan     0.0500   -0.1620
   240      165.6543             nan     0.0500   -0.4320
   260      165.2092             nan     0.0500   -0.6763
   280      164.8965             nan     0.0500   -0.4258
   300      164.0007             nan     0.0500   -0.8209

- Fold04.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      201.8072             nan     0.0500   -0.0401
     2      200.3098             nan     0.0500    0.0614
     3      199.0812             nan     0.0500    0.2740
     4      197.8062             nan     0.0500    0.9833
     5      196.2623             nan     0.0500    0.4242
     6      195.7649             nan     0.0500   -0.4837
     7      194.9403             nan     0.0500    0.3961
     8      193.5648             nan     0.0500   -0.1304
     9      191.6403             nan     0.0500    1.3388
    10      190.0713             nan     0.0500   -0.4805
    20      179.3425             nan     0.0500    0.2308
    40      163.8595             nan     0.0500   -0.4418
    60      154.3642             nan     0.0500   -0.2226
    80      149.1000             nan     0.0500   -0.5953
   100      143.5366             nan     0.0500   -0.3920
   120      138.3552             nan     0.0500   -0.6227
   140      134.1360             nan     0.0500   -0.7132
   160      131.3476             nan     0.0500   -0.3565
   180      127.2316             nan     0.0500   -0.5834
   200      124.7194             nan     0.0500   -0.4571
   220      122.4264             nan     0.0500   -0.4982
   240      120.0160             nan     0.0500   -0.3060
   260      118.2374             nan     0.0500   -0.7635
   280      116.3124             nan     0.0500   -0.3290
   300      114.6367             nan     0.0500   -0.1920

- Fold04.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      200.1495             nan     0.0500    1.1609
     2      198.6037             nan     0.0500    0.8764
     3      197.2966             nan     0.0500    0.5551
     4      196.2638             nan     0.0500   -0.1847
     5      193.8409             nan     0.0500    0.0517
     6      191.2238             nan     0.0500    0.8741
     7      189.6313             nan     0.0500    0.4022
     8      187.0881             nan     0.0500    0.4709
     9      185.1977             nan     0.0500   -0.3866
    10      183.7517             nan     0.0500    0.8016
    20      171.1702             nan     0.0500   -0.1363
    40      153.9655             nan     0.0500   -0.7264
    60      144.9310             nan     0.0500   -0.9352
    80      137.6820             nan     0.0500   -0.4751
   100      131.0907             nan     0.0500   -0.5318
   120      125.4661             nan     0.0500   -0.5474
   140      120.0555             nan     0.0500   -0.2687
   160      115.1532             nan     0.0500   -0.4324
   180      111.3413             nan     0.0500   -0.7937
   200      108.0744             nan     0.0500   -0.3802
   220      105.0427             nan     0.0500   -0.4313
   240      102.8427             nan     0.0500   -0.7122
   260      100.0143             nan     0.0500   -0.5502
   280       97.3092             nan     0.0500   -1.0818
   300       95.4190             nan     0.0500   -0.5842

- Fold04.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      204.2457             nan     0.0100    0.0801
     2      204.1433             nan     0.0100    0.0396
     3      203.9412             nan     0.0100    0.0616
     4      203.8168             nan     0.0100    0.1207
     5      203.6433             nan     0.0100    0.0871
     6      203.4811             nan     0.0100    0.0363
     7      203.3291             nan     0.0100    0.1386
     8      203.2013             nan     0.0100    0.0133
     9      203.0175             nan     0.0100    0.0352
    10      202.8936             nan     0.0100    0.1162
    20      201.5885             nan     0.0100    0.0724
    40      199.1251             nan     0.0100    0.0787
    60      197.1703             nan     0.0100    0.0080
    80      195.1256             nan     0.0100   -0.0145
   100      193.3092             nan     0.0100   -0.0125
   120      191.4425             nan     0.0100   -0.0117
   140      189.9113             nan     0.0100   -0.0952
   160      188.5211             nan     0.0100   -0.0048
   180      187.1798             nan     0.0100   -0.0271
   200      186.0477             nan     0.0100   -0.0711
   220      184.8815             nan     0.0100   -0.0603
   240      183.8178             nan     0.0100   -0.0030
   260      182.8403             nan     0.0100   -0.0388
   280      181.9689             nan     0.0100   -0.1103
   300      181.2589             nan     0.0100   -0.0188

- Fold05.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      204.1811             nan     0.0100    0.0996
     2      203.7248             nan     0.0100    0.1288
     3      203.3222             nan     0.0100    0.2773
     4      202.9803             nan     0.0100    0.2581
     5      202.7344             nan     0.0100    0.1439
     6      202.4697             nan     0.0100   -0.0025
     7      202.2401             nan     0.0100    0.1888
     8      201.8668             nan     0.0100    0.1602
     9      201.5444             nan     0.0100    0.1336
    10      201.2841             nan     0.0100    0.0794
    20      197.9568             nan     0.0100   -0.0335
    40      192.5492             nan     0.0100   -0.0472
    60      187.7354             nan     0.0100   -0.0503
    80      183.3653             nan     0.0100   -0.0322
   100      179.8875             nan     0.0100    0.0115
   120      177.2357             nan     0.0100   -0.0428
   140      174.0552             nan     0.0100    0.0116
   160      170.8109             nan     0.0100   -0.1075
   180      168.5483             nan     0.0100   -0.0595
   200      166.3312             nan     0.0100   -0.1298
   220      163.5793             nan     0.0100    0.0676
   240      161.5457             nan     0.0100   -0.1370
   260      159.2270             nan     0.0100    0.0233
   280      157.6986             nan     0.0100   -0.1538
   300      156.4048             nan     0.0100    0.0036

- Fold05.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      203.8627             nan     0.0100    0.3405
     2      203.4145             nan     0.0100    0.4469
     3      203.0801             nan     0.0100    0.3536
     4      202.6034             nan     0.0100    0.5088
     5      202.2089             nan     0.0100    0.2944
     6      201.6321             nan     0.0100    0.2321
     7      201.3926             nan     0.0100    0.0001
     8      200.9750             nan     0.0100    0.2135
     9      200.7354             nan     0.0100    0.1398
    10      200.2353             nan     0.0100    0.2900
    20      196.0429             nan     0.0100    0.0451
    40      189.3651             nan     0.0100    0.1713
    60      182.7181             nan     0.0100   -0.1350
    80      178.0487             nan     0.0100   -0.0213
   100      173.5293             nan     0.0100    0.0855
   120      169.2706             nan     0.0100    0.1710
   140      165.5097             nan     0.0100   -0.1601
   160      162.7034             nan     0.0100   -0.1205
   180      159.6003             nan     0.0100    0.0058
   200      156.8620             nan     0.0100   -0.0908
   220      154.3206             nan     0.0100   -0.0375
   240      152.6223             nan     0.0100   -0.1254
   260      150.8800             nan     0.0100   -0.0781
   280      148.8557             nan     0.0100   -0.1505
   300      147.4509             nan     0.0100   -0.1389

- Fold05.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      204.1523             nan     0.0200    0.0373
     2      203.9531             nan     0.0200    0.1938
     3      203.7259             nan     0.0200   -0.0529
     4      203.6055             nan     0.0200    0.0289
     5      203.3668             nan     0.0200    0.0075
     6      203.1308             nan     0.0200    0.0506
     7      202.7951             nan     0.0200    0.1386
     8      202.5462             nan     0.0200   -0.1160
     9      202.3445             nan     0.0200   -0.0615
    10      202.0611             nan     0.0200    0.0198
    20      199.4363             nan     0.0200    0.0985
    40      194.6734             nan     0.0200   -0.1986
    60      191.6859             nan     0.0200   -0.0797
    80      188.7275             nan     0.0200    0.0618
   100      186.2335             nan     0.0200   -0.0901
   120      184.0135             nan     0.0200   -0.0301
   140      182.3518             nan     0.0200   -0.1069
   160      180.7923             nan     0.0200    0.0887
   180      179.5253             nan     0.0200   -0.1404
   200      178.3781             nan     0.0200   -0.1191
   220      177.3956             nan     0.0200   -0.0367
   240      176.4561             nan     0.0200    0.0657
   260      175.5266             nan     0.0200    0.0580
   280      174.9344             nan     0.0200   -0.1602
   300      174.1908             nan     0.0200   -0.2854

- Fold05.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      204.0762             nan     0.0200    0.2646
     2      203.3251             nan     0.0200    0.0363
     3      202.6954             nan     0.0200    0.1054
     4      202.0622             nan     0.0200    0.1221
     5      201.6062             nan     0.0200    0.2091
     6      200.7725             nan     0.0200    0.1152
     7      200.2378             nan     0.0200    0.0656
     8      200.0307             nan     0.0200   -0.1070
     9      199.5295             nan     0.0200    0.2046
    10      198.8991             nan     0.0200    0.1172
    20      194.0799             nan     0.0200    0.3229
    40      183.9009             nan     0.0200   -0.0743
    60      175.9225             nan     0.0200   -0.1056
    80      170.1680             nan     0.0200   -0.3850
   100      166.1152             nan     0.0200   -0.1077
   120      162.5372             nan     0.0200   -0.1164
   140      159.0656             nan     0.0200   -0.3041
   160      156.7594             nan     0.0200   -0.0805
   180      153.5947             nan     0.0200   -0.0445
   200      150.6353             nan     0.0200    0.1039
   220      148.7546             nan     0.0200   -0.2518
   240      146.4932             nan     0.0200   -0.0954
   260      144.8984             nan     0.0200   -0.3156
   280      142.9595             nan     0.0200   -0.1154
   300      141.3572             nan     0.0200   -0.1822

- Fold05.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      203.6021             nan     0.0200    0.6479
     2      202.7977             nan     0.0200    0.0306
     3      201.6617             nan     0.0200    0.4825
     4      200.9647             nan     0.0200    0.6801
     5      200.4901             nan     0.0200    0.1472
     6      199.8572             nan     0.0200    0.3303
     7      199.0063             nan     0.0200    0.5663
     8      198.2141             nan     0.0200    0.3640
     9      197.6998             nan     0.0200    0.4270
    10      197.0423             nan     0.0200    0.3229
    20      190.8358             nan     0.0200    0.2911
    40      180.3970             nan     0.0200   -0.0079
    60      173.8651             nan     0.0200   -0.3104
    80      167.0136             nan     0.0200   -0.2181
   100      161.3087             nan     0.0200   -0.2148
   120      156.3644             nan     0.0200   -0.2933
   140      151.6933             nan     0.0200   -0.2810
   160      146.7923             nan     0.0200   -0.1631
   180      143.1708             nan     0.0200   -0.3128
   200      139.5306             nan     0.0200   -0.4690
   220      136.3662             nan     0.0200   -0.2001
   240      133.6404             nan     0.0200   -0.2774
   260      130.7701             nan     0.0200   -0.4071
   280      127.9701             nan     0.0200   -0.2635
   300      125.8846             nan     0.0200   -0.2652

- Fold05.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      203.6742             nan     0.0500    0.1145
     2      202.9379             nan     0.0500    0.3496
     3      202.2554             nan     0.0500   -0.3485
     4      201.2462             nan     0.0500    0.1761
     5      200.7484             nan     0.0500   -0.1441
     6      199.8968             nan     0.0500   -0.9696
     7      199.0462             nan     0.0500    0.0519
     8      198.4348             nan     0.0500    0.1416
     9      197.8023             nan     0.0500   -0.2178
    10      197.4456             nan     0.0500   -0.1683
    20      192.6678             nan     0.0500   -0.1131
    40      186.1918             nan     0.0500   -0.3912
    60      181.3467             nan     0.0500   -1.2617
    80      179.1241             nan     0.0500   -0.1370
   100      176.7338             nan     0.0500    0.1627
   120      174.3310             nan     0.0500   -0.2531
   140      172.8897             nan     0.0500   -0.2059
   160      171.4331             nan     0.0500    0.0970
   180      170.6868             nan     0.0500   -0.4217
   200      169.5572             nan     0.0500   -0.2940
   220      168.4627             nan     0.0500   -1.3809
   240      167.3465             nan     0.0500   -0.1035
   260      166.3134             nan     0.0500   -0.1777
   280      165.5939             nan     0.0500   -0.4674
   300      164.8071             nan     0.0500   -0.4014

- Fold05.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.1750             nan     0.0500    0.9448
     2      200.6919             nan     0.0500    0.1005
     3      199.5504             nan     0.0500    0.9164
     4      198.5393             nan     0.0500    0.8288
     5      197.7214             nan     0.0500    0.1458
     6      195.9041             nan     0.0500   -0.1930
     7      194.4883             nan     0.0500    0.3045
     8      193.6445             nan     0.0500   -0.1579
     9      192.4844             nan     0.0500    0.7023
    10      191.1191             nan     0.0500    0.6861
    20      180.5901             nan     0.0500   -0.2629
    40      169.1441             nan     0.0500   -0.7377
    60      161.2714             nan     0.0500   -0.3023
    80      153.5428             nan     0.0500   -0.7686
   100      149.1656             nan     0.0500   -0.7973
   120      144.7811             nan     0.0500   -0.3226
   140      140.4628             nan     0.0500   -0.3236
   160      137.3996             nan     0.0500   -0.5675
   180      134.5913             nan     0.0500   -0.3647
   200      131.0905             nan     0.0500   -0.5096
   220      129.1678             nan     0.0500   -1.1791
   240      126.7755             nan     0.0500   -0.5804
   260      124.2134             nan     0.0500   -0.5275
   280      122.2353             nan     0.0500   -0.4862
   300      120.8707             nan     0.0500   -0.4655

- Fold05.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      202.5181             nan     0.0500    0.6172
     2      200.5721             nan     0.0500    2.0945
     3      198.2436             nan     0.0500   -0.2325
     4      196.7710             nan     0.0500    1.4031
     5      194.6683             nan     0.0500    1.2752
     6      192.5893             nan     0.0500    1.5798
     7      190.9972             nan     0.0500    0.5163
     8      188.1609             nan     0.0500   -0.4285
     9      186.7494             nan     0.0500    0.1731
    10      185.8248             nan     0.0500    0.0995
    20      173.4595             nan     0.0500    0.3739
    40      158.2727             nan     0.0500   -0.6395
    60      147.5674             nan     0.0500   -0.8539
    80      140.4389             nan     0.0500   -0.5089
   100      133.3065             nan     0.0500   -0.6100
   120      127.8461             nan     0.0500   -0.3301
   140      123.4007             nan     0.0500   -0.7349
   160      120.2256             nan     0.0500   -1.0034
   180      115.5189             nan     0.0500   -0.3772
   200      112.3892             nan     0.0500   -0.7913
   220      108.9227             nan     0.0500   -1.2763
   240      106.0455             nan     0.0500   -0.4113
   260      103.1689             nan     0.0500   -0.5709
   280      101.0098             nan     0.0500   -0.3121
   300       98.6346             nan     0.0500   -0.8824

- Fold05.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.7608             nan     0.0100    0.0597
     2      206.6232             nan     0.0100    0.0225
     3      206.4445             nan     0.0100    0.0847
     4      206.2999             nan     0.0100    0.0812
     5      206.1843             nan     0.0100   -0.0702
     6      206.0273             nan     0.0100    0.0720
     7      205.8612             nan     0.0100    0.0978
     8      205.7400             nan     0.0100    0.0507
     9      205.5786             nan     0.0100   -0.0056
    10      205.3977             nan     0.0100   -0.0503
    20      204.2520             nan     0.0100   -0.0951
    40      201.9296             nan     0.0100   -0.0062
    60      199.7324             nan     0.0100    0.0154
    80      197.8694             nan     0.0100   -0.0232
   100      196.1329             nan     0.0100    0.0712
   120      194.2842             nan     0.0100   -0.0489
   140      192.7875             nan     0.0100   -0.1164
   160      191.3754             nan     0.0100   -0.0378
   180      190.1519             nan     0.0100   -0.0172
   200      188.7743             nan     0.0100   -0.0235
   220      187.6053             nan     0.0100   -0.1041
   240      186.5609             nan     0.0100    0.0202
   260      185.6935             nan     0.0100   -0.0310
   280      184.8449             nan     0.0100   -0.0317
   300      184.0169             nan     0.0100   -0.0672

- Fold06.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.7262             nan     0.0100   -0.0201
     2      206.4813             nan     0.0100    0.2668
     3      206.1133             nan     0.0100    0.0864
     4      205.7743             nan     0.0100    0.1102
     5      205.4870             nan     0.0100    0.1184
     6      205.1971             nan     0.0100    0.2963
     7      204.7910             nan     0.0100    0.0686
     8      204.4695             nan     0.0100    0.1616
     9      204.1036             nan     0.0100    0.2150
    10      203.6389             nan     0.0100    0.2219
    20      200.6795             nan     0.0100    0.0072
    40      195.3543             nan     0.0100    0.0522
    60      190.7338             nan     0.0100   -0.0511
    80      186.3609             nan     0.0100    0.2667
   100      183.0840             nan     0.0100    0.0340
   120      179.6649             nan     0.0100   -0.0045
   140      176.6374             nan     0.0100   -0.0965
   160      174.2923             nan     0.0100   -0.1397
   180      171.9092             nan     0.0100   -0.0459
   200      169.7470             nan     0.0100   -0.1245
   220      167.9278             nan     0.0100   -0.0214
   240      165.8188             nan     0.0100   -0.1165
   260      163.7112             nan     0.0100    0.0369
   280      161.6628             nan     0.0100   -0.0932
   300      160.0903             nan     0.0100   -0.1732

- Fold06.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.6012             nan     0.0100    0.1502
     2      206.3423             nan     0.0100    0.0572
     3      205.8615             nan     0.0100    0.1718
     4      205.5511             nan     0.0100    0.2126
     5      205.1245             nan     0.0100    0.1734
     6      204.8338             nan     0.0100    0.2342
     7      204.4263             nan     0.0100    0.1257
     8      204.0491             nan     0.0100    0.1436
     9      203.7081             nan     0.0100    0.2959
    10      203.2449             nan     0.0100    0.0144
    20      199.4572             nan     0.0100    0.0958
    40      192.5866             nan     0.0100    0.0368
    60      187.0392             nan     0.0100    0.0600
    80      182.2908             nan     0.0100   -0.0093
   100      178.0496             nan     0.0100   -0.0063
   120      174.2509             nan     0.0100   -0.0136
   140      170.6440             nan     0.0100   -0.0984
   160      167.5593             nan     0.0100    0.0351
   180      164.8846             nan     0.0100   -0.0072
   200      161.8866             nan     0.0100   -0.0141
   220      159.2764             nan     0.0100   -0.1465
   240      156.6980             nan     0.0100   -0.1147
   260      154.6068             nan     0.0100   -0.0958
   280      152.4879             nan     0.0100   -0.0591
   300      150.1756             nan     0.0100   -0.2088

- Fold06.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.5789             nan     0.0200   -0.0187
     2      206.1992             nan     0.0200   -0.1168
     3      205.8675             nan     0.0200    0.0702
     4      205.7129             nan     0.0200    0.1013
     5      205.4260             nan     0.0200   -0.0488
     6      205.1626             nan     0.0200    0.1314
     7      204.8293             nan     0.0200    0.1810
     8      204.4538             nan     0.0200    0.1927
     9      204.0385             nan     0.0200    0.0303
    10      203.8130             nan     0.0200    0.1000
    20      201.6065             nan     0.0200    0.0717
    40      197.3273             nan     0.0200   -0.1453
    60      194.1069             nan     0.0200   -0.0308
    80      191.0248             nan     0.0200   -0.0210
   100      188.2945             nan     0.0200   -0.5515
   120      186.0917             nan     0.0200   -0.0043
   140      184.3180             nan     0.0200   -0.0085
   160      182.7031             nan     0.0200   -0.0551
   180      181.3180             nan     0.0200    0.0022
   200      180.0888             nan     0.0200   -0.0901
   220      179.1723             nan     0.0200   -0.1035
   240      178.2255             nan     0.0200   -0.2671
   260      177.3725             nan     0.0200   -0.1427
   280      176.4906             nan     0.0200   -0.0780
   300      175.7433             nan     0.0200   -0.0364

- Fold06.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.3217             nan     0.0200    0.0440
     2      205.9609             nan     0.0200    0.3820
     3      205.4615             nan     0.0200    0.1012
     4      204.9654             nan     0.0200    0.0553
     5      204.1845             nan     0.0200    0.5205
     6      203.5720             nan     0.0200    0.3682
     7      202.8979             nan     0.0200    0.5096
     8      202.2626             nan     0.0200    0.4967
     9      201.2364             nan     0.0200    0.6159
    10      200.4140             nan     0.0200   -0.1208
    20      195.5409             nan     0.0200    0.0406
    40      187.1770             nan     0.0200   -0.1518
    60      179.7217             nan     0.0200    0.0797
    80      174.7003             nan     0.0200   -0.1367
   100      168.9584             nan     0.0200   -0.1087
   120      164.5959             nan     0.0200   -0.1144
   140      161.6597             nan     0.0200   -0.1121
   160      158.3116             nan     0.0200   -0.2002
   180      155.7480             nan     0.0200   -0.0960
   200      153.3839             nan     0.0200   -0.2024
   220      151.3845             nan     0.0200   -0.3032
   240      150.0393             nan     0.0200   -0.0644
   260      148.6289             nan     0.0200   -0.4375
   280      146.5560             nan     0.0200   -0.1955
   300      145.1818             nan     0.0200   -0.2189

- Fold06.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.1986             nan     0.0200    0.7639
     2      205.4495             nan     0.0200    0.6498
     3      204.7368             nan     0.0200    0.3422
     4      203.0722             nan     0.0200    0.2191
     5      202.4411             nan     0.0200    0.3396
     6      201.5524             nan     0.0200    0.3119
     7      201.0843             nan     0.0200    0.3291
     8      200.6226             nan     0.0200    0.0944
     9      199.9849             nan     0.0200    0.4325
    10      199.3803             nan     0.0200    0.1539
    20      192.7111             nan     0.0200    0.3930
    40      181.8149             nan     0.0200    0.0154
    60      174.3261             nan     0.0200   -0.0843
    80      167.5423             nan     0.0200   -0.2787
   100      161.5740             nan     0.0200   -0.3407
   120      156.1208             nan     0.0200   -0.0629
   140      150.7010             nan     0.0200   -0.0910
   160      147.3786             nan     0.0200   -0.2070
   180      142.6694             nan     0.0200   -0.2914
   200      139.6157             nan     0.0200   -0.3466
   220      136.5889             nan     0.0200   -0.2755
   240      133.9429             nan     0.0200   -0.2426
   260      131.8681             nan     0.0200   -0.2863
   280      129.5829             nan     0.0200   -0.2886
   300      127.5765             nan     0.0200   -0.2512

- Fold06.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.3802             nan     0.0500    0.2785
     2      205.3690             nan     0.0500   -0.4077
     3      204.6702             nan     0.0500   -0.2993
     4      204.1627             nan     0.0500    0.4550
     5      203.7251             nan     0.0500    0.3868
     6      203.1356             nan     0.0500   -0.0644
     7      202.6195             nan     0.0500   -0.3410
     8      202.2309             nan     0.0500    0.0260
     9      201.7168             nan     0.0500    0.1230
    10      201.1849             nan     0.0500    0.4650
    20      196.0750             nan     0.0500    0.2632
    40      189.2351             nan     0.0500    0.2219
    60      183.8936             nan     0.0500    0.0202
    80      180.1263             nan     0.0500   -0.1964
   100      177.4842             nan     0.0500   -0.6179
   120      175.7284             nan     0.0500   -0.4331
   140      173.8600             nan     0.0500   -0.5004
   160      172.5598             nan     0.0500   -0.2807
   180      171.3419             nan     0.0500   -0.2909
   200      170.9642             nan     0.0500   -0.5570
   220      169.9447             nan     0.0500    0.0626
   240      169.0121             nan     0.0500   -0.2730
   260      167.7392             nan     0.0500    0.0496
   280      167.4539             nan     0.0500   -0.4559
   300      167.1929             nan     0.0500   -0.5775

- Fold06.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      204.9983             nan     0.0500    1.5489
     2      203.2587             nan     0.0500    1.4593
     3      201.6963             nan     0.0500    0.8194
     4      199.7705             nan     0.0500    1.1666
     5      198.1566             nan     0.0500    1.0860
     6      196.8807             nan     0.0500    0.4338
     7      195.5468             nan     0.0500    0.6230
     8      193.5651             nan     0.0500   -0.3386
     9      191.9113             nan     0.0500    0.2055
    10      190.3387             nan     0.0500    0.5212
    20      181.0115             nan     0.0500   -0.1813
    40      170.5748             nan     0.0500   -0.7628
    60      160.6928             nan     0.0500   -0.5024
    80      154.0836             nan     0.0500   -0.2297
   100      148.4960             nan     0.0500   -0.8239
   120      143.9818             nan     0.0500   -0.5199
   140      141.3943             nan     0.0500   -1.1360
   160      137.2782             nan     0.0500   -0.3135
   180      134.5659             nan     0.0500   -1.0992
   200      130.9009             nan     0.0500   -0.2763
   220      127.6390             nan     0.0500   -0.6293
   240      125.1672             nan     0.0500   -0.5869
   260      123.6500             nan     0.0500   -0.6483
   280      120.8009             nan     0.0500   -0.1203
   300      119.5653             nan     0.0500   -0.8134

- Fold06.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      204.5498             nan     0.0500    1.2387
     2      202.2424             nan     0.0500   -0.0603
     3      199.9839             nan     0.0500    0.0437
     4      198.4555             nan     0.0500    0.5493
     5      196.0136             nan     0.0500    0.9642
     6      193.9273             nan     0.0500    0.6733
     7      192.8241             nan     0.0500    0.9753
     8      191.5956             nan     0.0500    0.1848
     9      190.8330             nan     0.0500   -0.1985
    10      189.4020             nan     0.0500   -0.1330
    20      178.1055             nan     0.0500   -0.5860
    40      160.7437             nan     0.0500   -0.2941
    60      148.9290             nan     0.0500   -0.7162
    80      141.0563             nan     0.0500   -0.9398
   100      134.7247             nan     0.0500   -0.9508
   120      129.2553             nan     0.0500   -0.5325
   140      122.4650             nan     0.0500   -0.2440
   160      118.4682             nan     0.0500   -0.5193
   180      113.8272             nan     0.0500   -0.9828
   200      110.2783             nan     0.0500   -0.5574
   220      105.7230             nan     0.0500   -0.7615
   240      102.7277             nan     0.0500   -0.3627
   260      100.2467             nan     0.0500   -0.3859
   280       97.5540             nan     0.0500   -0.8944
   300       95.0733             nan     0.0500   -0.2241

- Fold06.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      208.4530             nan     0.0100   -0.0372
     2      208.2946             nan     0.0100    0.0484
     3      208.1131             nan     0.0100    0.0458
     4      207.9846             nan     0.0100    0.1010
     5      207.8202             nan     0.0100   -0.0920
     6      207.6453             nan     0.0100    0.0338
     7      207.5198             nan     0.0100    0.0647
     8      207.3730             nan     0.0100   -0.0611
     9      207.3036             nan     0.0100   -0.0108
    10      207.1600             nan     0.0100   -0.0845
    20      205.6451             nan     0.0100    0.0015
    40      202.9635             nan     0.0100    0.0136
    60      200.5626             nan     0.0100   -0.0374
    80      198.3035             nan     0.0100   -0.0519
   100      196.3075             nan     0.0100    0.0587
   120      194.3331             nan     0.0100   -0.0558
   140      192.6800             nan     0.0100    0.0745
   160      191.0037             nan     0.0100   -0.0673
   180      189.4992             nan     0.0100   -0.0014
   200      188.1259             nan     0.0100   -0.0710
   220      186.9480             nan     0.0100   -0.0600
   240      185.8115             nan     0.0100   -0.0213
   260      184.9546             nan     0.0100   -0.0806
   280      184.0655             nan     0.0100   -0.0619
   300      183.1444             nan     0.0100   -0.0474

- Fold07.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      208.2770             nan     0.0100    0.0506
     2      208.0088             nan     0.0100    0.0919
     3      207.6619             nan     0.0100    0.1760
     4      207.3560             nan     0.0100    0.0372
     5      207.0887             nan     0.0100    0.2535
     6      206.6067             nan     0.0100    0.2998
     7      206.2665             nan     0.0100    0.1523
     8      205.9771             nan     0.0100    0.1422
     9      205.5880             nan     0.0100    0.1499
    10      205.1823             nan     0.0100    0.2577
    20      201.5969             nan     0.0100    0.1303
    40      195.5075             nan     0.0100    0.0143
    60      190.5692             nan     0.0100    0.0570
    80      186.8139             nan     0.0100   -0.0217
   100      183.1569             nan     0.0100   -0.0492
   120      179.5538             nan     0.0100    0.0594
   140      176.8663             nan     0.0100   -0.1267
   160      174.7716             nan     0.0100   -0.0757
   180      171.7417             nan     0.0100   -0.0808
   200      169.0736             nan     0.0100   -0.0294
   220      166.8855             nan     0.0100   -0.0065
   240      164.7407             nan     0.0100   -0.1877
   260      162.8792             nan     0.0100   -0.0819
   280      161.1732             nan     0.0100   -0.0953
   300      159.4756             nan     0.0100   -0.0761

- Fold07.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      208.0063             nan     0.0100    0.1248
     2      207.4811             nan     0.0100    0.3218
     3      206.6650             nan     0.0100    0.1803
     4      206.5025             nan     0.0100   -0.0065
     5      205.9610             nan     0.0100    0.2314
     6      205.3998             nan     0.0100    0.0666
     7      205.1140             nan     0.0100    0.1785
     8      204.6522             nan     0.0100   -0.0777
     9      204.1370             nan     0.0100    0.2386
    10      203.6683             nan     0.0100    0.0263
    20      199.2372             nan     0.0100    0.2171
    40      191.5171             nan     0.0100   -0.0095
    60      186.2801             nan     0.0100    0.1126
    80      181.1175             nan     0.0100    0.1277
   100      176.6839             nan     0.0100    0.0131
   120      172.3977             nan     0.0100   -0.0471
   140      169.1274             nan     0.0100   -0.1443
   160      165.5180             nan     0.0100   -0.0408
   180      163.0039             nan     0.0100   -0.2839
   200      160.3284             nan     0.0100    0.0139
   220      157.6065             nan     0.0100   -0.1756
   240      155.2884             nan     0.0100   -0.0197
   260      152.8948             nan     0.0100   -0.0704
   280      151.3041             nan     0.0100   -0.0353
   300      149.3566             nan     0.0100   -0.0916

- Fold07.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      208.3163             nan     0.0200    0.2116
     2      207.9446             nan     0.0200   -0.1666
     3      207.5953             nan     0.0200   -0.1363
     4      207.3496             nan     0.0200    0.0382
     5      206.9646             nan     0.0200    0.1932
     6      206.5365             nan     0.0200    0.1156
     7      206.1311             nan     0.0200    0.1941
     8      205.8074             nan     0.0200    0.0330
     9      205.4874             nan     0.0200    0.1089
    10      205.0539             nan     0.0200    0.0631
    20      202.1559             nan     0.0200   -0.0698
    40      198.0033             nan     0.0200    0.0123
    60      194.2493             nan     0.0200    0.0382
    80      191.2760             nan     0.0200    0.1100
   100      188.5873             nan     0.0200   -0.1134
   120      186.5158             nan     0.0200   -0.0487
   140      184.2218             nan     0.0200   -0.0207
   160      182.7445             nan     0.0200   -0.0071
   180      181.2542             nan     0.0200   -0.1706
   200      179.7096             nan     0.0200   -0.1869
   220      178.6033             nan     0.0200   -0.0767
   240      177.5734             nan     0.0200   -0.1931
   260      176.5903             nan     0.0200   -0.1163
   280      175.7321             nan     0.0200   -0.0531
   300      174.8157             nan     0.0200    0.0373

- Fold07.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      207.6896             nan     0.0200    0.5773
     2      206.8540             nan     0.0200    0.0928
     3      205.9781             nan     0.0200    0.5463
     4      205.0171             nan     0.0200    0.5223
     5      204.3071             nan     0.0200    0.0196
     6      203.3373             nan     0.0200    0.3023
     7      202.7250             nan     0.0200    0.4541
     8      202.2702             nan     0.0200    0.0121
     9      201.6960             nan     0.0200    0.2627
    10      200.9564             nan     0.0200    0.3699
    20      195.4404             nan     0.0200    0.3279
    40      186.2303             nan     0.0200    0.1110
    60      178.0685             nan     0.0200   -0.1670
    80      171.7686             nan     0.0200   -0.2910
   100      166.7864             nan     0.0200   -0.2478
   120      163.2455             nan     0.0200   -0.0710
   140      160.3952             nan     0.0200   -0.1500
   160      156.7974             nan     0.0200   -0.1414
   180      154.0520             nan     0.0200   -0.0695
   200      151.4087             nan     0.0200   -0.2234
   220      148.4560             nan     0.0200   -0.0782
   240      146.5950             nan     0.0200   -0.2082
   260      144.9748             nan     0.0200   -0.1109
   280      143.2171             nan     0.0200   -0.1923
   300      141.7568             nan     0.0200   -0.0845

- Fold07.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      207.8309             nan     0.0200   -0.0573
     2      206.4960             nan     0.0200    0.4715
     3      205.7147             nan     0.0200    0.6919
     4      204.4961             nan     0.0200    0.6542
     5      203.7319             nan     0.0200    0.6148
     6      202.7602             nan     0.0200    0.4192
     7      201.6873             nan     0.0200    0.3348
     8      200.9633             nan     0.0200    0.1630
     9      200.0806             nan     0.0200    0.4823
    10      199.0473             nan     0.0200    0.3741
    20      192.5635             nan     0.0200   -0.3982
    40      181.3564             nan     0.0200   -0.3694
    60      174.1509             nan     0.0200   -0.0731
    80      166.6453             nan     0.0200   -0.1322
   100      161.7182             nan     0.0200   -0.2351
   120      155.9126             nan     0.0200   -0.2784
   140      151.9827             nan     0.0200   -0.1860
   160      148.3099             nan     0.0200   -0.3618
   180      144.7068             nan     0.0200   -0.1638
   200      141.1254             nan     0.0200   -0.1171
   220      138.0296             nan     0.0200   -0.1635
   240      135.2382             nan     0.0200   -0.2428
   260      132.5616             nan     0.0200   -0.0654
   280      130.2885             nan     0.0200   -0.3753
   300      127.9562             nan     0.0200   -0.2594

- Fold07.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      207.8319             nan     0.0500   -0.2184
     2      207.1084             nan     0.0500    0.1743
     3      206.7397             nan     0.0500   -0.1155
     4      205.9443             nan     0.0500   -0.2095
     5      204.9842             nan     0.0500    0.0971
     6      203.9471             nan     0.0500    0.2704
     7      203.1362             nan     0.0500    0.3017
     8      202.5532             nan     0.0500    0.2232
     9      201.8724             nan     0.0500    0.4197
    10      201.3452             nan     0.0500   -0.2372
    20      196.2810             nan     0.0500    0.4401
    40      188.5951             nan     0.0500   -0.2903
    60      183.7976             nan     0.0500   -0.0754
    80      180.6525             nan     0.0500   -0.4506
   100      177.8200             nan     0.0500   -0.5368
   120      175.2483             nan     0.0500   -0.1913
   140      173.8530             nan     0.0500   -0.6177
   160      172.2412             nan     0.0500   -0.5198
   180      170.8836             nan     0.0500   -0.3088
   200      169.8288             nan     0.0500   -0.1236
   220      168.5845             nan     0.0500    0.1262
   240      168.0391             nan     0.0500   -0.2732
   260      167.7693             nan     0.0500   -0.2680
   280      167.1611             nan     0.0500   -0.2641
   300      166.7862             nan     0.0500   -0.3067

- Fold07.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.9482             nan     0.0500    0.6060
     2      204.9250             nan     0.0500    0.1877
     3      203.0806             nan     0.0500    1.1859
     4      201.0089             nan     0.0500    1.4233
     5      199.5646             nan     0.0500    0.1079
     6      198.2679             nan     0.0500   -0.1132
     7      197.1346             nan     0.0500    0.5169
     8      195.3578             nan     0.0500    0.4673
     9      194.1044             nan     0.0500    0.1021
    10      192.5057             nan     0.0500   -0.2634
    20      181.1248             nan     0.0500   -0.4919
    40      168.2016             nan     0.0500   -0.5648
    60      158.4011             nan     0.0500   -0.6041
    80      151.9199             nan     0.0500   -0.9353
   100      145.5752             nan     0.0500   -0.5964
   120      141.2798             nan     0.0500   -0.5285
   140      137.0181             nan     0.0500   -0.7582
   160      133.3702             nan     0.0500   -0.6633
   180      130.6793             nan     0.0500   -0.7227
   200      127.8504             nan     0.0500   -0.5889
   220      126.0643             nan     0.0500   -0.2063
   240      123.3133             nan     0.0500   -0.9212
   260      121.4229             nan     0.0500   -0.3743
   280      119.2268             nan     0.0500   -0.5186
   300      117.6699             nan     0.0500   -0.5823

- Fold07.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 17: Reason.for.absence17 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      206.0803             nan     0.0500    0.4463
     2      203.4595             nan     0.0500    0.3927
     3      200.8506             nan     0.0500    0.5745
     4      199.3668             nan     0.0500    0.2768
     5      197.2716             nan     0.0500   -0.0330
     6      196.0280             nan     0.0500    0.2314
     7      193.5814             nan     0.0500    0.8107
     8      192.1600             nan     0.0500    0.8849
     9      190.8052             nan     0.0500    0.4595
    10      189.0552             nan     0.0500    0.7928
    20      175.0146             nan     0.0500   -0.7429
    40      160.6017             nan     0.0500   -0.4986
    60      149.9345             nan     0.0500    0.0081
    80      140.4277             nan     0.0500   -0.7156
   100      132.0633             nan     0.0500   -1.0576
   120      127.2808             nan     0.0500   -0.7651
   140      121.6543             nan     0.0500   -1.0821
   160      118.3166             nan     0.0500   -0.7794
   180      113.5932             nan     0.0500   -0.5347
   200      110.8564             nan     0.0500   -0.8285
   220      107.4534             nan     0.0500   -0.9735
   240      104.5721             nan     0.0500   -0.5818
   260      101.9929             nan     0.0500   -0.5184
   280       99.5531             nan     0.0500   -0.5467
   300       97.2139             nan     0.0500   -0.4840

- Fold07.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.7084             nan     0.0100    0.0878
     2      157.5550             nan     0.0100    0.1264
     3      157.3769             nan     0.0100    0.0859
     4      157.1612             nan     0.0100    0.1111
     5      157.0315             nan     0.0100    0.0484
     6      156.9775             nan     0.0100   -0.0075
     7      156.8966             nan     0.0100    0.0469
     8      156.7525             nan     0.0100    0.0873
     9      156.6495             nan     0.0100    0.0233
    10      156.4991             nan     0.0100    0.0874
    20      155.2934             nan     0.0100    0.0847
    40      152.9247             nan     0.0100    0.0611
    60      150.8646             nan     0.0100   -0.1276
    80      149.1244             nan     0.0100   -0.0274
   100      147.7188             nan     0.0100    0.0291
   120      146.1820             nan     0.0100   -0.0121
   140      145.0334             nan     0.0100   -0.0326
   160      143.7689             nan     0.0100   -0.0542
   180      142.7756             nan     0.0100   -0.0784
   200      141.7837             nan     0.0100   -0.0815
   220      140.8482             nan     0.0100   -0.0428
   240      140.0597             nan     0.0100   -0.0100
   260      139.4206             nan     0.0100   -0.1148
   280      138.8442             nan     0.0100    0.0065
   300      138.2071             nan     0.0100    0.0179

- Fold08.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.5694             nan     0.0100    0.1910
     2      157.2737             nan     0.0100    0.1743
     3      156.8727             nan     0.0100    0.0371
     4      156.4050             nan     0.0100    0.1625
     5      156.1455             nan     0.0100    0.1949
     6      155.9079             nan     0.0100    0.0166
     7      155.6425             nan     0.0100    0.2687
     8      155.1958             nan     0.0100    0.0210
     9      154.9562             nan     0.0100    0.1119
    10      154.6095             nan     0.0100   -0.0491
    20      152.1035             nan     0.0100    0.1282
    40      147.5966             nan     0.0100    0.0728
    60      143.6617             nan     0.0100   -0.0418
    80      140.4163             nan     0.0100   -0.0393
   100      137.6501             nan     0.0100   -0.1040
   120      134.5966             nan     0.0100    0.0355
   140      132.3747             nan     0.0100    0.0389
   160      130.3867             nan     0.0100   -0.0000
   180      128.5816             nan     0.0100   -0.1281
   200      126.9323             nan     0.0100   -0.0651
   220      125.4018             nan     0.0100   -0.1219
   240      123.9738             nan     0.0100   -0.0832
   260      122.6093             nan     0.0100    0.0354
   280      121.4557             nan     0.0100   -0.1304
   300      120.0212             nan     0.0100   -0.0658

- Fold08.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.4956             nan     0.0100    0.3198
     2      156.8945             nan     0.0100    0.2577
     3      156.5735             nan     0.0100    0.2394
     4      156.0698             nan     0.0100    0.2773
     5      155.6642             nan     0.0100    0.2482
     6      155.3653             nan     0.0100    0.2538
     7      155.1545             nan     0.0100    0.1349
     8      154.7940             nan     0.0100    0.2560
     9      154.4529             nan     0.0100    0.2817
    10      154.0788             nan     0.0100    0.2295
    20      150.5643             nan     0.0100    0.1099
    40      145.5000             nan     0.0100   -0.0170
    60      140.5749             nan     0.0100   -0.0391
    80      136.6570             nan     0.0100   -0.0771
   100      133.3169             nan     0.0100    0.0534
   120      130.6001             nan     0.0100   -0.0486
   140      128.2144             nan     0.0100   -0.0047
   160      125.2689             nan     0.0100    0.1288
   180      123.1536             nan     0.0100    0.0278
   200      121.0353             nan     0.0100   -0.0118
   220      119.2055             nan     0.0100   -0.0199
   240      117.5232             nan     0.0100   -0.1356
   260      115.7360             nan     0.0100   -0.0903
   280      114.1954             nan     0.0100   -0.0516
   300      112.6944             nan     0.0100   -0.0731

- Fold08.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.5798             nan     0.0200    0.1116
     2      157.3121             nan     0.0200   -0.1856
     3      156.9559             nan     0.0200    0.2640
     4      156.5781             nan     0.0200    0.2146
     5      156.2829             nan     0.0200    0.1176
     6      156.0979             nan     0.0200   -0.0565
     7      155.9838             nan     0.0200   -0.0637
     8      155.7941             nan     0.0200    0.1382
     9      155.4547             nan     0.0200    0.1424
    10      155.3065             nan     0.0200   -0.0927
    20      152.9300             nan     0.0200    0.1512
    40      148.9544             nan     0.0200   -0.0402
    60      146.1031             nan     0.0200    0.0071
    80      144.0256             nan     0.0200   -0.0729
   100      141.9835             nan     0.0200   -0.0440
   120      140.4112             nan     0.0200   -0.1267
   140      138.9635             nan     0.0200   -0.0209
   160      137.6058             nan     0.0200   -0.0194
   180      136.4792             nan     0.0200   -0.1538
   200      135.6539             nan     0.0200   -0.1148
   220      134.7478             nan     0.0200   -0.0468
   240      134.0417             nan     0.0200   -0.1295
   260      133.2865             nan     0.0200   -0.0344
   280      132.5834             nan     0.0200    0.0116
   300      132.0136             nan     0.0200   -0.2505

- Fold08.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.1976             nan     0.0200    0.1091
     2      156.5868             nan     0.0200    0.5935
     3      156.2177             nan     0.0200    0.3281
     4      155.6292             nan     0.0200    0.0547
     5      154.9662             nan     0.0200    0.2184
     6      154.5528             nan     0.0200    0.0506
     7      153.8866             nan     0.0200    0.2439
     8      153.5236             nan     0.0200    0.2046
     9      153.2512             nan     0.0200   -0.1363
    10      152.5829             nan     0.0200    0.4634
    20      147.5838             nan     0.0200    0.3535
    40      140.8954             nan     0.0200   -0.1828
    60      135.5527             nan     0.0200    0.0447
    80      130.5312             nan     0.0200    0.0044
   100      126.9862             nan     0.0200   -0.0564
   120      124.3307             nan     0.0200    0.0333
   140      121.5259             nan     0.0200   -0.0871
   160      119.1813             nan     0.0200   -0.0698
   180      117.4763             nan     0.0200   -0.0513
   200      115.3580             nan     0.0200   -0.0742
   220      113.6401             nan     0.0200   -0.2540
   240      112.1332             nan     0.0200   -0.2009
   260      110.5764             nan     0.0200   -0.1886
   280      109.0028             nan     0.0200   -0.1259
   300      107.2780             nan     0.0200   -0.2060

- Fold08.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.1357             nan     0.0200    0.5842
     2      156.1616             nan     0.0200    0.6394
     3      155.8153             nan     0.0200    0.2135
     4      155.2288             nan     0.0200    0.4396
     5      154.7651             nan     0.0200    0.0451
     6      154.0680             nan     0.0200    0.3879
     7      153.1615             nan     0.0200    0.4878
     8      152.8326             nan     0.0200    0.1619
     9      152.0259             nan     0.0200    0.1016
    10      151.4257             nan     0.0200   -0.1376
    20      145.3320             nan     0.0200    0.0388
    40      135.9797             nan     0.0200   -0.0366
    60      130.3572             nan     0.0200   -0.0360
    80      124.7145             nan     0.0200   -0.2310
   100      120.7418             nan     0.0200   -0.1114
   120      117.4076             nan     0.0200   -0.2500
   140      113.5965             nan     0.0200   -0.2464
   160      111.4631             nan     0.0200   -0.2486
   180      108.8060             nan     0.0200   -0.0707
   200      106.3486             nan     0.0200   -0.1437
   220      104.3544             nan     0.0200   -0.2967
   240      102.1436             nan     0.0200   -0.2220
   260      100.2370             nan     0.0200   -0.2405
   280       98.3472             nan     0.0200   -0.0614
   300       97.0608             nan     0.0200   -0.2461

- Fold08.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      157.2176             nan     0.0500    0.1066
     2      156.4920             nan     0.0500    0.3898
     3      155.4218             nan     0.0500    0.4039
     4      154.7665             nan     0.0500    0.5627
     5      154.6095             nan     0.0500   -0.0920
     6      153.8508             nan     0.0500    0.0442
     7      153.1776             nan     0.0500   -0.3355
     8      152.7278             nan     0.0500    0.2385
     9      152.3170             nan     0.0500    0.2816
    10      151.5661             nan     0.0500   -0.8051
    20      146.9530             nan     0.0500    0.1920
    40      141.4265             nan     0.0500   -0.0062
    60      138.2710             nan     0.0500   -0.2252
    80      136.0593             nan     0.0500   -0.0706
   100      133.4173             nan     0.0500   -0.2542
   120      131.4118             nan     0.0500   -0.1555
   140      129.9557             nan     0.0500   -0.2302
   160      129.0201             nan     0.0500   -0.7148
   180      128.1056             nan     0.0500   -0.2693
   200      127.2417             nan     0.0500   -0.0150
   220      126.4786             nan     0.0500   -0.1836
   240      125.5560             nan     0.0500   -0.1324
   260      124.5724             nan     0.0500   -0.1112
   280      123.9019             nan     0.0500   -0.6023
   300      123.3554             nan     0.0500   -0.3002

- Fold08.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      156.8680             nan     0.0500    0.2566
     2      155.6852             nan     0.0500    0.4917
     3      154.2478             nan     0.0500    0.7528
     4      152.9230             nan     0.0500    0.0842
     5      152.1187             nan     0.0500    0.7343
     6      150.5706             nan     0.0500    0.9363
     7      148.8252             nan     0.0500    0.1806
     8      147.1335             nan     0.0500    0.5359
     9      146.3952             nan     0.0500    0.3302
    10      144.8152             nan     0.0500   -0.1548
    20      138.5715             nan     0.0500   -0.1799
    40      128.7001             nan     0.0500    0.2283
    60      122.1036             nan     0.0500   -0.3647
    80      116.6595             nan     0.0500   -0.3650
   100      111.9893             nan     0.0500   -0.3794
   120      108.8895             nan     0.0500   -0.4819
   140      106.3303             nan     0.0500   -0.3213
   160      103.9071             nan     0.0500   -0.4271
   180      100.2121             nan     0.0500   -0.5696
   200       98.4070             nan     0.0500   -0.5350
   220       96.4047             nan     0.0500   -0.2684
   240       94.6546             nan     0.0500   -0.1151
   260       92.8661             nan     0.0500   -0.3774
   280       91.3904             nan     0.0500   -0.4008
   300       90.1278             nan     0.0500   -0.5773

- Fold08.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 4: Reason.for.absence4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      155.6910             nan     0.0500    1.4003
     2      154.7802             nan     0.0500    0.4436
     3      153.3894             nan     0.0500   -0.2289
     4      152.0710             nan     0.0500    0.5121
     5      150.5249             nan     0.0500    0.9470
     6      149.6893             nan     0.0500    0.1871
     7      147.9556             nan     0.0500    0.7965
     8      146.9591             nan     0.0500    0.2214
     9      145.9794             nan     0.0500    0.7576
    10      144.9854             nan     0.0500    0.4183
    20      137.3322             nan     0.0500   -0.2087
    40      122.6673             nan     0.0500    0.0916
    60      114.8128             nan     0.0500   -0.3360
    80      108.6003             nan     0.0500   -0.1898
   100      104.4010             nan     0.0500   -0.1373
   120       99.1097             nan     0.0500   -0.6080
   140       95.3936             nan     0.0500   -0.2957
   160       91.3316             nan     0.0500   -1.3393
   180       88.4388             nan     0.0500   -0.2733
   200       85.9223             nan     0.0500   -0.8197
   220       83.1334             nan     0.0500   -0.3878
   240       81.0495             nan     0.0500   -0.3255
   260       79.3696             nan     0.0500   -0.3466
   280       77.9302             nan     0.0500   -0.6720
   300       76.0073             nan     0.0500   -0.7838

- Fold08.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      171.3102             nan     0.0100    0.0559
     2      171.2440             nan     0.0100   -0.0218
     3      171.0613             nan     0.0100    0.0041
     4      170.9953             nan     0.0100   -0.0792
     5      170.8117             nan     0.0100    0.0042
     6      170.6611             nan     0.0100    0.0791
     7      170.4739             nan     0.0100   -0.0431
     8      170.3374             nan     0.0100    0.0876
     9      170.2671             nan     0.0100   -0.0762
    10      170.1046             nan     0.0100    0.0249
    20      169.0716             nan     0.0100   -0.0664
    40      167.0054             nan     0.0100    0.0870
    60      165.4980             nan     0.0100    0.0665
    80      163.7657             nan     0.0100    0.0274
   100      162.3505             nan     0.0100    0.0604
   120      161.1198             nan     0.0100   -0.0668
   140      159.8832             nan     0.0100   -0.0204
   160      158.7890             nan     0.0100   -0.0302
   180      157.7421             nan     0.0100   -0.0278
   200      156.8110             nan     0.0100    0.0085
   220      155.9436             nan     0.0100    0.0006
   240      154.9931             nan     0.0100   -0.0435
   260      154.1843             nan     0.0100   -0.0105
   280      153.5360             nan     0.0100   -0.0994
   300      152.7149             nan     0.0100    0.0244

- Fold09.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      171.0614             nan     0.0100    0.1394
     2      170.6981             nan     0.0100    0.0655
     3      170.4940             nan     0.0100    0.0947
     4      169.9636             nan     0.0100    0.0707
     5      169.6731             nan     0.0100    0.0492
     6      169.4075             nan     0.0100    0.1300
     7      169.1517             nan     0.0100    0.1159
     8      168.9063             nan     0.0100    0.1275
     9      168.5463             nan     0.0100    0.0632
    10      168.0462             nan     0.0100    0.0007
    20      165.8387             nan     0.0100    0.0817
    40      161.1851             nan     0.0100    0.0703
    60      157.1062             nan     0.0100   -0.0181
    80      153.4633             nan     0.0100    0.0025
   100      149.6933             nan     0.0100    0.0477
   120      146.6891             nan     0.0100    0.0095
   140      144.0313             nan     0.0100   -0.0582
   160      141.5937             nan     0.0100    0.0452
   180      139.9631             nan     0.0100   -0.1249
   200      138.0663             nan     0.0100   -0.0045
   220      136.2684             nan     0.0100    0.0028
   240      134.3487             nan     0.0100    0.0054
   260      132.7943             nan     0.0100   -0.0595
   280      131.3076             nan     0.0100   -0.1126
   300      129.8891             nan     0.0100    0.0044

- Fold09.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      170.9009             nan     0.0100    0.1666
     2      170.6621             nan     0.0100    0.1478
     3      170.2543             nan     0.0100    0.1491
     4      169.6651             nan     0.0100    0.1507
     5      169.2969             nan     0.0100    0.1774
     6      168.9380             nan     0.0100    0.2248
     7      168.7314             nan     0.0100    0.1075
     8      168.1624             nan     0.0100    0.4195
     9      167.7738             nan     0.0100    0.0699
    10      167.3640             nan     0.0100    0.2993
    20      163.8101             nan     0.0100    0.1417
    40      158.2664             nan     0.0100    0.1116
    60      153.7830             nan     0.0100    0.0860
    80      149.3278             nan     0.0100   -0.0756
   100      145.6255             nan     0.0100    0.0296
   120      142.4210             nan     0.0100   -0.0473
   140      139.0984             nan     0.0100   -0.0701
   160      136.2656             nan     0.0100   -0.1509
   180      133.7079             nan     0.0100   -0.0127
   200      131.4650             nan     0.0100   -0.1146
   220      129.3150             nan     0.0100   -0.0885
   240      127.7562             nan     0.0100   -0.1188
   260      125.9050             nan     0.0100   -0.0433
   280      124.0227             nan     0.0100   -0.0503
   300      122.4591             nan     0.0100   -0.0882

- Fold09.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      171.0853             nan     0.0200    0.1707
     2      170.9508             nan     0.0200   -0.0873
     3      170.6105             nan     0.0200    0.0217
     4      170.3441             nan     0.0200    0.0415
     5      170.2061             nan     0.0200    0.0760
     6      170.0325             nan     0.0200   -0.0180
     7      169.8434             nan     0.0200    0.1302
     8      169.6683             nan     0.0200   -0.1356
     9      169.5288             nan     0.0200    0.0190
    10      169.2587             nan     0.0200    0.0654
    20      167.2130             nan     0.0200    0.0137
    40      163.9500             nan     0.0200    0.0264
    60      161.2722             nan     0.0200   -0.0512
    80      158.9385             nan     0.0200    0.0150
   100      156.7926             nan     0.0200    0.0407
   120      155.1505             nan     0.0200   -0.1318
   140      153.6274             nan     0.0200   -0.0339
   160      152.4083             nan     0.0200   -0.0472
   180      151.0241             nan     0.0200    0.0732
   200      149.8640             nan     0.0200   -0.0521
   220      148.8147             nan     0.0200   -0.0508
   240      147.6323             nan     0.0200   -0.1790
   260      146.7324             nan     0.0200   -0.0344
   280      145.8743             nan     0.0200   -0.2643
   300      145.1207             nan     0.0200   -0.0857

- Fold09.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      170.7380             nan     0.0200    0.5373
     2      170.2574             nan     0.0200    0.3866
     3      169.2908             nan     0.0200    0.4304
     4      168.9860             nan     0.0200    0.1653
     5      168.3529             nan     0.0200    0.3735
     6      167.9947             nan     0.0200   -0.1758
     7      167.4094             nan     0.0200   -0.0009
     8      167.0192             nan     0.0200    0.2156
     9      166.4731             nan     0.0200    0.0642
    10      165.9692             nan     0.0200   -0.1552
    20      161.3242             nan     0.0200    0.1344
    40      153.8836             nan     0.0200   -0.1378
    60      147.2809             nan     0.0200   -0.0720
    80      142.2292             nan     0.0200   -0.1605
   100      137.9204             nan     0.0200   -0.1135
   120      134.4197             nan     0.0200   -0.1736
   140      131.4579             nan     0.0200   -0.0500
   160      129.1073             nan     0.0200   -0.1591
   180      126.2777             nan     0.0200    0.1180
   200      123.6932             nan     0.0200   -0.1676
   220      121.6222             nan     0.0200   -0.1340
   240      120.0506             nan     0.0200   -0.2553
   260      118.7624             nan     0.0200   -0.1306
   280      117.5120             nan     0.0200   -0.1518
   300      116.4519             nan     0.0200   -0.2498

- Fold09.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      170.7576             nan     0.0200    0.3947
     2      170.1529             nan     0.0200    0.5418
     3      169.4657             nan     0.0200    0.2415
     4      168.8179             nan     0.0200    0.4804
     5      167.7441             nan     0.0200    0.4400
     6      167.2378             nan     0.0200    0.4528
     7      166.6233             nan     0.0200    0.1923
     8      166.2612             nan     0.0200    0.1745
     9      165.5540             nan     0.0200    0.1830
    10      164.9266             nan     0.0200    0.2660
    20      159.1407             nan     0.0200    0.1188
    40      149.1050             nan     0.0200   -0.0295
    60      141.6085             nan     0.0200   -0.1235
    80      136.3666             nan     0.0200   -0.1375
   100      131.3021             nan     0.0200   -0.2571
   120      126.9850             nan     0.0200   -0.2266
   140      123.2536             nan     0.0200   -0.0083
   160      119.8658             nan     0.0200   -0.3292
   180      116.8342             nan     0.0200   -0.1519
   200      114.5353             nan     0.0200   -0.2083
   220      111.9401             nan     0.0200   -0.0186
   240      110.4053             nan     0.0200   -0.2920
   260      107.7240             nan     0.0200   -0.2421
   280      105.3857             nan     0.0200   -0.2540
   300      103.6350             nan     0.0200   -0.3488

- Fold09.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      170.5780             nan     0.0500    0.1765
     2      169.8944             nan     0.0500    0.0211
     3      168.9966             nan     0.0500    0.0665
     4      168.4328             nan     0.0500    0.1408
     5      168.2609             nan     0.0500   -0.2603
     6      167.8166             nan     0.0500    0.2866
     7      167.4113             nan     0.0500    0.3212
     8      166.8731             nan     0.0500   -0.1915
     9      166.6683             nan     0.0500   -0.0100
    10      166.0745             nan     0.0500    0.3678
    20      162.4940             nan     0.0500   -0.3850
    40      157.9380             nan     0.0500    0.0550
    60      153.4995             nan     0.0500   -0.0928
    80      150.4346             nan     0.0500   -0.0192
   100      148.0033             nan     0.0500   -0.2378
   120      146.1261             nan     0.0500   -0.0264
   140      144.9828             nan     0.0500   -0.2490
   160      143.4317             nan     0.0500   -0.3417
   180      142.4035             nan     0.0500   -0.1280
   200      141.3336             nan     0.0500    0.0843
   220      140.1265             nan     0.0500   -0.1102
   240      139.0968             nan     0.0500   -0.1210
   260      138.6857             nan     0.0500   -0.3813
   280      137.7294             nan     0.0500    0.0324
   300      137.1061             nan     0.0500   -0.2268

- Fold09.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      169.2730             nan     0.0500    0.3780
     2      167.8737             nan     0.0500    0.5825
     3      166.5843             nan     0.0500    0.1587
     4      165.9687             nan     0.0500   -0.0098
     5      165.0747             nan     0.0500   -0.3502
     6      163.5563             nan     0.0500   -0.4169
     7      162.2954             nan     0.0500    0.7611
     8      160.7626             nan     0.0500    0.1835
     9      159.6564             nan     0.0500   -0.5174
    10      158.7258             nan     0.0500   -0.5508
    20      150.8307             nan     0.0500   -0.0439
    40      138.3356             nan     0.0500   -0.1245
    60      131.0657             nan     0.0500   -0.3858
    80      126.4881             nan     0.0500   -0.5895
   100      121.3299             nan     0.0500   -0.0484
   120      118.4047             nan     0.0500   -0.5842
   140      114.2781             nan     0.0500   -0.4648
   160      111.1609             nan     0.0500   -0.2407
   180      108.7727             nan     0.0500   -0.6596
   200      106.5744             nan     0.0500   -0.1530
   220      104.9736             nan     0.0500   -0.2878
   240      103.3375             nan     0.0500   -0.3659
   260      101.6782             nan     0.0500   -0.3806
   280       99.7642             nan     0.0500   -0.4548
   300       98.3842             nan     0.0500   -0.3310

- Fold09.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      170.5471             nan     0.0500   -0.2679
     2      168.6051             nan     0.0500    1.5961
     3      167.5493             nan     0.0500    0.1838
     4      165.9704             nan     0.0500    0.8550
     5      163.8403             nan     0.0500    1.1075
     6      162.4433             nan     0.0500   -0.0933
     7      161.0287             nan     0.0500   -0.4764
     8      159.1596             nan     0.0500    0.0549
     9      158.1511             nan     0.0500    0.5101
    10      156.6741             nan     0.0500    0.8022
    20      146.8903             nan     0.0500   -0.1471
    40      131.3668             nan     0.0500   -0.3738
    60      121.3452             nan     0.0500   -0.3639
    80      113.7367             nan     0.0500   -0.6018
   100      107.7818             nan     0.0500   -0.7567
   120      102.9629             nan     0.0500    0.0774
   140       99.1834             nan     0.0500   -0.6062
   160       95.4485             nan     0.0500   -0.0516
   180       92.3550             nan     0.0500   -0.6858
   200       89.3852             nan     0.0500   -0.3806
   220       86.4836             nan     0.0500   -0.7167
   240       84.2393             nan     0.0500   -0.5146
   260       82.1920             nan     0.0500   -0.5999
   280       79.6877             nan     0.0500   -0.5817
   300       77.0944             nan     0.0500   -0.3633

- Fold09.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      199.8731             nan     0.0100   -0.0459
     2      199.7274             nan     0.0100   -0.0850
     3      199.5845             nan     0.0100    0.1314
     4      199.3672             nan     0.0100    0.0398
     5      199.1999             nan     0.0100   -0.0096
     6      199.0719             nan     0.0100    0.0894
     7      198.8891             nan     0.0100    0.1110
     8      198.7844             nan     0.0100    0.1152
     9      198.6197             nan     0.0100   -0.0927
    10      198.5176             nan     0.0100   -0.0299
    20      197.0173             nan     0.0100    0.0246
    40      194.4590             nan     0.0100    0.1226
    60      191.9821             nan     0.0100    0.0069
    80      189.8193             nan     0.0100    0.0660
   100      188.0226             nan     0.0100   -0.0053
   120      186.3728             nan     0.0100    0.0565
   140      184.5914             nan     0.0100   -0.0917
   160      182.9408             nan     0.0100   -0.0144
   180      181.4782             nan     0.0100   -0.0438
   200      180.0291             nan     0.0100   -0.0465
   220      178.9550             nan     0.0100   -0.0524
   240      177.7611             nan     0.0100   -0.0556
   260      176.6595             nan     0.0100   -0.0793
   280      175.5865             nan     0.0100   -0.0070
   300      174.5656             nan     0.0100    0.0278

- Fold10.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      199.5545             nan     0.0100    0.3779
     2      199.2282             nan     0.0100    0.1698
     3      198.8523             nan     0.0100   -0.0003
     4      198.5870             nan     0.0100   -0.0053
     5      198.1508             nan     0.0100    0.1657
     6      197.7004             nan     0.0100    0.1904
     7      197.4021             nan     0.0100    0.0542
     8      197.1324             nan     0.0100    0.1389
     9      196.8174             nan     0.0100    0.2577
    10      196.5750             nan     0.0100    0.0442
    20      192.8237             nan     0.0100    0.0538
    40      186.3325             nan     0.0100    0.0970
    60      181.0303             nan     0.0100    0.0442
    80      176.1789             nan     0.0100   -0.0483
   100      172.6557             nan     0.0100    0.0276
   120      169.2462             nan     0.0100    0.0686
   140      166.1536             nan     0.0100   -0.0030
   160      163.2194             nan     0.0100   -0.0649
   180      160.1888             nan     0.0100   -0.0152
   200      157.4511             nan     0.0100   -0.0971
   220      155.2724             nan     0.0100   -0.0191
   240      153.5000             nan     0.0100   -0.0979
   260      151.5206             nan     0.0100   -0.1023
   280      149.6433             nan     0.0100   -0.1705
   300      147.8192             nan     0.0100   -0.0246

- Fold10.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      199.2938             nan     0.0100    0.3145
     2      199.0574             nan     0.0100    0.2106
     3      198.7496             nan     0.0100    0.2875
     4      198.3544             nan     0.0100    0.4216
     5      197.7563             nan     0.0100   -0.0816
     6      197.3552             nan     0.0100   -0.0790
     7      196.5959             nan     0.0100    0.3745
     8      195.9248             nan     0.0100    0.0975
     9      195.6332             nan     0.0100    0.2418
    10      195.3209             nan     0.0100    0.1144
    20      190.8594             nan     0.0100    0.4511
    40      183.3756             nan     0.0100   -0.0201
    60      177.1329             nan     0.0100   -0.0584
    80      171.5533             nan     0.0100    0.1194
   100      167.5329             nan     0.0100    0.0493
   120      163.4993             nan     0.0100   -0.1021
   140      159.6754             nan     0.0100   -0.0174
   160      156.7631             nan     0.0100   -0.0354
   180      153.8100             nan     0.0100   -0.0340
   200      150.9869             nan     0.0100   -0.2028
   220      148.7372             nan     0.0100   -0.0863
   240      146.1177             nan     0.0100   -0.0801
   260      143.9339             nan     0.0100   -0.1048
   280      141.8314             nan     0.0100   -0.1132
   300      139.9453             nan     0.0100   -0.0942

- Fold10.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      199.7700             nan     0.0200   -0.0899
     2      199.5941             nan     0.0200   -0.0205
     3      199.4577             nan     0.0200   -0.0533
     4      199.0165             nan     0.0200    0.2018
     5      198.5248             nan     0.0200    0.1428
     6      198.2624             nan     0.0200    0.0957
     7      197.7555             nan     0.0200    0.1004
     8      197.5706             nan     0.0200    0.1299
     9      197.1414             nan     0.0200    0.2611
    10      196.9075             nan     0.0200    0.1278
    20      194.1782             nan     0.0200   -0.0719
    40      189.3770             nan     0.0200   -0.2445
    60      185.7046             nan     0.0200    0.0256
    80      182.4325             nan     0.0200   -0.0226
   100      179.7250             nan     0.0200    0.0211
   120      177.4382             nan     0.0200   -0.0162
   140      175.3935             nan     0.0200    0.0353
   160      173.4455             nan     0.0200   -0.0490
   180      172.1221             nan     0.0200   -0.0676
   200      170.7383             nan     0.0200   -0.1193
   220      169.5023             nan     0.0200   -0.0788
   240      168.4414             nan     0.0200   -0.1106
   260      167.4506             nan     0.0200   -0.0854
   280      166.5087             nan     0.0200   -0.0337
   300      165.7107             nan     0.0200   -0.1872

- Fold10.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      198.9552             nan     0.0200    0.9151
     2      197.9892             nan     0.0200    0.1002
     3      197.3436             nan     0.0200    0.1417
     4      196.5964             nan     0.0200    0.4484
     5      195.4504             nan     0.0200   -0.4183
     6      194.7659             nan     0.0200   -0.0219
     7      194.2432             nan     0.0200    0.4524
     8      193.7705             nan     0.0200    0.1445
     9      193.2352             nan     0.0200    0.3987
    10      191.9229             nan     0.0200   -0.3923
    20      185.4250             nan     0.0200   -0.1621
    40      177.1752             nan     0.0200    0.0596
    60      169.1324             nan     0.0200   -0.0396
    80      162.2050             nan     0.0200   -0.2389
   100      157.5706             nan     0.0200   -0.1344
   120      153.5815             nan     0.0200   -0.1857
   140      150.8385             nan     0.0200   -0.2335
   160      146.6825             nan     0.0200   -0.0571
   180      143.4324             nan     0.0200   -0.1053
   200      140.8491             nan     0.0200   -0.2233
   220      138.5472             nan     0.0200   -0.0976
   240      136.1600             nan     0.0200   -0.0428
   260      134.3140             nan     0.0200   -0.0045
   280      132.5026             nan     0.0200   -0.1334
   300      130.9713             nan     0.0200   -0.4561

- Fold10.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      199.3701             nan     0.0200    0.5827
     2      198.4010             nan     0.0200    0.6504
     3      197.4308             nan     0.0200    0.1694
     4      196.9180             nan     0.0200   -0.0693
     5      196.1968             nan     0.0200    0.1328
     6      195.1832             nan     0.0200    0.8578
     7      194.5795             nan     0.0200    0.0836
     8      194.0142             nan     0.0200    0.4006
     9      192.9798             nan     0.0200    0.3904
    10      192.2583             nan     0.0200    0.2078
    20      184.3496             nan     0.0200    0.0924
    40      172.0110             nan     0.0200    0.1336
    60      163.4217             nan     0.0200   -0.1164
    80      156.5565             nan     0.0200    0.0227
   100      151.4864             nan     0.0200   -0.1583
   120      145.9346             nan     0.0200   -0.1137
   140      142.2030             nan     0.0200   -0.2331
   160      138.7761             nan     0.0200    0.0598
   180      135.1602             nan     0.0200   -0.1385
   200      132.2010             nan     0.0200   -0.2427
   220      128.9881             nan     0.0200   -0.2821
   240      126.2549             nan     0.0200   -0.2423
   260      123.3886             nan     0.0200   -0.2534
   280      120.7551             nan     0.0200   -0.4218
   300      118.4569             nan     0.0200   -0.2729

- Fold10.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      199.3432             nan     0.0500    0.3384
     2      198.5535             nan     0.0500    0.2675
     3      197.7496             nan     0.0500    0.7090
     4      197.2382             nan     0.0500    0.0885
     5      196.3130             nan     0.0500    0.5945
     6      195.6155             nan     0.0500    0.5741
     7      195.0222             nan     0.0500    0.1232
     8      194.4228             nan     0.0500    0.3257
     9      193.7272             nan     0.0500    0.3759
    10      193.1967             nan     0.0500    0.5729
    20      188.0375             nan     0.0500   -0.2060
    40      179.9681             nan     0.0500   -0.2632
    60      174.8760             nan     0.0500   -0.1608
    80      171.6341             nan     0.0500   -0.5220
   100      168.4494             nan     0.0500   -0.1421
   120      166.3419             nan     0.0500   -0.2704
   140      164.5912             nan     0.0500   -0.1401
   160      162.3453             nan     0.0500   -0.2748
   180      161.4913             nan     0.0500   -0.2624
   200      160.1787             nan     0.0500   -0.3590
   220      158.7895             nan     0.0500   -0.2562
   240      157.7454             nan     0.0500   -0.3484
   260      157.0974             nan     0.0500   -0.0964
   280      156.4249             nan     0.0500   -0.1497
   300      155.6870             nan     0.0500   -0.3722

- Fold10.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      196.5810             nan     0.0500    0.1382
     2      195.3009             nan     0.0500   -0.1261
     3      193.4988             nan     0.0500    0.7011
     4      191.5607             nan     0.0500    1.0085
     5      189.7769             nan     0.0500    0.3319
     6      189.0602             nan     0.0500    0.6290
     7      187.5447             nan     0.0500    0.7058
     8      185.6300             nan     0.0500    0.7784
     9      184.0571             nan     0.0500    0.4986
    10      182.5482             nan     0.0500    0.7035
    20      172.4973             nan     0.0500   -0.1903
    40      159.8435             nan     0.0500   -0.3186
    60      150.6001             nan     0.0500   -0.6344
    80      144.2262             nan     0.0500   -0.5419
   100      138.5215             nan     0.0500   -0.5156
   120      133.5580             nan     0.0500   -0.3969
   140      129.2411             nan     0.0500   -0.1190
   160      125.6732             nan     0.0500   -0.1144
   180      122.0898             nan     0.0500   -0.7588
   200      119.2221             nan     0.0500   -0.6227
   220      116.6407             nan     0.0500   -0.8192
   240      113.3767             nan     0.0500   -0.2887
   260      110.7624             nan     0.0500   -0.4799
   280      108.9990             nan     0.0500   -0.6583
   300      107.1794             nan     0.0500   -0.7161

- Fold10.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 2: Reason.for.absence2 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      198.0252             nan     0.0500    1.4955
     2      195.7320             nan     0.0500    1.2453
     3      193.8961             nan     0.0500    0.7850
     4      192.9331             nan     0.0500    0.0675
     5      189.9217             nan     0.0500    1.2483
     6      188.3966             nan     0.0500    0.5344
     7      186.6145             nan     0.0500    1.4092
     8      184.3736             nan     0.0500    1.7472
     9      181.6454             nan     0.0500    0.9265
    10      180.4724             nan     0.0500    0.6193
    20      167.3526             nan     0.0500    0.3703
    40      154.2678             nan     0.0500   -0.3161
    60      143.7266             nan     0.0500   -0.3516
    80      132.7599             nan     0.0500   -0.0536
   100      124.3225             nan     0.0500   -0.6805
   120      119.4432             nan     0.0500   -0.7465
   140      112.4385             nan     0.0500   -1.0784
   160      107.0462             nan     0.0500   -0.2949
   180      102.2146             nan     0.0500   -0.8169
   200       98.0668             nan     0.0500   -0.6534
   220       95.1266             nan     0.0500   -0.3416
   240       91.6640             nan     0.0500   -0.3021
   260       88.6861             nan     0.0500   -0.3191
   280       86.3808             nan     0.0500   -0.5251
   300       83.7892             nan     0.0500   -0.8833

- Fold10.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Aggregating results
Selecting tuning parameters
Fitting n.trees = 100, interaction.depth = 5, shrinkage = 0.02, n.minobsinnode = 10 on full training set
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1      190.9389             nan     0.0200    0.5400
     2      190.1623             nan     0.0200    0.4314
     3      189.5059             nan     0.0200    0.4681
     4      188.8033             nan     0.0200    0.4956
     5      187.5160             nan     0.0200    0.3472
     6      186.6510             nan     0.0200    0.5704
     7      185.9245             nan     0.0200    0.4129
     8      185.4297             nan     0.0200    0.3280
     9      184.5076             nan     0.0200    0.4257
    10      183.9508             nan     0.0200    0.3143
    20      177.6355             nan     0.0200    0.2035
    40      166.7496             nan     0.0200   -0.0869
    60      158.3304             nan     0.0200   -0.1312
    80      151.8675             nan     0.0200   -0.1558
   100      147.2709             nan     0.0200   -0.2545

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
10.5981491040878
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[238]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">Model</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;Lasso Reg&quot;</span><span class="p">,</span> <span class="s">&quot;Decision Tree 1&quot;</span><span class="p">,</span><span class="s">&quot;Decision Tree 2&quot;</span><span class="p">,</span> <span class="s">&quot;Decision Tree 3&quot;</span><span class="p">,</span>
                <span class="s">&quot;Random Forest&quot;</span><span class="p">,</span> <span class="s">&quot;Gradient Boosting&quot;</span><span class="p">)</span>
<span class="n">RMSE_Value</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">lasso_error1</span><span class="p">,</span> <span class="n">dt_error1.1</span><span class="p">,</span> <span class="n">dt_error1.2</span><span class="p">,</span> <span class="n">dt_error1.3</span><span class="p">,</span> <span class="n">rf_error1</span><span class="p">,</span> <span class="n">sgb_error1</span><span class="p">)</span>

<span class="n">table1</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span><span class="n">RMSE_Value</span><span class="p">)</span>
<span class="n">table1</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>Model</th><th scope=col>RMSE_Value</th></tr></thead>
<tbody>
	<tr><td>Lasso Reg        </td><td>10.66077         </td></tr>
	<tr><td>Decision Tree 1  </td><td>11.52163         </td></tr>
	<tr><td>Decision Tree 2  </td><td>11.06996         </td></tr>
	<tr><td>Decision Tree 3  </td><td>10.40201         </td></tr>
	<tr><td>Random Forest    </td><td>10.39521         </td></tr>
	<tr><td>Gradient Boosting</td><td>10.59815         </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>According to RMSE values, for this data set random forest model is the best option, it has the smallest error.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Data-Set-2:-Online-News-Popularity">Data Set 2: Online News Popularity<a class="anchor-link" href="#Data-Set-2:-Online-News-Popularity">&#182;</a></h3>
<pre><code>1. timedelta:                     Days between the article publication and
                                   the dataset acquisition
 2. n_tokens_title:                Number of words in the title
 3. n_tokens_content:              Number of words in the content
 4. n_unique_tokens:               Rate of unique words in the content
 5. n_non_stop_words:              Rate of non-stop words in the content
 6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the
                                   content
 7. num_hrefs:                     Number of links
 8. num_self_hrefs:                Number of links to other articles
                                   published by Mashable
 9. num_imgs:                      Number of images
10. num_videos:                    Number of videos
11. average_token_length:          Average length of the words in the
                                   content
12. num_keywords:                  Number of keywords in the metadata
13. data_channel_is_lifestyle:     Is data channel 'Lifestyle'?
14. data_channel_is_entertainment: Is data channel 'Entertainment'?
15. data_channel_is_bus:           Is data channel 'Business'?
16. data_channel_is_socmed:        Is data channel 'Social Media'?
17. data_channel_is_tech:          Is data channel 'Tech'?
18. data_channel_is_world:         Is data channel 'World'?
19. kw_min_min:                    Worst keyword (min. shares)
20. kw_max_min:                    Worst keyword (max. shares)
21. kw_avg_min:                    Worst keyword (avg. shares)
22. kw_min_max:                    Best keyword (min. shares)
23. kw_max_max:                    Best keyword (max. shares)
24. kw_avg_max:                    Best keyword (avg. shares)
25. kw_min_avg:                    Avg. keyword (min. shares)
26. kw_max_avg:                    Avg. keyword (max. shares)
27. kw_avg_avg:                    Avg. keyword (avg. shares)
28. self_reference_min_shares:     Min. shares of referenced articles in
                                   Mashable
29. self_reference_max_shares:     Max. shares of referenced articles in
                                   Mashable
30. self_reference_avg_sharess:    Avg. shares of referenced articles in
                                   Mashable
31. weekday_is_monday:             Was the article published on a Monday?
32. weekday_is_tuesday:            Was the article published on a Tuesday?
33. weekday_is_wednesday:          Was the article published on a Wednesday?
34. weekday_is_thursday:           Was the article published on a Thursday?
35. weekday_is_friday:             Was the article published on a Friday?
36. weekday_is_saturday:           Was the article published on a Saturday?
37. weekday_is_sunday:             Was the article published on a Sunday?
38. is_weekend:                    Was the article published on the weekend?
39. LDA_00:                        Closeness to LDA topic 0
40. LDA_01:                        Closeness to LDA topic 1
41. LDA_02:                        Closeness to LDA topic 2
42. LDA_03:                        Closeness to LDA topic 3
43. LDA_04:                        Closeness to LDA topic 4
44. global_subjectivity:           Text subjectivity
45. global_sentiment_polarity:     Text sentiment polarity
46. global_rate_positive_words:    Rate of positive words in the content
47. global_rate_negative_words:    Rate of negative words in the content
48. rate_positive_words:           Rate of positive words among non-neutral
                                   tokens
49. rate_negative_words:           Rate of negative words among non-neutral
                                   tokens
50. avg_positive_polarity:         Avg. polarity of positive words
51. min_positive_polarity:         Min. polarity of positive words
52. max_positive_polarity:         Max. polarity of positive words
53. avg_negative_polarity:         Avg. polarity of negative  words
54. min_negative_polarity:         Min. polarity of negative  words
55. max_negative_polarity:         Max. polarity of negative  words
56. title_subjectivity:            Title subjectivity
57. title_sentiment_polarity:      Title polarity
58. abs_title_subjectivity:        Absolute subjectivity level
59. abs_title_sentiment_polarity:  Absolute polarity level
60. shares:                        Number of shares (target)</code></pre>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data2</span> <span class="o">&lt;-</span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;DataSet2/OnlineNewsPopularity.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="bp">T</span><span class="p">)</span>
<span class="n">data2</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span> <span class="o">&lt;-</span><span class="kc">NULL</span>
<span class="nf">head</span><span class="p">(</span><span class="n">data2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>timedelta</th><th scope=col>n_tokens_title</th><th scope=col>n_tokens_content</th><th scope=col>n_unique_tokens</th><th scope=col>n_non_stop_words</th><th scope=col>n_non_stop_unique_tokens</th><th scope=col>num_hrefs</th><th scope=col>num_self_hrefs</th><th scope=col>num_imgs</th><th scope=col>num_videos</th><th scope=col>...</th><th scope=col>min_positive_polarity</th><th scope=col>max_positive_polarity</th><th scope=col>avg_negative_polarity</th><th scope=col>min_negative_polarity</th><th scope=col>max_negative_polarity</th><th scope=col>title_subjectivity</th><th scope=col>title_sentiment_polarity</th><th scope=col>abs_title_subjectivity</th><th scope=col>abs_title_sentiment_polarity</th><th scope=col>shares</th></tr></thead>
<tbody>
	<tr><td>731       </td><td>12        </td><td> 219      </td><td>0.6635945 </td><td>1         </td><td>0.8153846 </td><td> 4        </td><td> 2        </td><td> 1        </td><td>0         </td><td>...       </td><td>0.10000000</td><td>0.7       </td><td>-0.3500000</td><td>-0.600    </td><td>-0.2000000</td><td>0.5000000 </td><td>-0.1875000</td><td>0.00000000</td><td>0.1875000 </td><td> 593      </td></tr>
	<tr><td>731       </td><td> 9        </td><td> 255      </td><td>0.6047431 </td><td>1         </td><td>0.7919463 </td><td> 3        </td><td> 1        </td><td> 1        </td><td>0         </td><td>...       </td><td>0.03333333</td><td>0.7       </td><td>-0.1187500</td><td>-0.125    </td><td>-0.1000000</td><td>0.0000000 </td><td> 0.0000000</td><td>0.50000000</td><td>0.0000000 </td><td> 711      </td></tr>
	<tr><td>731       </td><td> 9        </td><td> 211      </td><td>0.5751295 </td><td>1         </td><td>0.6638655 </td><td> 3        </td><td> 1        </td><td> 1        </td><td>0         </td><td>...       </td><td>0.10000000</td><td>1.0       </td><td>-0.4666667</td><td>-0.800    </td><td>-0.1333333</td><td>0.0000000 </td><td> 0.0000000</td><td>0.50000000</td><td>0.0000000 </td><td>1500      </td></tr>
	<tr><td>731       </td><td> 9        </td><td> 531      </td><td>0.5037879 </td><td>1         </td><td>0.6656347 </td><td> 9        </td><td> 0        </td><td> 1        </td><td>0         </td><td>...       </td><td>0.13636364</td><td>0.8       </td><td>-0.3696970</td><td>-0.600    </td><td>-0.1666667</td><td>0.0000000 </td><td> 0.0000000</td><td>0.50000000</td><td>0.0000000 </td><td>1200      </td></tr>
	<tr><td>731       </td><td>13        </td><td>1072      </td><td>0.4156456 </td><td>1         </td><td>0.5408895 </td><td>19        </td><td>19        </td><td>20        </td><td>0         </td><td>...       </td><td>0.03333333</td><td>1.0       </td><td>-0.2201923</td><td>-0.500    </td><td>-0.0500000</td><td>0.4545455 </td><td> 0.1363636</td><td>0.04545455</td><td>0.1363636 </td><td> 505      </td></tr>
	<tr><td>731       </td><td>10        </td><td> 370      </td><td>0.5598886 </td><td>1         </td><td>0.6981982 </td><td> 2        </td><td> 2        </td><td> 0        </td><td>0         </td><td>...       </td><td>0.13636364</td><td>0.6       </td><td>-0.1950000</td><td>-0.400    </td><td>-0.1000000</td><td>0.6428571 </td><td> 0.2142857</td><td>0.14285714</td><td>0.2142857 </td><td> 855      </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">str</span><span class="p">(</span><span class="n">data2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>&#39;data.frame&#39;:	39644 obs. of  60 variables:
 $ timedelta                    : num  731 731 731 731 731 731 731 731 731 731 ...
 $ n_tokens_title               : num  12 9 9 9 13 10 8 12 11 10 ...
 $ n_tokens_content             : num  219 255 211 531 1072 ...
 $ n_unique_tokens              : num  0.664 0.605 0.575 0.504 0.416 ...
 $ n_non_stop_words             : num  1 1 1 1 1 ...
 $ n_non_stop_unique_tokens     : num  0.815 0.792 0.664 0.666 0.541 ...
 $ num_hrefs                    : num  4 3 3 9 19 2 21 20 2 4 ...
 $ num_self_hrefs               : num  2 1 1 0 19 2 20 20 0 1 ...
 $ num_imgs                     : num  1 1 1 1 20 0 20 20 0 1 ...
 $ num_videos                   : num  0 0 0 0 0 0 0 0 0 1 ...
 $ average_token_length         : num  4.68 4.91 4.39 4.4 4.68 ...
 $ num_keywords                 : num  5 4 6 7 7 9 10 9 7 5 ...
 $ data_channel_is_lifestyle    : num  0 0 0 0 0 0 1 0 0 0 ...
 $ data_channel_is_entertainment: num  1 0 0 1 0 0 0 0 0 0 ...
 $ data_channel_is_bus          : num  0 1 1 0 0 0 0 0 0 0 ...
 $ data_channel_is_socmed       : num  0 0 0 0 0 0 0 0 0 0 ...
 $ data_channel_is_tech         : num  0 0 0 0 1 1 0 1 1 0 ...
 $ data_channel_is_world        : num  0 0 0 0 0 0 0 0 0 1 ...
 $ kw_min_min                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_max_min                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_avg_min                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_min_max                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_max_max                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_avg_max                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_min_avg                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_max_avg                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ kw_avg_avg                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ self_reference_min_shares    : num  496 0 918 0 545 8500 545 545 0 0 ...
 $ self_reference_max_shares    : num  496 0 918 0 16000 8500 16000 16000 0 0 ...
 $ self_reference_avg_sharess   : num  496 0 918 0 3151 ...
 $ weekday_is_monday            : num  1 1 1 1 1 1 1 1 1 1 ...
 $ weekday_is_tuesday           : num  0 0 0 0 0 0 0 0 0 0 ...
 $ weekday_is_wednesday         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ weekday_is_thursday          : num  0 0 0 0 0 0 0 0 0 0 ...
 $ weekday_is_friday            : num  0 0 0 0 0 0 0 0 0 0 ...
 $ weekday_is_saturday          : num  0 0 0 0 0 0 0 0 0 0 ...
 $ weekday_is_sunday            : num  0 0 0 0 0 0 0 0 0 0 ...
 $ is_weekend                   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ LDA_00                       : num  0.5003 0.7998 0.2178 0.0286 0.0286 ...
 $ LDA_01                       : num  0.3783 0.05 0.0333 0.4193 0.0288 ...
 $ LDA_02                       : num  0.04 0.0501 0.0334 0.4947 0.0286 ...
 $ LDA_03                       : num  0.0413 0.0501 0.0333 0.0289 0.0286 ...
 $ LDA_04                       : num  0.0401 0.05 0.6822 0.0286 0.8854 ...
 $ global_subjectivity          : num  0.522 0.341 0.702 0.43 0.514 ...
 $ global_sentiment_polarity    : num  0.0926 0.1489 0.3233 0.1007 0.281 ...
 $ global_rate_positive_words   : num  0.0457 0.0431 0.0569 0.0414 0.0746 ...
 $ global_rate_negative_words   : num  0.0137 0.01569 0.00948 0.02072 0.01213 ...
 $ rate_positive_words          : num  0.769 0.733 0.857 0.667 0.86 ...
 $ rate_negative_words          : num  0.231 0.267 0.143 0.333 0.14 ...
 $ avg_positive_polarity        : num  0.379 0.287 0.496 0.386 0.411 ...
 $ min_positive_polarity        : num  0.1 0.0333 0.1 0.1364 0.0333 ...
 $ max_positive_polarity        : num  0.7 0.7 1 0.8 1 0.6 1 1 0.8 0.5 ...
 $ avg_negative_polarity        : num  -0.35 -0.119 -0.467 -0.37 -0.22 ...
 $ min_negative_polarity        : num  -0.6 -0.125 -0.8 -0.6 -0.5 -0.4 -0.5 -0.5 -0.125 -0.5 ...
 $ max_negative_polarity        : num  -0.2 -0.1 -0.133 -0.167 -0.05 ...
 $ title_subjectivity           : num  0.5 0 0 0 0.455 ...
 $ title_sentiment_polarity     : num  -0.188 0 0 0 0.136 ...
 $ abs_title_subjectivity       : num  0 0.5 0.5 0.5 0.0455 ...
 $ abs_title_sentiment_polarity : num  0.188 0 0 0 0.136 ...
 $ shares                       : int  593 711 1500 1200 505 855 556 891 3600 710 ...
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">sample2</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data2</span><span class="p">),</span> <span class="n">size</span> <span class="o">=</span> <span class="nf">floor</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">data2</span><span class="p">)</span><span class="o">*</span><span class="m">0.77</span><span class="p">),</span> <span class="n">replace</span> <span class="o">=</span> <span class="bp">F</span><span class="p">)</span>
<span class="n">train2</span> <span class="o">&lt;-</span> <span class="n">data2</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
<span class="n">test2</span>  <span class="o">&lt;-</span> <span class="n">data2</span><span class="p">[</span><span class="o">-</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
<span class="nf">head</span><span class="p">(</span><span class="n">train2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th></th><th scope=col>timedelta</th><th scope=col>n_tokens_title</th><th scope=col>n_tokens_content</th><th scope=col>n_unique_tokens</th><th scope=col>n_non_stop_words</th><th scope=col>n_non_stop_unique_tokens</th><th scope=col>num_hrefs</th><th scope=col>num_self_hrefs</th><th scope=col>num_imgs</th><th scope=col>num_videos</th><th scope=col>...</th><th scope=col>min_positive_polarity</th><th scope=col>max_positive_polarity</th><th scope=col>avg_negative_polarity</th><th scope=col>min_negative_polarity</th><th scope=col>max_negative_polarity</th><th scope=col>title_subjectivity</th><th scope=col>title_sentiment_polarity</th><th scope=col>abs_title_subjectivity</th><th scope=col>abs_title_sentiment_polarity</th><th scope=col>shares</th></tr></thead>
<tbody>
	<tr><th scope=row>679</th><td>720        </td><td> 9         </td><td>227        </td><td>0.5972222  </td><td>1          </td><td>0.7388060  </td><td> 2         </td><td>0          </td><td> 1         </td><td>0          </td><td>...        </td><td>0.20000000 </td><td>1.00       </td><td>-0.15500000</td><td>-0.3000000 </td><td>-0.10000000</td><td>0.0        </td><td>0.0        </td><td>0.5        </td><td>0.0        </td><td> 1400      </td></tr>
	<tr><th scope=row>129</th><td>729        </td><td>10         </td><td>258        </td><td>0.5891473  </td><td>1          </td><td>0.7371795  </td><td> 2         </td><td>1          </td><td>11         </td><td>0          </td><td>...        </td><td>0.20000000 </td><td>0.60       </td><td>-0.48214286</td><td>-0.7142857 </td><td>-0.25000000</td><td>0.0        </td><td>0.0        </td><td>0.5        </td><td>0.0        </td><td>  752      </td></tr>
	<tr><th scope=row>509</th><td>723        </td><td> 8         </td><td>744        </td><td>0.5033829  </td><td>1          </td><td>0.6780822  </td><td>19         </td><td>0          </td><td> 1         </td><td>0          </td><td>...        </td><td>0.05000000 </td><td>0.85       </td><td>-0.25370370</td><td>-0.6000000 </td><td>-0.05000000</td><td>0.0        </td><td>0.0        </td><td>0.5        </td><td>0.0        </td><td> 2100      </td></tr>
	<tr><th scope=row>471</th><td>723        </td><td> 9         </td><td>282        </td><td>0.5543478  </td><td>1          </td><td>0.7337662  </td><td> 2         </td><td>2          </td><td> 1         </td><td>0          </td><td>...        </td><td>0.10000000 </td><td>0.50       </td><td>-0.08571429</td><td>-0.1000000 </td><td>-0.07142857</td><td>0.0        </td><td>0.0        </td><td>0.5        </td><td>0.0        </td><td>17100      </td></tr>
	<tr><th scope=row>299</th><td>727        </td><td>13         </td><td>578        </td><td>0.4736842  </td><td>1          </td><td>0.6000000  </td><td> 4         </td><td>3          </td><td>19         </td><td>1          </td><td>...        </td><td>0.03333333 </td><td>0.80       </td><td>-0.35666667</td><td>-1.0000000 </td><td>-0.05000000</td><td>0.9        </td><td>0.4        </td><td>0.4        </td><td>0.4        </td><td>  840      </td></tr>
	<tr><th scope=row>270</th><td>727        </td><td>13         </td><td>220        </td><td>0.6028037  </td><td>1          </td><td>0.6821705  </td><td> 5         </td><td>3          </td><td> 1         </td><td>0          </td><td>...        </td><td>0.20000000 </td><td>0.50       </td><td>-0.31250000</td><td>-0.5000000 </td><td>-0.12500000</td><td>0.0        </td><td>0.0        </td><td>0.5        </td><td>0.0        </td><td> 1800      </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">folds2</span> <span class="o">&lt;-</span> <span class="nf">createMultiFolds</span><span class="p">(</span><span class="n">train2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="m">10</span><span class="p">,</span><span class="n">times</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
<span class="n">control2</span><span class="o">&lt;-</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">verboseIter</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">folds2</span><span class="p">,</span><span class="n">allowParallel</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[207]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">lasso_grid2</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">lambda</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">400</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">3</span><span class="p">)))</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">reg2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">shares</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;glmnet&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">lasso_grid2</span><span class="p">,</span> 
                 <span class="n">trControl</span><span class="o">=</span> <span class="n">control2</span><span class="p">,</span> <span class="n">preProcess</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span><span class="s">&quot;scale&quot;</span><span class="p">))</span>

<span class="n">pred2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">reg2</span><span class="p">,</span><span class="n">test2</span><span class="p">)</span>

<span class="n">lasso_error2</span> <span class="o">&lt;-</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span> <span class="n">pred2</span><span class="p">)</span>
<span class="n">lasso_error2</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: alpha=1, lambda=400 
- Fold01.Rep1: alpha=1, lambda=400 
+ Fold02.Rep1: alpha=1, lambda=400 
- Fold02.Rep1: alpha=1, lambda=400 
+ Fold03.Rep1: alpha=1, lambda=400 
- Fold03.Rep1: alpha=1, lambda=400 
+ Fold04.Rep1: alpha=1, lambda=400 
- Fold04.Rep1: alpha=1, lambda=400 
+ Fold05.Rep1: alpha=1, lambda=400 
- Fold05.Rep1: alpha=1, lambda=400 
+ Fold06.Rep1: alpha=1, lambda=400 
- Fold06.Rep1: alpha=1, lambda=400 
+ Fold07.Rep1: alpha=1, lambda=400 
- Fold07.Rep1: alpha=1, lambda=400 
+ Fold08.Rep1: alpha=1, lambda=400 
- Fold08.Rep1: alpha=1, lambda=400 
+ Fold09.Rep1: alpha=1, lambda=400 
- Fold09.Rep1: alpha=1, lambda=400 
+ Fold10.Rep1: alpha=1, lambda=400 
- Fold10.Rep1: alpha=1, lambda=400 
Aggregating results
Selecting tuning parameters
Fitting alpha = 1, lambda = 400 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
11694.9791008123
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[209]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">grid_dt2</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.005</span><span class="p">,</span><span class="m">0.01</span><span class="p">))</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">dt2.1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">shares</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train2</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">grid_dt2</span><span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control2</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">)))</span>
<span class="n">pred2.1</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt2.1</span><span class="p">,</span><span class="n">test2</span><span class="p">)</span>
<span class="n">dt_error2.1</span><span class="o">=</span><span class="nf">RMSE</span><span class="p">(</span><span class="n">test2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span><span class="n">pred2.1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[210]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt2.2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">shares</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train2</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">grid_dt2</span><span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control2</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">)))</span>
<span class="n">pred2.2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt2.2</span><span class="p">,</span><span class="n">test2</span><span class="p">)</span>
<span class="n">dt_error2.2</span> <span class="o">&lt;-</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span><span class="n">pred2.2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[211]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt2.3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">shares</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train2</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">grid_dt2</span><span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control2</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">)))</span>
<span class="n">pred2.3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt2.3</span><span class="p">,</span><span class="n">test2</span><span class="p">)</span>
<span class="n">dt_error2.3</span> <span class="o">&lt;-</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span><span class="n">pred2.3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[213]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&#39;e1071&#39;</span><span class="p">,</span> <span class="n">dependencies</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;ranger&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>package &#39;e1071&#39; successfully unpacked and MD5 sums checked
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message:
&#34;cannot remove prior installation of package &#39;e1071&#39;&#34;Warning message in file.copy(savedcopy, lib, recursive = TRUE):
&#34;problem copying C:\Users\lenovo\Anaconda3\envs\renv\Lib\R\library\00LOCK\e1071\libs\x64\e1071.dll to C:\Users\lenovo\Anaconda3\envs\renv\Lib\R\library\e1071\libs\x64\e1071.dll: Permission denied&#34;Warning message:
&#34;restored &#39;e1071&#39;&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
The downloaded binary packages are in
	C:\Users\lenovo\AppData\Local\Temp\RtmpmY4E4B\downloaded_packages
package &#39;ranger&#39; successfully unpacked and MD5 sums checked
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message:
&#34;cannot remove prior installation of package &#39;ranger&#39;&#34;Warning message in file.copy(savedcopy, lib, recursive = TRUE):
&#34;problem copying C:\Users\lenovo\Anaconda3\envs\renv\Lib\R\library\00LOCK\ranger\libs\x64\ranger.dll to C:\Users\lenovo\Anaconda3\envs\renv\Lib\R\library\ranger\libs\x64\ranger.dll: Permission denied&#34;Warning message:
&#34;restored &#39;ranger&#39;&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
The downloaded binary packages are in
	C:\Users\lenovo\AppData\Local\Temp\RtmpmY4E4B\downloaded_packages
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[214]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">forest_grid2</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">6</span><span class="p">)</span> <span class="p">,</span><span class="n">min.node.size</span><span class="o">=</span><span class="m">5</span><span class="p">,</span> <span class="n">splitrule</span> <span class="o">=</span> <span class="s">&quot;variance&quot;</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>
<span class="n">rf2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">shares</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;ranger&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">forest_grid2</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span> <span class="n">control2</span><span class="p">)</span>
<span class="n">pred2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">rf2</span><span class="p">,</span><span class="n">test2</span><span class="p">)</span>
<span class="n">rf_error2</span> <span class="o">=</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span><span class="n">pred2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold01.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold01.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold01.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold01.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold01.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold02.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold02.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold02.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold02.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold02.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold02.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold03.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold03.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold03.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold03.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold03.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold03.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold04.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold04.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold04.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold04.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold04.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold04.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold05.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold05.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold05.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold05.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold05.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold05.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold06.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold06.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold06.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold06.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold06.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold06.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold07.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold07.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold07.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold07.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold07.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold07.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold08.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold08.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold08.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold08.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold08.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold08.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold09.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold09.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold09.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold09.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold09.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold09.Rep1: mtry=6, min.node.size=5, splitrule=variance 
+ Fold10.Rep1: mtry=2, min.node.size=5, splitrule=variance 
- Fold10.Rep1: mtry=2, min.node.size=5, splitrule=variance 
+ Fold10.Rep1: mtry=4, min.node.size=5, splitrule=variance 
- Fold10.Rep1: mtry=4, min.node.size=5, splitrule=variance 
+ Fold10.Rep1: mtry=6, min.node.size=5, splitrule=variance 
- Fold10.Rep1: mtry=6, min.node.size=5, splitrule=variance 
Aggregating results
Selecting tuning parameters
Fitting mtry = 2, splitrule = variance, min.node.size = 5 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[215]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">grid_sgb2</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">300</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.02</span><span class="p">),</span> <span class="n">n.minobsinnode</span><span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">sgb2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">shares</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">grid_sgb2</span> <span class="p">,</span> <span class="n">trControl</span><span class="o">=</span> <span class="n">control2</span><span class="p">)</span>
<span class="n">pred2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sgb2</span><span class="p">,</span><span class="n">test2</span><span class="p">)</span>
<span class="n">sgb_error2</span> <span class="o">&lt;-</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">test2</span><span class="o">$</span><span class="n">shares</span><span class="p">,</span><span class="n">pred2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18325038.1862             nan     0.0100 -1064.5240
     2 18282295.9569             nan     0.0100 5147.5508
     3 18266293.9212             nan     0.0100 6137.6543
     4 18256279.3861             nan     0.0100 2468.6504
     5 18241993.1966             nan     0.0100 -1313.1014
     6 18209746.6682             nan     0.0100 2437.1472
     7 18190129.8266             nan     0.0100 21544.8531
     8 18151278.4012             nan     0.0100 12410.3947
     9 18130204.3085             nan     0.0100 10533.1134
    10 18100974.5437             nan     0.0100 15414.2888
    20 17953637.7022             nan     0.0100 3875.9698
    40 17636643.3503             nan     0.0100 -2456.8238
    60 17378509.5992             nan     0.0100 -1108.0027
    80 17179087.2363             nan     0.0100 -7022.0117
   100 16937649.5412             nan     0.0100 3150.3913
   120 16725282.7052             nan     0.0100 -5762.3871
   140 16517089.2064             nan     0.0100 -7535.6560
   160 16344265.6969             nan     0.0100 -8190.9468
   180 16138259.5446             nan     0.0100 -10275.3927
   200 15950997.6374             nan     0.0100 -6800.1330
   220 15785531.6344             nan     0.0100 -11572.3772
   240 15641335.5131             nan     0.0100 -2036.5570
   260 15547154.5754             nan     0.0100 -6477.2264
   280 15419129.7790             nan     0.0100 -10508.9208
   300 15310858.2191             nan     0.0100 -8872.2801

- Fold01.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18294507.0311             nan     0.0100 6211.1822
     2 18252186.0237             nan     0.0100 16112.4684
     3 18221644.1072             nan     0.0100 4711.5729
     4 18192699.5840             nan     0.0100 23942.3569
     5 18167032.4288             nan     0.0100 -1734.7367
     6 18149720.9365             nan     0.0100 4136.7186
     7 18112405.9883             nan     0.0100 23170.3502
     8 18056312.4709             nan     0.0100 5391.3007
     9 18002329.6082             nan     0.0100 9833.4471
    10 17964352.9295             nan     0.0100 -3769.4233
    20 17634816.0516             nan     0.0100 14410.7953
    40 17107327.6636             nan     0.0100 2771.0657
    60 16584570.9335             nan     0.0100 4908.2638
    80 16030270.2043             nan     0.0100 25638.9974
   100 15660036.8063             nan     0.0100 8971.2430
   120 15206792.9073             nan     0.0100 -1148.7823
   140 14786105.4946             nan     0.0100 7269.8884
   160 14384008.8114             nan     0.0100 -9794.7273
   180 13995761.4163             nan     0.0100 -12402.0574
   200 13737535.5575             nan     0.0100 -26325.5387
   220 13466695.0779             nan     0.0100 -10667.8451
   240 13128282.2353             nan     0.0100 -11241.0332
   260 12923103.7621             nan     0.0100 -15974.0835
   280 12731764.9825             nan     0.0100 -16868.0148
   300 12463953.0419             nan     0.0100 -8966.7086

- Fold01.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18311028.8856             nan     0.0100 26287.9383
     2 18277416.5299             nan     0.0100 16711.6330
     3 18233777.7324             nan     0.0100 27143.1179
     4 18200366.7920             nan     0.0100 26886.6778
     5 18177156.4305             nan     0.0100 5862.8291
     6 18123191.6344             nan     0.0100 -6337.6251
     7 18086924.0434             nan     0.0100 -8547.2829
     8 18055869.3992             nan     0.0100 11203.2735
     9 18012893.2554             nan     0.0100 21116.5205
    10 17985743.0097             nan     0.0100 8743.3483
    20 17658276.8662             nan     0.0100 -14781.0761
    40 16964190.1778             nan     0.0100 15570.3639
    60 16393976.4393             nan     0.0100 3779.0909
    80 15802331.4643             nan     0.0100 -7681.7614
   100 15254090.6179             nan     0.0100 -12523.8790
   120 14780925.0727             nan     0.0100 -15778.9002
   140 14407334.5203             nan     0.0100 1406.9973
   160 14079663.5662             nan     0.0100 -4565.6067
   180 13806504.8126             nan     0.0100 -21531.7407
   200 13451433.2697             nan     0.0100 -12799.8639
   220 13119993.4857             nan     0.0100 6190.1859
   240 12765164.0622             nan     0.0100 -2535.8654
   260 12505247.9652             nan     0.0100 -15430.9602
   280 12195923.7418             nan     0.0100 -11984.7472
   300 11970554.7624             nan     0.0100 -5490.2118

- Fold01.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18324866.4973             nan     0.0200 6118.7960
     2 18325260.7426             nan     0.0200 -16338.4174
     3 18307413.7880             nan     0.0200 4636.8441
     4 18290810.0315             nan     0.0200 6633.4865
     5 18248404.6831             nan     0.0200 18580.8021
     6 18182555.1547             nan     0.0200 45681.5586
     7 18149390.5544             nan     0.0200 7429.2416
     8 18137404.8834             nan     0.0200 -1637.6220
     9 18127156.8939             nan     0.0200 -4288.1480
    10 18063359.9482             nan     0.0200 -19312.7806
    20 17675440.2132             nan     0.0200 -6015.7350
    40 17178728.1716             nan     0.0200 -9315.8878
    60 16668859.1457             nan     0.0200 -10010.3688
    80 16211062.1205             nan     0.0200 -707.3830
   100 15888874.7070             nan     0.0200   11.0883
   120 15633670.6274             nan     0.0200 -8447.2608
   140 15375961.9533             nan     0.0200 -29686.0306
   160 15166943.4888             nan     0.0200 -9680.3819
   180 15004363.4062             nan     0.0200 -34587.7222
   200 14878741.5575             nan     0.0200 -7636.1303
   220 14775401.1895             nan     0.0200 -23409.0830
   240 14628951.5385             nan     0.0200 -15533.5482
   260 14553407.7696             nan     0.0200 -27826.9712
   280 14454906.9820             nan     0.0200 -6690.2791
   300 14367494.9727             nan     0.0200 -13853.9158

- Fold01.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18292139.8678             nan     0.0200 38613.6962
     2 18195593.2572             nan     0.0200 -4532.7020
     3 18117204.5591             nan     0.0200 -1335.1341
     4 18056870.8716             nan     0.0200 5682.1347
     5 18006823.1617             nan     0.0200 7020.8197
     6 17970159.3253             nan     0.0200 3936.0836
     7 17902287.5907             nan     0.0200 40281.6848
     8 17804632.6028             nan     0.0200 18994.3908
     9 17732385.9797             nan     0.0200 6510.6289
    10 17638282.3574             nan     0.0200 39591.9372
    20 16928776.7306             nan     0.0200 -18947.1974
    40 15714304.5463             nan     0.0200 -2524.2882
    60 14804833.1768             nan     0.0200 -27887.5294
    80 14291986.0889             nan     0.0200 2034.5035
   100 13543265.7739             nan     0.0200 -10151.1093
   120 13045281.4220             nan     0.0200 -14401.8055
   140 12542913.5133             nan     0.0200 -10036.6045
   160 12125835.1525             nan     0.0200 -9150.2791
   180 11700317.0866             nan     0.0200 -28216.2606
   200 11204442.0479             nan     0.0200 -17128.3407
   220 10906256.1033             nan     0.0200 -20112.4903
   240 10612543.8716             nan     0.0200 -10734.7608
   260 10356886.6868             nan     0.0200 -14532.5141
   280 10034016.7342             nan     0.0200 -16883.6920
   300  9714290.6270             nan     0.0200 -3429.9639

- Fold01.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18264269.7956             nan     0.0200 45264.4493
     2 18215826.1187             nan     0.0200 -7182.7239
     3 18149852.1031             nan     0.0200 14170.4012
     4 18027388.1004             nan     0.0200 -9044.8609
     5 17975254.6855             nan     0.0200 -20418.1140
     6 17889398.1889             nan     0.0200 -8245.1977
     7 17820979.2378             nan     0.0200 12479.1081
     8 17723939.6668             nan     0.0200 23310.5046
     9 17648042.8696             nan     0.0200 7812.9836
    10 17606431.0047             nan     0.0200 4392.6622
    20 16993806.0588             nan     0.0200 -21862.4234
    40 16035340.9089             nan     0.0200 -31196.8012
    60 15090699.7130             nan     0.0200 -18824.1149
    80 14133865.5884             nan     0.0200 -31323.9991
   100 13249963.0984             nan     0.0200 -1277.9933
   120 12556470.9177             nan     0.0200 -22424.3211
   140 11889721.4593             nan     0.0200 -24573.0522
   160 11283527.3312             nan     0.0200 -19611.1289
   180 10944378.8807             nan     0.0200 -23664.5595
   200 10482956.5891             nan     0.0200 -16577.7258
   220  9974446.0953             nan     0.0200 -7855.6938
   240  9649882.5191             nan     0.0200 -18771.1074
   260  9282654.6169             nan     0.0200 -14383.8757
   280  8940273.6305             nan     0.0200 -20853.1905
   300  8634353.2811             nan     0.0200 -22121.4575

- Fold01.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18290677.0948             nan     0.0500 -17734.8613
     2 18269870.7566             nan     0.0500 -22269.5809
     3 18137277.9150             nan     0.0500 11942.5447
     4 18014164.2826             nan     0.0500 40330.3212
     5 17972023.4403             nan     0.0500 19665.2980
     6 17841556.6163             nan     0.0500 4935.5267
     7 17720607.1761             nan     0.0500 -29294.9442
     8 17650200.7469             nan     0.0500 18615.3442
     9 17629509.8123             nan     0.0500 -19762.0518
    10 17579071.3700             nan     0.0500 -44796.1689
    20 16963246.8494             nan     0.0500 12337.2747
    40 16021665.4563             nan     0.0500 -106917.1617
    60 15374208.4970             nan     0.0500 -27021.7761
    80 14958238.2321             nan     0.0500 -51237.9892
   100 14672866.5991             nan     0.0500 -29343.0169
   120 14454366.1544             nan     0.0500 -24778.8626
   140 14187114.3799             nan     0.0500 -37583.2316
   160 13960676.7250             nan     0.0500 -16836.4764
   180 13831415.4515             nan     0.0500 -29698.1045
   200 13597059.8536             nan     0.0500 -10293.2268
   220 13422023.4382             nan     0.0500 -26213.8008
   240 13333425.5680             nan     0.0500 -47064.6096
   260 13178477.6245             nan     0.0500 -29511.7093
   280 13067229.2538             nan     0.0500 -58960.9820
   300 12915075.6991             nan     0.0500 -40985.6805

- Fold01.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18138449.2195             nan     0.0500 82711.4790
     2 18002958.7987             nan     0.0500 -3584.7933
     3 17845040.8420             nan     0.0500 28399.3962
     4 17671128.5680             nan     0.0500 -18082.7971
     5 17569679.3096             nan     0.0500 32438.1261
     6 17503676.2110             nan     0.0500 -59243.4708
     7 17449493.3076             nan     0.0500 9327.5766
     8 17312041.7108             nan     0.0500 34525.6929
     9 17061980.5450             nan     0.0500 7433.1707
    10 16949885.4080             nan     0.0500 31379.4591
    20 15740129.4098             nan     0.0500 -30870.2315
    40 14112390.9506             nan     0.0500 75274.8302
    60 13147916.0195             nan     0.0500 -13206.0986
    80 11779597.1429             nan     0.0500 -55624.9999
   100 11076739.6424             nan     0.0500 -61002.4160
   120 10259527.5031             nan     0.0500 -44758.1243
   140  9695644.8313             nan     0.0500 -43301.4065
   160  8995085.1424             nan     0.0500 -56080.1596
   180  8465011.8369             nan     0.0500 -24877.5915
   200  8065248.2866             nan     0.0500 -33643.8588
   220  7642421.3530             nan     0.0500 -19621.9546
   240  7142068.6181             nan     0.0500 -35076.2659
   260  6718511.7172             nan     0.0500 -26738.8627
   280  6447149.4220             nan     0.0500 -32729.5228
   300  6011035.1802             nan     0.0500 -38071.2056

- Fold01.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18094819.8439             nan     0.0500 107609.5765
     2 17919966.4834             nan     0.0500 59430.4691
     3 17687046.3699             nan     0.0500 35270.7578
     4 17471446.9803             nan     0.0500 5360.4034
     5 17367671.0128             nan     0.0500 34335.9254
     6 17114438.2054             nan     0.0500 29502.1873
     7 16842768.5422             nan     0.0500 1717.8322
     8 16644572.7229             nan     0.0500 -1636.0875
     9 16562644.5483             nan     0.0500 1648.4665
    10 16417120.5615             nan     0.0500 33475.6783
    20 15148011.8765             nan     0.0500 -61144.8897
    40 13506576.1470             nan     0.0500 -66590.3623
    60 12304660.4657             nan     0.0500 -48286.9953
    80 10839894.8399             nan     0.0500 -51928.6872
   100  9974884.6052             nan     0.0500 -66943.0975
   120  9031963.5349             nan     0.0500 -22905.9858
   140  8163495.3300             nan     0.0500 -67923.2845
   160  7601260.7581             nan     0.0500 -22431.3828
   180  6936301.0187             nan     0.0500 -13457.3952
   200  6358023.8249             nan     0.0500 -51742.2749
   220  5888345.3313             nan     0.0500 -38482.1072
   240  5490903.7725             nan     0.0500 -46561.4872
   260  5151953.7311             nan     0.0500 -27266.9428
   280  4787008.3397             nan     0.0500 -45237.1941
   300  4493964.8376             nan     0.0500 -34534.6768

- Fold01.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19738017.1766             nan     0.0100 -4984.9904
     2 19722834.7872             nan     0.0100 -8865.5318
     3 19710401.3315             nan     0.0100 -2779.7308
     4 19689446.2324             nan     0.0100 5731.4187
     5 19667795.6339             nan     0.0100  977.5616
     6 19655958.7184             nan     0.0100 -5887.2122
     7 19628324.2204             nan     0.0100 1527.6989
     8 19589329.6443             nan     0.0100 -8547.5324
     9 19575408.4472             nan     0.0100 -13335.6775
    10 19552846.1653             nan     0.0100 5060.2134
    20 19402802.2076             nan     0.0100 5003.7766
    40 19066598.4819             nan     0.0100 7253.3875
    60 18798965.6495             nan     0.0100 -371.9314
    80 18532270.0788             nan     0.0100  559.7018
   100 18299843.7514             nan     0.0100 3441.1025
   120 18101977.7815             nan     0.0100  633.7507
   140 17884092.1724             nan     0.0100 -5426.7599
   160 17702888.3368             nan     0.0100 -10696.6866
   180 17545578.1470             nan     0.0100 -5278.5738
   200 17399104.3724             nan     0.0100 -3352.8876
   220 17247597.1825             nan     0.0100 -1407.5873
   240 17090251.3290             nan     0.0100 -8902.7250
   260 16952514.9278             nan     0.0100 -4687.8279
   280 16819260.8479             nan     0.0100 -7558.2205
   300 16680764.8103             nan     0.0100 -194.0864

- Fold02.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19742525.5307             nan     0.0100 5558.5266
     2 19714513.4920             nan     0.0100 -120.7938
     3 19690309.5740             nan     0.0100 8298.6180
     4 19673824.7877             nan     0.0100 -5841.4768
     5 19645193.4220             nan     0.0100 -266.5071
     6 19599006.1830             nan     0.0100 6080.8731
     7 19576079.5828             nan     0.0100 5078.6422
     8 19535555.8265             nan     0.0100 26794.9693
     9 19510748.7426             nan     0.0100 -11225.3635
    10 19486782.7373             nan     0.0100 9437.4599
    20 19156967.0582             nan     0.0100 -4324.3726
    40 18545587.0789             nan     0.0100 -1990.9309
    60 18052368.1250             nan     0.0100 -11667.3953
    80 17476765.2236             nan     0.0100 5898.3184
   100 17016300.5473             nan     0.0100 -4533.0867
   120 16535278.8646             nan     0.0100 -4249.1551
   140 16150924.2089             nan     0.0100 -1544.6159
   160 15822749.7302             nan     0.0100 -3800.2358
   180 15468522.3616             nan     0.0100 3172.5016
   200 15237568.8833             nan     0.0100 -8254.2090
   220 14960351.4315             nan     0.0100 -24136.5870
   240 14660878.1587             nan     0.0100 -7788.7127
   260 14355848.0035             nan     0.0100 -9886.1589
   280 14102688.7386             nan     0.0100 5936.2533
   300 13857652.2825             nan     0.0100 -9824.9329

- Fold02.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19731570.7393             nan     0.0100 -490.0176
     2 19683644.9545             nan     0.0100 17055.2446
     3 19657539.6873             nan     0.0100 6692.4971
     4 19613857.3623             nan     0.0100 9722.2232
     5 19582272.4844             nan     0.0100 -3386.6048
     6 19517178.8123             nan     0.0100 3227.3367
     7 19472672.8937             nan     0.0100 23391.2044
     8 19436295.1221             nan     0.0100 2565.0931
     9 19390264.9486             nan     0.0100 25362.2605
    10 19355618.4167             nan     0.0100 -11570.0671
    20 19080373.4533             nan     0.0100 -10202.1050
    40 18285901.7778             nan     0.0100 11846.9655
    60 17715532.1601             nan     0.0100  -95.5844
    80 17133657.8431             nan     0.0100 -12022.8010
   100 16603134.2459             nan     0.0100 -709.6442
   120 16233201.6876             nan     0.0100 1184.3491
   140 15762923.3002             nan     0.0100 -17812.3286
   160 15312383.2419             nan     0.0100 -6166.2771
   180 14978279.9343             nan     0.0100 -12750.2618
   200 14652983.2120             nan     0.0100 -20229.2435
   220 14284224.9735             nan     0.0100 -14037.4760
   240 13941801.0648             nan     0.0100 -9863.3865
   260 13684518.4696             nan     0.0100 -13991.7496
   280 13414517.2697             nan     0.0100 -14706.4449
   300 12999557.4310             nan     0.0100 -17918.1999

- Fold02.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19744151.5728             nan     0.0200 -17476.0905
     2 19725666.4919             nan     0.0200 13391.7269
     3 19684558.1416             nan     0.0200 -17715.4476
     4 19634865.5130             nan     0.0200 -12733.3478
     5 19576908.2787             nan     0.0200 8791.8616
     6 19569660.3082             nan     0.0200 -13823.7358
     7 19518710.1411             nan     0.0200 -6666.9962
     8 19447086.1622             nan     0.0200 39925.9625
     9 19418091.1178             nan     0.0200  -35.9688
    10 19397478.7982             nan     0.0200 5296.6035
    20 19042711.6219             nan     0.0200 -4028.3083
    40 18547393.3395             nan     0.0200 3511.0804
    60 18113295.9497             nan     0.0200 -446.1079
    80 17657683.9588             nan     0.0200 -8911.9999
   100 17325195.1213             nan     0.0200 -27841.5633
   120 17068430.6431             nan     0.0200 -14982.9056
   140 16827946.4510             nan     0.0200 -6342.6434
   160 16602370.1143             nan     0.0200 -6062.9716
   180 16460954.5845             nan     0.0200 -36846.6628
   200 16270335.1037             nan     0.0200 -19517.8591
   220 16101348.7366             nan     0.0200 -14503.4861
   240 15973555.2088             nan     0.0200 -12050.5636
   260 15871294.8491             nan     0.0200 -14929.8409
   280 15742906.3791             nan     0.0200 7171.6939
   300 15640356.0299             nan     0.0200 -7195.9567

- Fold02.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19691603.8403             nan     0.0200 14455.1483
     2 19615465.6068             nan     0.0200 13366.5487
     3 19564503.5327             nan     0.0200 6598.2858
     4 19481587.3856             nan     0.0200 13601.2864
     5 19455577.5870             nan     0.0200 -8796.1700
     6 19413780.3042             nan     0.0200 8372.8012
     7 19346472.5192             nan     0.0200 3172.2708
     8 19261939.8005             nan     0.0200 14506.1115
     9 19181231.0660             nan     0.0200 -14320.2536
    10 19088799.1707             nan     0.0200 5538.9517
    20 18497878.8115             nan     0.0200 -4085.9868
    40 17313026.4628             nan     0.0200 30630.7830
    60 16525359.0654             nan     0.0200 -6380.8595
    80 15722476.6240             nan     0.0200 -744.1598
   100 15068062.0138             nan     0.0200 14291.4183
   120 14570797.6981             nan     0.0200 -40672.7896
   140 14064960.3502             nan     0.0200 -9768.5425
   160 13606480.2087             nan     0.0200 -19635.2260
   180 13075183.7165             nan     0.0200 -19808.7719
   200 12586133.0283             nan     0.0200 -24861.2258
   220 12192655.0336             nan     0.0200 -24549.0004
   240 11870483.3866             nan     0.0200 1756.2177
   260 11544110.9812             nan     0.0200 -30200.3720
   280 11179403.9727             nan     0.0200 -46386.2776
   300 10834903.1727             nan     0.0200 -21732.6965

- Fold02.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19732499.6529             nan     0.0200 -16712.7457
     2 19622069.5227             nan     0.0200 19695.8990
     3 19513234.0650             nan     0.0200 -24315.8991
     4 19455877.0296             nan     0.0200 -4555.7189
     5 19349457.7076             nan     0.0200 -1296.9046
     6 19274948.7208             nan     0.0200 15454.1995
     7 19216721.9720             nan     0.0200 -42052.1109
     8 19120520.8491             nan     0.0200 14009.9923
     9 19030362.5215             nan     0.0200 -23300.9625
    10 18956524.2365             nan     0.0200 -17978.4722
    20 18262158.3319             nan     0.0200 -6972.8660
    40 17143820.5354             nan     0.0200 -19059.5273
    60 16198989.4294             nan     0.0200 -34739.3848
    80 15319199.5121             nan     0.0200 -33359.3867
   100 14443812.5320             nan     0.0200 1085.5155
   120 13815446.3828             nan     0.0200  -64.6903
   140 13139251.9896             nan     0.0200 -18917.0016
   160 12565307.0584             nan     0.0200 -14213.6438
   180 11989554.7093             nan     0.0200 -10212.7538
   200 11502778.4078             nan     0.0200 -25333.4744
   220 11035780.2488             nan     0.0200 -18376.2179
   240 10587348.3646             nan     0.0200 -40941.0576
   260 10202191.4572             nan     0.0200 -31727.0503
   280  9873478.4226             nan     0.0200 -20131.8865
   300  9529081.8530             nan     0.0200 -20936.6840

- Fold02.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19714666.1188             nan     0.0500 -1790.8866
     2 19689536.7080             nan     0.0500 -19017.8987
     3 19591781.7873             nan     0.0500 48201.1357
     4 19511295.8114             nan     0.0500 16578.0144
     5 19414089.7668             nan     0.0500 3908.3798
     6 19316708.6085             nan     0.0500 25675.3141
     7 19198957.2204             nan     0.0500  598.0305
     8 19120687.5510             nan     0.0500 -28697.6811
     9 19070335.2676             nan     0.0500 24723.1784
    10 18973239.1850             nan     0.0500 14264.1970
    20 18156283.8837             nan     0.0500 -28165.3249
    40 17259883.0725             nan     0.0500 -11469.2008
    60 16527687.6401             nan     0.0500 -104335.0197
    80 16071514.8551             nan     0.0500 -33037.9995
   100 15804859.1869             nan     0.0500 -44395.7388
   120 15487885.3101             nan     0.0500 -17040.4358
   140 15284961.6573             nan     0.0500 -12462.1373
   160 15036035.3266             nan     0.0500 -20435.5149
   180 14744476.7597             nan     0.0500 -10362.8090
   200 14526927.6949             nan     0.0500 -54837.4087
   220 14371626.7601             nan     0.0500 -29641.7597
   240 14227407.6804             nan     0.0500 -88593.4874
   260 14045490.6279             nan     0.0500 -30155.2702
   280 13935238.3359             nan     0.0500 1049.9815
   300 13769273.5276             nan     0.0500 -38134.1671

- Fold02.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19630772.4761             nan     0.0500 61381.2080
     2 19476675.5501             nan     0.0500 41651.0653
     3 19336350.1435             nan     0.0500 16066.3218
     4 19239662.8631             nan     0.0500 -12102.3655
     5 19046359.5433             nan     0.0500 -22681.8071
     6 18920155.4230             nan     0.0500 -27131.4251
     7 18725233.0085             nan     0.0500 -36524.9054
     8 18452599.8864             nan     0.0500 41192.0407
     9 18355049.1536             nan     0.0500 -16399.3270
    10 18221463.7495             nan     0.0500 45352.1583
    20 17213115.3844             nan     0.0500 -62324.5276
    40 15497711.3439             nan     0.0500 -53882.2501
    60 13813973.3908             nan     0.0500 -36310.5380
    80 12741592.3014             nan     0.0500 -51673.8534
   100 11926095.3055             nan     0.0500 -98898.7286
   120 11355353.6956             nan     0.0500 -71569.1724
   140 10473077.3491             nan     0.0500 -55044.7305
   160  9894442.0077             nan     0.0500 -50204.9584
   180  9281430.3522             nan     0.0500 -30391.3009
   200  8733580.4208             nan     0.0500 -37834.1274
   220  8221933.3348             nan     0.0500 -29795.0254
   240  7725850.7780             nan     0.0500 -44013.5563
   260  7316536.1903             nan     0.0500 -13382.3447
   280  6947678.9272             nan     0.0500 -57676.3111
   300  6523839.2489             nan     0.0500 -22397.1207

- Fold02.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19484576.4493             nan     0.0500 -80969.8495
     2 19254816.3025             nan     0.0500 118536.1377
     3 18974127.0447             nan     0.0500 85073.1099
     4 18846291.0404             nan     0.0500 -49355.5738
     5 18693581.6840             nan     0.0500 35686.0282
     6 18492036.3649             nan     0.0500 -29852.6043
     7 18309115.1886             nan     0.0500 16194.8035
     8 18139726.2686             nan     0.0500 -34080.8827
     9 18020076.3249             nan     0.0500 -37661.5523
    10 17824868.3579             nan     0.0500 -27516.9061
    20 16504883.9580             nan     0.0500 36017.5100
    40 14840303.4842             nan     0.0500 -92512.6654
    60 13314179.2660             nan     0.0500 -12355.7437
    80 11806155.1435             nan     0.0500 -70269.7338
   100 10742564.9859             nan     0.0500 -38797.0638
   120  9685117.3011             nan     0.0500 -38382.9943
   140  8781483.6424             nan     0.0500 -88309.8274
   160  7962484.3983             nan     0.0500 -15349.6552
   180  7306400.6396             nan     0.0500 -41243.2014
   200  6708057.7594             nan     0.0500 -43914.1004
   220  6225167.1048             nan     0.0500 -26305.4718
   240  5760931.2099             nan     0.0500 -24470.8584
   260  5261966.2649             nan     0.0500 -17123.5632
   280  4924541.3614             nan     0.0500 -78668.0718
   300  4573768.1932             nan     0.0500 -11442.5790

- Fold02.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16347318.5846             nan     0.0100 -1180.7620
     2 16337578.0143             nan     0.0100 9683.6667
     3 16327878.1810             nan     0.0100 4996.7730
     4 16303629.5867             nan     0.0100 1598.9890
     5 16292604.4613             nan     0.0100 8942.9164
     6 16280402.1196             nan     0.0100 -3576.3624
     7 16258901.9853             nan     0.0100 3172.7990
     8 16232857.9302             nan     0.0100 3774.8198
     9 16219729.3099             nan     0.0100 8001.8414
    10 16209959.0164             nan     0.0100 9515.8962
    20 16072518.8138             nan     0.0100 1101.6255
    40 15809230.9135             nan     0.0100 -6633.5604
    60 15527331.3195             nan     0.0100 3256.6275
    80 15312216.2487             nan     0.0100 4757.9369
   100 15108084.4515             nan     0.0100 -2460.9215
   120 14951314.0362             nan     0.0100 -9165.4437
   140 14794772.9848             nan     0.0100 -4760.9865
   160 14641623.8520             nan     0.0100 -6437.4092
   180 14500803.7956             nan     0.0100 -4008.7354
   200 14378513.5880             nan     0.0100 -6619.2963
   220 14278047.7734             nan     0.0100 -2582.7525
   240 14164590.2863             nan     0.0100 -9759.7595
   260 14048011.6087             nan     0.0100 -9722.6938
   280 13957396.6210             nan     0.0100 -3530.0886
   300 13876326.5137             nan     0.0100 -1746.4637

- Fold03.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16349813.1071             nan     0.0100 10719.4650
     2 16320171.0480             nan     0.0100 18434.8319
     3 16287079.8924             nan     0.0100  288.5292
     4 16254242.4899             nan     0.0100 -8650.5866
     5 16228077.5391             nan     0.0100 17944.2844
     6 16176759.5647             nan     0.0100 -8038.3793
     7 16155950.6830             nan     0.0100  457.5945
     8 16139141.3818             nan     0.0100 -2322.0678
     9 16117177.3150             nan     0.0100 8233.6843
    10 16067116.3845             nan     0.0100 31188.1659
    20 15835696.2453             nan     0.0100 1234.2622
    40 15326298.4577             nan     0.0100 3370.9316
    60 14950314.0823             nan     0.0100 -748.9104
    80 14575795.9933             nan     0.0100 -2100.8584
   100 14213201.5636             nan     0.0100 2949.1712
   120 13893545.2701             nan     0.0100 1457.2152
   140 13527334.4967             nan     0.0100 -5133.9583
   160 13177997.2025             nan     0.0100 -8072.1354
   180 12944809.6417             nan     0.0100 -2846.3701
   200 12747705.7305             nan     0.0100 -8250.4139
   220 12519097.9985             nan     0.0100 -529.6038
   240 12262244.6002             nan     0.0100 -12679.2653
   260 12029281.1017             nan     0.0100 -8639.2400
   280 11808726.2646             nan     0.0100 -3635.9135
   300 11645601.7350             nan     0.0100 -8932.7394

- Fold03.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16352875.1364             nan     0.0100 1289.5453
     2 16323274.2504             nan     0.0100 3077.0747
     3 16297799.1479             nan     0.0100 10617.6377
     4 16244031.5373             nan     0.0100 11134.9588
     5 16199704.8320             nan     0.0100 3599.2014
     6 16146931.6083             nan     0.0100 5612.6015
     7 16092178.9233             nan     0.0100 16043.5211
     8 16059211.5805             nan     0.0100 6978.6321
     9 16014830.3338             nan     0.0100 24201.3408
    10 15986673.6331             nan     0.0100 14270.8925
    20 15645424.4650             nan     0.0100 4108.9573
    40 15040378.9079             nan     0.0100 -311.5084
    60 14532324.6387             nan     0.0100 -14114.4513
    80 13973673.6820             nan     0.0100 -9419.8815
   100 13502703.9080             nan     0.0100 -3540.3587
   120 13092437.6807             nan     0.0100 -9501.7444
   140 12745856.2098             nan     0.0100 -5968.1686
   160 12427511.0263             nan     0.0100 -2210.2381
   180 12091865.6829             nan     0.0100 -13155.6454
   200 11808560.0180             nan     0.0100 -9713.5031
   220 11534013.5490             nan     0.0100 -7011.8784
   240 11280541.5396             nan     0.0100 -3043.2834
   260 11078436.4709             nan     0.0100 -2325.1853
   280 10823293.3700             nan     0.0100 -10804.0124
   300 10608410.6793             nan     0.0100 -14974.8589

- Fold03.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16366025.3232             nan     0.0200 -3658.5188
     2 16329204.6270             nan     0.0200 5485.8937
     3 16308623.9363             nan     0.0200 -9610.5482
     4 16290372.0252             nan     0.0200 20548.3895
     5 16277309.2673             nan     0.0200 -4652.1703
     6 16267246.4143             nan     0.0200 -1326.8268
     7 16257114.2732             nan     0.0200 -582.4076
     8 16209085.2625             nan     0.0200 -3709.1529
     9 16190897.9148             nan     0.0200 5913.6574
    10 16158585.8526             nan     0.0200 4304.5085
    20 15928536.2101             nan     0.0200 10247.7901
    40 15424831.8445             nan     0.0200 -23640.3591
    60 15010901.8767             nan     0.0200 -11611.9624
    80 14719375.9649             nan     0.0200 -5015.8728
   100 14469344.2076             nan     0.0200 -6578.7881
   120 14244296.9486             nan     0.0200 -24370.1152
   140 14044333.7976             nan     0.0200 -4699.4322
   160 13899023.9410             nan     0.0200 -30043.5622
   180 13753984.5215             nan     0.0200 -23663.9064
   200 13610194.9866             nan     0.0200 -20410.0821
   220 13492178.9636             nan     0.0200 -18010.2739
   240 13392484.3104             nan     0.0200 -10857.4735
   260 13303048.9691             nan     0.0200 -6980.2798
   280 13227583.1268             nan     0.0200 -14620.9209
   300 13154042.9595             nan     0.0200 -2728.1674

- Fold03.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16297448.0195             nan     0.0200 -11096.5738
     2 16222343.4341             nan     0.0200 21041.0313
     3 16118139.0502             nan     0.0200 32453.7577
     4 16053233.1069             nan     0.0200 13619.6110
     5 15992633.1931             nan     0.0200 1811.6981
     6 15944827.3909             nan     0.0200 -4961.0061
     7 15904426.7970             nan     0.0200 25277.7963
     8 15883886.6067             nan     0.0200 2850.7953
     9 15800013.0917             nan     0.0200 -10991.0301
    10 15751843.5494             nan     0.0200 11171.5006
    20 15274945.0598             nan     0.0200 -21949.2233
    40 14440411.4633             nan     0.0200 -3041.7010
    60 13751188.3733             nan     0.0200 -15677.7213
    80 13046789.7213             nan     0.0200 -23466.8621
   100 12594415.4730             nan     0.0200 -343.0348
   120 12106235.1989             nan     0.0200 -17470.4915
   140 11698252.5096             nan     0.0200 -14467.1159
   160 11316822.2953             nan     0.0200 1996.1400
   180 10967995.0884             nan     0.0200 -6355.5096
   200 10593308.0783             nan     0.0200 -11199.1362
   220 10216575.7255             nan     0.0200 -18652.4700
   240  9893424.4526             nan     0.0200 -17592.9285
   260  9663648.6290             nan     0.0200 -15995.9337
   280  9453024.3733             nan     0.0200 -11564.8298
   300  9275383.4037             nan     0.0200 -16345.4981

- Fold03.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16309684.1171             nan     0.0200 30746.3636
     2 16258080.8371             nan     0.0200 19560.2922
     3 16216775.5535             nan     0.0200 32852.8460
     4 16139929.0727             nan     0.0200 28668.1222
     5 16078892.8145             nan     0.0200 30439.5567
     6 16011859.5746             nan     0.0200 -456.7504
     7 15929713.0322             nan     0.0200 15626.9252
     8 15892084.0572             nan     0.0200 6684.2986
     9 15811879.8102             nan     0.0200 23004.6058
    10 15758481.2403             nan     0.0200 3536.3819
    20 15213704.3059             nan     0.0200 29542.2223
    40 14261878.8630             nan     0.0200 -14997.5546
    60 13540740.0344             nan     0.0200 -3778.3527
    80 12782713.4263             nan     0.0200 -8496.3622
   100 12131771.6524             nan     0.0200 -24558.7072
   120 11673309.4264             nan     0.0200 -23269.3615
   140 11219189.8379             nan     0.0200 9214.8947
   160 10785807.6052             nan     0.0200 -20152.5181
   180 10293156.4972             nan     0.0200 -24786.4302
   200  9894973.7849             nan     0.0200 -29864.4928
   220  9531800.8388             nan     0.0200 -11345.0723
   240  9132643.0247             nan     0.0200 -17130.2020
   260  8863702.5291             nan     0.0200 -7924.9676
   280  8459824.3060             nan     0.0200 -16792.0230
   300  8186330.1309             nan     0.0200 -7615.8064

- Fold03.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16272492.7931             nan     0.0500 14793.9033
     2 16224149.0736             nan     0.0500 -6300.8909
     3 16116740.1022             nan     0.0500 4878.2198
     4 16061781.7594             nan     0.0500 45472.8642
     5 16025712.0295             nan     0.0500 31112.8599
     6 15941516.2536             nan     0.0500 7403.2655
     7 15904176.8714             nan     0.0500 -771.6164
     8 15813941.5592             nan     0.0500 12764.5234
     9 15745548.3711             nan     0.0500 -15898.9740
    10 15666884.3881             nan     0.0500 42111.6054
    20 15173894.8798             nan     0.0500 -2693.4954
    40 14496548.3530             nan     0.0500 -34653.0191
    60 13981732.5599             nan     0.0500 -707.7550
    80 13587168.8854             nan     0.0500 -33869.3635
   100 13409890.3706             nan     0.0500 -45116.9812
   120 13189264.9726             nan     0.0500 -31560.7048
   140 12968941.2813             nan     0.0500 -39864.3775
   160 12761137.6211             nan     0.0500 -10461.5142
   180 12539303.3399             nan     0.0500 -23381.9114
   200 12370603.2887             nan     0.0500 -7354.4265
   220 12235977.2155             nan     0.0500 -19385.6633
   240 12075115.2119             nan     0.0500 -18850.4940
   260 11978848.7166             nan     0.0500 -35207.6810
   280 11850614.2721             nan     0.0500 -74424.5555
   300 11710043.7567             nan     0.0500 -43859.1158

- Fold03.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16207004.9612             nan     0.0500 -1726.1387
     2 16040240.3707             nan     0.0500 -25064.9709
     3 15844200.4244             nan     0.0500 15152.7058
     4 15667396.4751             nan     0.0500 -4881.8025
     5 15600087.0469             nan     0.0500 -27359.6974
     6 15484954.3299             nan     0.0500 -2838.0755
     7 15333780.0812             nan     0.0500 11682.0945
     8 15181359.5778             nan     0.0500 -25162.6814
     9 15063512.0480             nan     0.0500 -56671.1942
    10 14902954.6523             nan     0.0500 -54828.3842
    20 14046706.5565             nan     0.0500 -15843.6957
    40 12635418.2264             nan     0.0500 -30322.4133
    60 11522902.2784             nan     0.0500 -33384.8119
    80 10676418.5127             nan     0.0500 -845.4811
   100  9994001.2624             nan     0.0500 -53703.5011
   120  9401700.2202             nan     0.0500 -30264.0060
   140  8839514.6764             nan     0.0500 -27562.7081
   160  8275063.6295             nan     0.0500 -40215.2210
   180  7761467.8538             nan     0.0500 -47244.1108
   200  7236739.0064             nan     0.0500 -20635.5862
   220  6754052.9681             nan     0.0500 -35952.4179
   240  6412259.5653             nan     0.0500 -22888.8047
   260  6117019.5517             nan     0.0500 -15020.4985
   280  5887399.3196             nan     0.0500 -25156.7406
   300  5568789.0179             nan     0.0500 -16119.2467

- Fold03.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 16252010.2390             nan     0.0500 -40038.2476
     2 16123292.4969             nan     0.0500 -15696.7590
     3 15904462.9987             nan     0.0500 -11746.6234
     4 15792918.3765             nan     0.0500 33954.1320
     5 15671288.8895             nan     0.0500 -23718.7437
     6 15416871.0555             nan     0.0500 -45750.8967
     7 15219543.6648             nan     0.0500 32396.0198
     8 15092096.0117             nan     0.0500 -13200.0144
     9 14901194.4990             nan     0.0500 -50452.8683
    10 14788392.1557             nan     0.0500 50176.4226
    20 13733017.8219             nan     0.0500 -28098.9609
    40 11975442.0270             nan     0.0500 93040.5724
    60 10851672.6588             nan     0.0500  539.7660
    80  9601623.5960             nan     0.0500 -22350.5621
   100  8665334.4067             nan     0.0500 -79617.9505
   120  7954610.2803             nan     0.0500 -29609.3639
   140  7302459.5179             nan     0.0500 -32453.4865
   160  6506963.3170             nan     0.0500 -47216.3344
   180  5984177.3472             nan     0.0500 -39160.6064
   200  5580423.6237             nan     0.0500 -22796.4545
   220  5164031.8667             nan     0.0500 -34784.2408
   240  4825341.2304             nan     0.0500 -10597.5545
   260  4402261.9152             nan     0.0500 -42788.1074
   280  4122918.8790             nan     0.0500 -12480.3624
   300  3766553.1652             nan     0.0500 -16008.3023

- Fold03.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17240470.5155             nan     0.0100 -501.7885
     2 17206320.2410             nan     0.0100 2833.4923
     3 17182040.5603             nan     0.0100 2834.0304
     4 17161872.6144             nan     0.0100 22161.5391
     5 17131405.1790             nan     0.0100 -6818.6935
     6 17120240.7197             nan     0.0100 9256.0438
     7 17097229.4452             nan     0.0100 8728.4487
     8 17064626.7158             nan     0.0100 12056.2782
     9 17036888.5866             nan     0.0100 19653.5057
    10 17021196.2189             nan     0.0100 6699.3049
    20 16826041.5684             nan     0.0100 -334.4802
    40 16507977.3685             nan     0.0100 -1003.8818
    60 16266749.8634             nan     0.0100  678.8625
    80 15991368.1290             nan     0.0100 3488.2525
   100 15782773.7170             nan     0.0100 -5714.6833
   120 15578605.5656             nan     0.0100 -3779.9148
   140 15381618.0439             nan     0.0100 -8477.8616
   160 15210962.0305             nan     0.0100 -8578.3806
   180 15050016.4425             nan     0.0100  923.1536
   200 14905110.9900             nan     0.0100 -1716.8468
   220 14766583.1320             nan     0.0100 -15449.3359
   240 14647519.2999             nan     0.0100 -2153.3343
   260 14547270.4383             nan     0.0100  115.8698
   280 14450050.1805             nan     0.0100 -10481.9066
   300 14341761.6526             nan     0.0100 -11014.4916

- Fold04.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17214569.3637             nan     0.0100 15227.7854
     2 17184591.1581             nan     0.0100 15233.9557
     3 17147317.8771             nan     0.0100 -6318.3199
     4 17106660.4536             nan     0.0100 7926.3918
     5 17093991.9788             nan     0.0100 3253.3306
     6 17042597.9894             nan     0.0100 13153.8298
     7 17007763.5501             nan     0.0100 11447.2260
     8 16977857.3732             nan     0.0100 19263.0652
     9 16955081.0913             nan     0.0100 -5389.7650
    10 16927232.9317             nan     0.0100 -10458.5502
    20 16575314.8136             nan     0.0100  184.5297
    40 16067586.4017             nan     0.0100 -941.8554
    60 15523448.3284             nan     0.0100 -2835.8457
    80 15103776.7877             nan     0.0100 2413.2923
   100 14782506.0407             nan     0.0100 -2685.6969
   120 14453044.9129             nan     0.0100 13478.4295
   140 14239403.3612             nan     0.0100 -10401.3350
   160 13961626.2045             nan     0.0100 -8312.9701
   180 13634524.3925             nan     0.0100 -15333.6588
   200 13357406.5791             nan     0.0100 -14457.3743
   220 13117262.9768             nan     0.0100 -19754.7817
   240 12941677.0208             nan     0.0100 -17765.8599
   260 12719316.7292             nan     0.0100 1874.1499
   280 12474775.3050             nan     0.0100 -6055.7314
   300 12247727.0639             nan     0.0100 -7926.9340

- Fold04.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17223157.0974             nan     0.0100 2328.8409
     2 17170764.8734             nan     0.0100 3383.1766
     3 17132221.7096             nan     0.0100 7786.1987
     4 17105104.6420             nan     0.0100 6471.8470
     5 17059419.9943             nan     0.0100 14318.1224
     6 17025105.2762             nan     0.0100 24786.6897
     7 16976314.1165             nan     0.0100 6164.1746
     8 16942276.1564             nan     0.0100 5283.6633
     9 16891975.8089             nan     0.0100  786.6623
    10 16871314.7723             nan     0.0100 4609.4752
    20 16579460.9521             nan     0.0100 -4240.0721
    40 15992436.7960             nan     0.0100 9680.9676
    60 15453718.9129             nan     0.0100 5961.4718
    80 14850493.7807             nan     0.0100 -2748.4990
   100 14438680.9494             nan     0.0100 -10101.8415
   120 13989075.3119             nan     0.0100 -12988.8221
   140 13598721.4965             nan     0.0100 -5503.6564
   160 13200512.2596             nan     0.0100 -11875.0146
   180 12888130.4683             nan     0.0100 -7365.0895
   200 12583511.3171             nan     0.0100 -4902.8655
   220 12291215.9731             nan     0.0100 -10685.3713
   240 12038500.0197             nan     0.0100 -2299.2867
   260 11811142.6045             nan     0.0100 -6370.9251
   280 11588547.9355             nan     0.0100 -13070.8602
   300 11355952.3400             nan     0.0100 -6295.5808

- Fold04.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17213275.0275             nan     0.0200 -3417.4274
     2 17208637.4224             nan     0.0200 -4467.8649
     3 17174907.5003             nan     0.0200 -10908.5586
     4 17146099.9945             nan     0.0200 14433.6982
     5 17093750.9443             nan     0.0200 -11563.3227
     6 17033825.1654             nan     0.0200 -916.4957
     7 17015804.0643             nan     0.0200 5528.1004
     8 17006891.4840             nan     0.0200 -3830.3261
     9 16956222.5720             nan     0.0200 4539.7425
    10 16932488.9179             nan     0.0200 4176.5267
    20 16652193.0717             nan     0.0200 -11615.2083
    40 16174914.3882             nan     0.0200 -11077.1609
    60 15653007.7002             nan     0.0200 -26216.5426
    80 15252017.8288             nan     0.0200 -21376.1164
   100 14949284.7521             nan     0.0200 -10178.0233
   120 14738313.8966             nan     0.0200 -6252.4106
   140 14482342.4670             nan     0.0200 -5621.8106
   160 14301511.7076             nan     0.0200 -5921.7433
   180 14152549.5314             nan     0.0200 -24816.4493
   200 13982862.7597             nan     0.0200 -9974.0697
   220 13847107.0450             nan     0.0200 -18552.6825
   240 13702572.0858             nan     0.0200 -2557.9620
   260 13609075.5027             nan     0.0200 -13040.3609
   280 13494888.7448             nan     0.0200 -29950.0760
   300 13381081.6312             nan     0.0200 -7934.0345

- Fold04.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17195876.6421             nan     0.0200 19556.2455
     2 17141255.2573             nan     0.0200  666.8289
     3 17039961.6899             nan     0.0200 -619.2178
     4 16994284.2577             nan     0.0200 10601.9553
     5 16950101.2503             nan     0.0200 31731.1252
     6 16886367.0811             nan     0.0200 -18458.4489
     7 16833751.8922             nan     0.0200 19246.8255
     8 16764448.4568             nan     0.0200 -4059.0572
     9 16707474.6971             nan     0.0200 36009.7172
    10 16658462.0667             nan     0.0200 -1184.0238
    20 16095954.4244             nan     0.0200 40354.6018
    40 15220087.6915             nan     0.0200 -6723.9124
    60 14622797.6736             nan     0.0200 -7747.3075
    80 14028487.8918             nan     0.0200 -16558.1199
   100 13509868.9135             nan     0.0200  525.6979
   120 12824933.7997             nan     0.0200 -12122.6915
   140 12506833.8269             nan     0.0200 -19263.7893
   160 12139420.7360             nan     0.0200 -1485.3969
   180 11835708.8480             nan     0.0200 -26416.5633
   200 11398653.0160             nan     0.0200 -20285.8990
   220 11041393.9613             nan     0.0200 -38858.1619
   240 10743878.5288             nan     0.0200 -28850.3054
   260 10485302.4234             nan     0.0200 -20424.2010
   280 10180370.4306             nan     0.0200 -12363.2759
   300  9909061.4146             nan     0.0200 -19567.1016

- Fold04.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17182610.8936             nan     0.0200 64970.4499
     2 17072965.1170             nan     0.0200 7271.1947
     3 17031246.1165             nan     0.0200 -7511.3879
     4 16948655.0531             nan     0.0200 43479.4502
     5 16902292.8601             nan     0.0200 -3563.1263
     6 16833834.7238             nan     0.0200 50654.1123
     7 16779474.2285             nan     0.0200 23635.5663
     8 16756332.7222             nan     0.0200 -24895.3931
     9 16722758.2355             nan     0.0200 -897.9456
    10 16679682.2156             nan     0.0200 17221.8263
    20 15978512.0617             nan     0.0200 23746.9929
    40 15003535.4738             nan     0.0200 -22096.3889
    60 14287005.5409             nan     0.0200 -8959.9411
    80 13608758.0002             nan     0.0200 -19059.1840
   100 12954790.1289             nan     0.0200 -16026.4777
   120 12412122.4919             nan     0.0200 -25196.1188
   140 12031372.8351             nan     0.0200 -27002.9194
   160 11618436.6000             nan     0.0200 -36541.5157
   180 11199811.9167             nan     0.0200 -6743.5646
   200 10810538.9828             nan     0.0200 -33657.7983
   220 10565286.1062             nan     0.0200 -29459.4186
   240 10143954.8504             nan     0.0200 -36166.8857
   260  9792184.8522             nan     0.0200 -28175.4338
   280  9498882.7669             nan     0.0200 -13761.7660
   300  9169857.6080             nan     0.0200 -23747.1118

- Fold04.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17135306.9973             nan     0.0500 120376.8982
     2 16969825.5050             nan     0.0500 -42551.0654
     3 16815772.6819             nan     0.0500 -75539.1763
     4 16717810.8966             nan     0.0500 15585.7675
     5 16696923.0838             nan     0.0500 -25411.9641
     6 16627247.4980             nan     0.0500 -41169.5224
     7 16582960.6277             nan     0.0500 14181.6310
     8 16541641.5030             nan     0.0500 -45916.2778
     9 16422677.3357             nan     0.0500 43988.7055
    10 16295447.4735             nan     0.0500 35726.2581
    20 15640492.2478             nan     0.0500 -72724.9748
    40 14888772.7245             nan     0.0500 -55466.3954
    60 14360004.1536             nan     0.0500 -39776.4588
    80 14006551.6432             nan     0.0500 -57862.9354
   100 13691977.2391             nan     0.0500 -26552.0220
   120 13519898.8042             nan     0.0500 -59769.3631
   140 13292706.5330             nan     0.0500 -46858.4117
   160 13030187.9197             nan     0.0500 -30696.8018
   180 12837472.7333             nan     0.0500 -88761.1357
   200 12685240.4090             nan     0.0500 -25775.0295
   220 12445352.5279             nan     0.0500 -32823.2050
   240 12265887.9767             nan     0.0500 -34417.4119
   260 12056354.7800             nan     0.0500  996.8032
   280 11919392.1163             nan     0.0500 -11133.3308
   300 11801633.5043             nan     0.0500 -40522.0804

- Fold04.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17116421.8738             nan     0.0500 6907.4857
     2 16947189.1407             nan     0.0500 -37050.6924
     3 16844939.6730             nan     0.0500 -26613.7292
     4 16743671.8090             nan     0.0500 5827.2330
     5 16580319.1942             nan     0.0500 3042.0848
     6 16426454.4556             nan     0.0500 79629.5344
     7 16208673.9144             nan     0.0500 -5192.2383
     8 16037061.1277             nan     0.0500 26190.5598
     9 15956160.5216             nan     0.0500 26302.6414
    10 15861900.7423             nan     0.0500 -14522.5172
    20 14803755.0371             nan     0.0500 -51552.6298
    40 13451716.0363             nan     0.0500 -31632.1177
    60 12102016.8669             nan     0.0500 -24544.7299
    80 11387697.8121             nan     0.0500 -63923.8788
   100 10763988.8031             nan     0.0500 -37506.9920
   120 10105659.2383             nan     0.0500 -27220.1741
   140  9654947.1928             nan     0.0500 -44907.7698
   160  8991404.4309             nan     0.0500 -20929.5862
   180  8409942.2485             nan     0.0500 -7609.0196
   200  7910403.1846             nan     0.0500 -25762.7316
   220  7265848.4290             nan     0.0500 -52742.4050
   240  6881225.8357             nan     0.0500 -21275.0690
   260  6498327.9500             nan     0.0500 -22662.8103
   280  6227099.5851             nan     0.0500 -55438.9854
   300  5900314.7249             nan     0.0500 -46778.1998

- Fold04.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17049398.4074             nan     0.0500 -20673.3144
     2 16793670.1495             nan     0.0500 -74444.4139
     3 16578874.8882             nan     0.0500 42477.4996
     4 16378483.0577             nan     0.0500 -8809.1986
     5 16226075.0828             nan     0.0500 31589.6145
     6 16083526.5540             nan     0.0500 24217.2135
     7 15794033.2944             nan     0.0500  451.5459
     8 15578310.3842             nan     0.0500 27256.4887
     9 15492148.5707             nan     0.0500 -48539.2911
    10 15417424.1041             nan     0.0500 23839.4720
    20 14315833.9095             nan     0.0500 -19234.2939
    40 12578118.5013             nan     0.0500 -55051.2107
    60 11433869.2162             nan     0.0500 -57281.7565
    80 10342484.7708             nan     0.0500 -95744.8408
   100  9448122.1144             nan     0.0500 -48502.5192
   120  8517338.2524             nan     0.0500 -57850.0435
   140  7590202.0415             nan     0.0500 -50519.0190
   160  6992198.0456             nan     0.0500 -54816.9563
   180  6395082.8147             nan     0.0500 -19044.9641
   200  5742214.0372             nan     0.0500 -31423.8060
   220  5355394.8182             nan     0.0500 -20489.0035
   240  4908201.6801             nan     0.0500 -38278.7788
   260  4455321.5346             nan     0.0500 -11511.1575
   280  4122461.5232             nan     0.0500 -37069.1876
   300  3848857.7091             nan     0.0500 -14462.1216

- Fold04.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19709433.0868             nan     0.0100 24839.2825
     2 19684239.9060             nan     0.0100 15494.9517
     3 19657185.7756             nan     0.0100 9810.0921
     4 19637808.2576             nan     0.0100 10319.0543
     5 19610009.0788             nan     0.0100 6166.8858
     6 19606266.1394             nan     0.0100 -5197.6286
     7 19587732.9507             nan     0.0100 -2996.6074
     8 19566552.9278             nan     0.0100 5063.4482
     9 19552690.6265             nan     0.0100 -8329.2347
    10 19529786.6372             nan     0.0100 6161.1085
    20 19338362.5646             nan     0.0100 -5815.9241
    40 18990049.4095             nan     0.0100 3473.0230
    60 18641074.4334             nan     0.0100 6910.7082
    80 18351634.4290             nan     0.0100 -1857.0383
   100 18091949.6898             nan     0.0100 -5919.2023
   120 17851592.0467             nan     0.0100 -18150.1328
   140 17640283.4747             nan     0.0100 -7698.6076
   160 17433829.4485             nan     0.0100 2556.2124
   180 17300431.0404             nan     0.0100 -5810.4357
   200 17150026.2401             nan     0.0100 -580.5101
   220 16992312.5827             nan     0.0100 -4767.2468
   240 16860142.5068             nan     0.0100 -6540.8368
   260 16746379.2819             nan     0.0100 -9309.8321
   280 16623243.4995             nan     0.0100 1292.9012
   300 16512316.1864             nan     0.0100 -4123.9978

- Fold05.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19709763.0881             nan     0.0100 23528.8995
     2 19681940.7419             nan     0.0100 8416.3575
     3 19644411.9149             nan     0.0100 16170.4966
     4 19612892.5412             nan     0.0100 26711.6773
     5 19590744.1992             nan     0.0100 2946.7125
     6 19563213.3214             nan     0.0100 3242.9954
     7 19512391.9115             nan     0.0100 1526.0617
     8 19489074.4396             nan     0.0100 2236.2223
     9 19444807.0350             nan     0.0100 -3462.4470
    10 19425298.1779             nan     0.0100 4270.1732
    20 19026497.2000             nan     0.0100 6831.5453
    40 18396402.4069             nan     0.0100 -3060.0064
    60 17913527.2182             nan     0.0100 -586.3770
    80 17336958.6069             nan     0.0100 11615.3346
   100 16900402.5068             nan     0.0100 -824.7501
   120 16455963.0678             nan     0.0100 -5230.7631
   140 16074041.9959             nan     0.0100 -3088.9265
   160 15649227.6576             nan     0.0100 5693.5708
   180 15329149.7801             nan     0.0100 -6836.5460
   200 15024224.2608             nan     0.0100 -11319.4193
   220 14718419.9093             nan     0.0100 -5537.0010
   240 14373792.5561             nan     0.0100 -3039.7572
   260 14138518.2094             nan     0.0100 1665.9640
   280 13861944.5428             nan     0.0100 -7850.2918
   300 13670543.7447             nan     0.0100 -10390.8190

- Fold05.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19704269.0931             nan     0.0100 8488.0494
     2 19657718.4492             nan     0.0100 16505.7177
     3 19627193.6034             nan     0.0100 11060.3635
     4 19565109.4785             nan     0.0100 -2513.7491
     5 19509860.6769             nan     0.0100 23482.9966
     6 19467389.3433             nan     0.0100 2838.5071
     7 19418060.7158             nan     0.0100 -1495.7689
     8 19359545.5937             nan     0.0100 9988.4273
     9 19340691.1731             nan     0.0100 -7735.7758
    10 19307106.3194             nan     0.0100 2809.6720
    20 18849063.9238             nan     0.0100 -7110.7245
    40 18146101.9397             nan     0.0100 8190.6685
    60 17479987.3528             nan     0.0100  787.8310
    80 16915731.9302             nan     0.0100 -6044.5949
   100 16256791.9654             nan     0.0100 -24276.9733
   120 15795075.7641             nan     0.0100 -19889.3327
   140 15410037.8542             nan     0.0100 -14149.8404
   160 15076519.0745             nan     0.0100 -19057.6510
   180 14708519.2417             nan     0.0100 -2704.4581
   200 14309322.9714             nan     0.0100 -9087.5509
   220 13964308.2368             nan     0.0100 -5854.1892
   240 13485004.9235             nan     0.0100 -9375.9745
   260 13180965.9668             nan     0.0100 -18802.6915
   280 12813840.4720             nan     0.0100 -4987.2408
   300 12535094.3116             nan     0.0100 -13932.8830

- Fold05.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19687401.6944             nan     0.0200 12218.5134
     2 19629430.8180             nan     0.0200 -10879.6608
     3 19589068.9655             nan     0.0200 18220.1086
     4 19544371.8804             nan     0.0200 11606.3611
     5 19520578.8773             nan     0.0200 -9464.2193
     6 19438312.7376             nan     0.0200 -4569.0683
     7 19379624.3661             nan     0.0200 19405.1368
     8 19330938.4203             nan     0.0200 18175.7651
     9 19315343.8017             nan     0.0200 5801.9774
    10 19288174.4561             nan     0.0200 -10250.1940
    20 18984546.8849             nan     0.0200 -4504.0865
    40 18326366.4960             nan     0.0200 -1801.4151
    60 17882476.0844             nan     0.0200 -514.2110
    80 17497927.7664             nan     0.0200 -19306.7062
   100 17151343.0583             nan     0.0200 -8028.8354
   120 16905766.6233             nan     0.0200 -18943.3091
   140 16658669.0106             nan     0.0200 -1670.8591
   160 16430251.0206             nan     0.0200 -6883.7430
   180 16227414.4902             nan     0.0200 -8385.3606
   200 16054972.3909             nan     0.0200 -29184.0668
   220 15938472.8984             nan     0.0200 -17629.6883
   240 15835863.1975             nan     0.0200 -59213.8274
   260 15737772.4095             nan     0.0200 -14692.1968
   280 15624455.6325             nan     0.0200 -18894.8066
   300 15502319.7797             nan     0.0200 -25444.4852

- Fold05.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19645454.4674             nan     0.0200 -8427.2423
     2 19560625.3143             nan     0.0200 -2697.0494
     3 19503634.0926             nan     0.0200 11643.9448
     4 19437148.8439             nan     0.0200 3418.0304
     5 19368026.1410             nan     0.0200 13962.6673
     6 19287556.8560             nan     0.0200 -15229.6091
     7 19210039.0330             nan     0.0200 13396.2778
     8 19130999.3694             nan     0.0200 -2533.5712
     9 19071517.3227             nan     0.0200 -1558.5605
    10 19029789.2370             nan     0.0200 -2070.0651
    20 18471810.6514             nan     0.0200 -14249.2705
    40 17423222.0923             nan     0.0200  402.2699
    60 16473580.8630             nan     0.0200 -17240.1998
    80 15614575.2299             nan     0.0200 -7952.8097
   100 14840436.9089             nan     0.0200 -9000.9902
   120 14338278.9985             nan     0.0200 -32787.4677
   140 13817623.5050             nan     0.0200 -18038.1051
   160 13331538.3959             nan     0.0200 -19297.7001
   180 12868645.7428             nan     0.0200 -27832.5444
   200 12565019.0853             nan     0.0200 -18106.8885
   220 12209228.7348             nan     0.0200 -24760.7114
   240 11813940.3745             nan     0.0200 -30928.4941
   260 11551816.9011             nan     0.0200 -39917.0359
   280 11227166.7192             nan     0.0200 -16892.7178
   300 10830532.2859             nan     0.0200 -33664.1261

- Fold05.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19636227.9333             nan     0.0200 24342.0558
     2 19502082.5411             nan     0.0200 17607.7073
     3 19431238.4571             nan     0.0200 -4593.7273
     4 19378666.4965             nan     0.0200 -7897.6185
     5 19204553.7521             nan     0.0200 85002.9723
     6 19126900.3078             nan     0.0200 29184.5777
     7 19050884.6332             nan     0.0200  966.1116
     8 18981432.7723             nan     0.0200 18099.9560
     9 18896781.9042             nan     0.0200 35727.9363
    10 18809592.5078             nan     0.0200 27651.2006
    20 17968073.2624             nan     0.0200 18868.7663
    40 16758558.9770             nan     0.0200 -15584.3427
    60 15668734.4794             nan     0.0200 -16296.8291
    80 14744491.1318             nan     0.0200 -24137.2112
   100 14039438.8637             nan     0.0200 3237.1752
   120 13468361.5156             nan     0.0200 -1184.3347
   140 12891479.2471             nan     0.0200 -31163.7959
   160 12441024.9072             nan     0.0200 -19162.5989
   180 11847853.4543             nan     0.0200 -14430.8292
   200 11376822.8764             nan     0.0200 -13068.1636
   220 11001323.1848             nan     0.0200 -33376.4637
   240 10540308.6746             nan     0.0200 -33095.3641
   260 10180377.1533             nan     0.0200 -33192.9718
   280  9819933.4767             nan     0.0200 -22637.6541
   300  9409697.1574             nan     0.0200 -15205.3185

- Fold05.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19732232.1475             nan     0.0500 -48751.3217
     2 19611066.4940             nan     0.0500  729.9404
     3 19548188.9313             nan     0.0500 49048.1966
     4 19398575.6003             nan     0.0500 79432.9290
     5 19371229.2699             nan     0.0500 -32286.9014
     6 19199747.2526             nan     0.0500 -44872.8632
     7 19155439.9749             nan     0.0500 30004.2772
     8 19021524.9920             nan     0.0500 -40814.8499
     9 18933945.9072             nan     0.0500 36767.1106
    10 18883281.2887             nan     0.0500 -28820.5145
    20 18106963.8550             nan     0.0500 22555.9927
    40 17121445.2513             nan     0.0500 -24670.0505
    60 16483623.7343             nan     0.0500 -109118.4332
    80 16063970.5328             nan     0.0500 18712.0111
   100 15805978.9734             nan     0.0500 -57719.4539
   120 15464909.0461             nan     0.0500 -38194.3213
   140 15173233.2153             nan     0.0500 -13238.1049
   160 14890431.1801             nan     0.0500 -43940.8637
   180 14682151.2248             nan     0.0500 -53244.7015
   200 14490139.2196             nan     0.0500 -76095.3135
   220 14185336.0606             nan     0.0500 -19457.2184
   240 13951707.9474             nan     0.0500 -48109.6494
   260 13778121.6664             nan     0.0500 -24898.3673
   280 13621858.2265             nan     0.0500 -19592.4300
   300 13441316.7953             nan     0.0500 -8572.8890

- Fold05.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19607128.0562             nan     0.0500 48428.6078
     2 19410469.6876             nan     0.0500 38501.2970
     3 19318473.8008             nan     0.0500 20103.4380
     4 19104504.6714             nan     0.0500 -18185.0660
     5 18965197.7828             nan     0.0500 35878.9884
     6 18830989.5265             nan     0.0500 2785.3396
     7 18721040.5132             nan     0.0500 -18122.5246
     8 18640010.3841             nan     0.0500 40195.4508
     9 18554533.3882             nan     0.0500 -15422.7095
    10 18511492.5578             nan     0.0500 -23381.5559
    20 17107595.1316             nan     0.0500 -32357.1346
    40 14913381.2634             nan     0.0500 -64435.6396
    60 13371816.8885             nan     0.0500 -72040.3676
    80 12493963.9781             nan     0.0500 -78349.3230
   100 11663285.8542             nan     0.0500 -21513.7019
   120 10847048.3014             nan     0.0500 -45058.4887
   140 10154605.6527             nan     0.0500 -51791.2663
   160  9464110.7769             nan     0.0500 -46907.9313
   180  9023330.7802             nan     0.0500 13624.7130
   200  8491082.9628             nan     0.0500 -53072.6753
   220  7920031.7447             nan     0.0500 -27216.0974
   240  7501763.8828             nan     0.0500 -34032.2803
   260  6980340.6879             nan     0.0500 -30348.9232
   280  6526006.0610             nan     0.0500 -26599.9664
   300  6166711.8581             nan     0.0500 -54510.7209

- Fold05.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19428026.3212             nan     0.0500 -35811.1858
     2 19296626.5608             nan     0.0500 51310.5669
     3 19131702.0419             nan     0.0500 -49291.7368
     4 18895813.0774             nan     0.0500 -33580.8614
     5 18709388.5212             nan     0.0500 5799.2324
     6 18587554.7626             nan     0.0500 -26764.9041
     7 18432420.7789             nan     0.0500 -56622.0126
     8 18342876.0017             nan     0.0500 10212.5394
     9 18017412.7846             nan     0.0500 144458.9789
    10 17909847.8780             nan     0.0500 -15681.1226
    20 16452768.1321             nan     0.0500 -46187.0986
    40 14495880.2092             nan     0.0500 -83322.3140
    60 12826296.9645             nan     0.0500 -44315.2352
    80 11338073.6580             nan     0.0500 -42553.6209
   100 10199762.4751             nan     0.0500 -52512.4599
   120  9211702.1670             nan     0.0500 -40841.0154
   140  8331377.8031             nan     0.0500 -60727.7349
   160  7654224.7128             nan     0.0500 -63627.4186
   180  7092456.8296             nan     0.0500 -34405.2893
   200  6598825.8089             nan     0.0500 -40983.4284
   220  6071018.4151             nan     0.0500 -22122.3184
   240  5635678.6182             nan     0.0500 -31620.1116
   260  5342119.6354             nan     0.0500 -57933.8593
   280  5018234.0808             nan     0.0500 -27121.1362
   300  4615008.7434             nan     0.0500 -21393.2075

- Fold05.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14697087.0796             nan     0.0100 8941.7021
     2 14691731.9767             nan     0.0100 -2859.0810
     3 14680737.8867             nan     0.0100 -427.1341
     4 14671375.5942             nan     0.0100 2848.1325
     5 14662599.2679             nan     0.0100 -3826.0436
     6 14657906.6194             nan     0.0100 -2653.7156
     7 14652488.3670             nan     0.0100 -1593.0388
     8 14639841.0903             nan     0.0100 -3298.1343
     9 14632491.0644             nan     0.0100 2029.6040
    10 14619445.6959             nan     0.0100 3258.0043
    20 14508328.8737             nan     0.0100 5013.3063
    40 14296470.0041             nan     0.0100 -10844.3834
    60 14117057.9894             nan     0.0100 -4563.7549
    80 13957284.0709             nan     0.0100 -1538.6472
   100 13801020.4276             nan     0.0100 -11736.8350
   120 13636032.0602             nan     0.0100 1022.0093
   140 13491719.8222             nan     0.0100 -2070.8323
   160 13354244.1332             nan     0.0100  660.2443
   180 13256141.8020             nan     0.0100 -4238.0064
   200 13129360.5725             nan     0.0100  928.3255
   220 13017900.7489             nan     0.0100 -3667.1524
   240 12889366.4025             nan     0.0100 -3696.7407
   260 12793538.6156             nan     0.0100 -3094.1844
   280 12690300.6009             nan     0.0100 -3739.5788
   300 12590839.9811             nan     0.0100 -4463.7558

- Fold06.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14685444.0396             nan     0.0100 -5171.3685
     2 14653222.7104             nan     0.0100 -7897.5244
     3 14628682.2488             nan     0.0100 1776.2102
     4 14598152.5347             nan     0.0100 -6333.9751
     5 14567425.3502             nan     0.0100   98.0481
     6 14541212.0212             nan     0.0100 -1033.7310
     7 14529802.2348             nan     0.0100 -4426.6659
     8 14474116.3702             nan     0.0100 13247.3333
     9 14453589.1691             nan     0.0100 -2360.2753
    10 14388382.6376             nan     0.0100  313.5311
    20 13990735.5272             nan     0.0100 -6930.0095
    40 13451414.7286             nan     0.0100 4564.6635
    60 12996724.2115             nan     0.0100 -8122.1619
    80 12487772.9927             nan     0.0100 1401.8988
   100 12136780.6885             nan     0.0100 -4696.1075
   120 11813451.1971             nan     0.0100 -2962.7831
   140 11452775.6404             nan     0.0100 1850.3855
   160 11214803.9601             nan     0.0100 -2464.1373
   180 10962247.0561             nan     0.0100 -6199.0126
   200 10710376.2782             nan     0.0100 2687.6868
   220 10480944.6515             nan     0.0100 -8871.2677
   240 10235278.7300             nan     0.0100 -13606.6542
   260  9998557.4079             nan     0.0100 -8087.0376
   280  9802470.0430             nan     0.0100 -1990.7448
   300  9605000.6773             nan     0.0100 -5808.1936

- Fold06.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14677020.4599             nan     0.0100 19869.8534
     2 14640845.4469             nan     0.0100 5320.3832
     3 14610737.3459             nan     0.0100 1273.2287
     4 14586294.0049             nan     0.0100 4033.3473
     5 14565522.6727             nan     0.0100 7896.5279
     6 14533142.1612             nan     0.0100 3247.4548
     7 14510936.6200             nan     0.0100 -804.7677
     8 14480208.7607             nan     0.0100 17126.6386
     9 14457520.3277             nan     0.0100 1898.7081
    10 14437248.6544             nan     0.0100 -4647.4346
    20 14136178.3490             nan     0.0100 -275.3210
    40 13429866.4563             nan     0.0100 -392.5852
    60 13024943.7193             nan     0.0100 -13934.0351
    80 12554883.6276             nan     0.0100 1432.4697
   100 12131600.9912             nan     0.0100 6413.0170
   120 11591432.6861             nan     0.0100 -10119.9609
   140 11180773.8393             nan     0.0100 -11684.3732
   160 10863070.2109             nan     0.0100 7741.7162
   180 10560483.9324             nan     0.0100 -6573.7658
   200 10168604.6454             nan     0.0100 -8380.0126
   220  9877518.1223             nan     0.0100 -12966.3972
   240  9605090.7780             nan     0.0100 -5801.2211
   260  9310178.3486             nan     0.0100 -10491.4028
   280  8993780.3464             nan     0.0100 -8072.1301
   300  8745734.2144             nan     0.0100 -11992.3479

- Fold06.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14675483.6342             nan     0.0200 -5757.8613
     2 14648769.3489             nan     0.0200 7311.2257
     3 14633902.0289             nan     0.0200 10841.3912
     4 14608056.5882             nan     0.0200 -14851.5419
     5 14584699.0272             nan     0.0200 -20985.4404
     6 14570865.9472             nan     0.0200 -9927.3523
     7 14540853.0522             nan     0.0200  119.0170
     8 14518181.3535             nan     0.0200 -1227.3408
     9 14485378.4673             nan     0.0200  966.0258
    10 14459726.9858             nan     0.0200 8368.0847
    20 14229423.0135             nan     0.0200 -1703.7271
    40 13867548.9494             nan     0.0200 -13163.1223
    60 13568083.0878             nan     0.0200 -21695.0975
    80 13297483.3695             nan     0.0200 -21908.2117
   100 13074620.6772             nan     0.0200 -11467.6525
   120 12849153.1123             nan     0.0200 -12293.8081
   140 12684949.8612             nan     0.0200 -10152.5099
   160 12494043.0169             nan     0.0200 -14373.4131
   180 12339721.3946             nan     0.0200 -4198.5534
   200 12220097.8192             nan     0.0200 -23793.2962
   220 12111452.8541             nan     0.0200 -13145.0463
   240 12000512.3522             nan     0.0200 -14203.2227
   260 11895195.7545             nan     0.0200 -13839.6745
   280 11755406.5522             nan     0.0200 -798.6104
   300 11669647.3977             nan     0.0200 -14703.6986

- Fold06.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14651402.0060             nan     0.0200 12072.3091
     2 14610805.6784             nan     0.0200 8942.6457
     3 14552261.1326             nan     0.0200 38700.1368
     4 14524978.0256             nan     0.0200 2999.4814
     5 14480153.6844             nan     0.0200 -6286.2509
     6 14391993.2673             nan     0.0200 -23491.3128
     7 14352626.1657             nan     0.0200 9942.7432
     8 14307673.3886             nan     0.0200 16408.6777
     9 14285644.1358             nan     0.0200 -9485.8608
    10 14217080.6749             nan     0.0200 -8214.7905
    20 13747819.5149             nan     0.0200 -552.4049
    40 12932771.8442             nan     0.0200 -12763.8876
    60 12196688.0925             nan     0.0200 -10499.4939
    80 11538024.6700             nan     0.0200 -4131.8331
   100 11028415.6429             nan     0.0200 -11901.1424
   120 10494110.3034             nan     0.0200 1519.3019
   140  9949287.7025             nan     0.0200 -21525.8601
   160  9567555.4514             nan     0.0200 4069.3629
   180  9223577.0840             nan     0.0200 -213.6226
   200  8959074.5138             nan     0.0200 -5488.0779
   220  8642787.1496             nan     0.0200 2954.5402
   240  8360081.1034             nan     0.0200 -23197.5165
   260  8032537.9816             nan     0.0200 -8996.5538
   280  7774973.5868             nan     0.0200 -7081.2218
   300  7562808.2626             nan     0.0200 -10879.7743

- Fold06.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14650839.5662             nan     0.0200 19166.3081
     2 14589002.8185             nan     0.0200 12428.9495
     3 14510924.5869             nan     0.0200 16470.1124
     4 14444773.4740             nan     0.0200 22481.1913
     5 14378748.5737             nan     0.0200 -912.0853
     6 14352163.3225             nan     0.0200 -15367.1228
     7 14290863.5268             nan     0.0200 51408.1724
     8 14221353.0056             nan     0.0200 -8015.1908
     9 14088804.1725             nan     0.0200 12435.3373
    10 14040115.0866             nan     0.0200 -24160.9838
    20 13547723.5069             nan     0.0200 -5919.9425
    40 12544157.8671             nan     0.0200 -19596.9300
    60 11687100.7976             nan     0.0200 -24753.5101
    80 11061488.5737             nan     0.0200 -23725.6928
   100 10480120.6488             nan     0.0200 -11641.3086
   120  9833629.7255             nan     0.0200 8476.8253
   140  9241501.6736             nan     0.0200 -26639.7509
   160  8667817.8515             nan     0.0200 -20439.7270
   180  8151136.3540             nan     0.0200 -21142.4801
   200  7753487.8185             nan     0.0200 -10406.0177
   220  7370209.1590             nan     0.0200 -20836.8706
   240  7026445.1711             nan     0.0200 -12966.4086
   260  6682022.8132             nan     0.0200 -12006.8599
   280  6360220.6673             nan     0.0200 -12403.5495
   300  6045223.5892             nan     0.0200 -13833.2625

- Fold06.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14665920.5314             nan     0.0500 22086.5722
     2 14599677.8538             nan     0.0500 -33019.2660
     3 14552966.4645             nan     0.0500 1236.8125
     4 14487255.7598             nan     0.0500 36111.2272
     5 14428413.9863             nan     0.0500 6524.8853
     6 14381624.5527             nan     0.0500 31508.2339
     7 14319511.8770             nan     0.0500 -15653.5559
     8 14260198.5708             nan     0.0500 30213.7919
     9 14186653.7504             nan     0.0500 -26726.9427
    10 14144883.6805             nan     0.0500  318.0735
    20 13686330.5914             nan     0.0500 -28446.9695
    40 12915445.5177             nan     0.0500 -6473.1345
    60 12500801.4730             nan     0.0500 -12619.8876
    80 12147397.8524             nan     0.0500 -18531.0829
   100 11850397.2920             nan     0.0500 -11001.6247
   120 11596641.7091             nan     0.0500 -21495.3461
   140 11385863.3249             nan     0.0500 -43377.3268
   160 11242157.0394             nan     0.0500 -31456.3878
   180 11023645.8902             nan     0.0500 -1009.1168
   200 10837302.6709             nan     0.0500 -44475.9124
   220 10675512.9539             nan     0.0500 -20855.1062
   240 10547394.0586             nan     0.0500 -38010.2246
   260 10388172.0262             nan     0.0500 -72942.6298
   280 10281833.3119             nan     0.0500 -46759.5632
   300 10143257.1908             nan     0.0500 -7850.5284

- Fold06.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14602864.4020             nan     0.0500 23333.5647
     2 14349422.3415             nan     0.0500 20957.1096
     3 14220024.6208             nan     0.0500 10249.4575
     4 14105338.8286             nan     0.0500 40896.6694
     5 13968418.8414             nan     0.0500 13564.0043
     6 13864475.9276             nan     0.0500 -12985.3710
     7 13805835.4024             nan     0.0500 -220.5021
     8 13713257.0418             nan     0.0500 6775.7618
     9 13650486.4054             nan     0.0500 -20622.7852
    10 13550629.8261             nan     0.0500 -9556.2783
    20 12788056.6501             nan     0.0500 -28876.7725
    40 11470590.6687             nan     0.0500 -28053.1838
    60 10555919.9314             nan     0.0500 -44137.2501
    80  9638537.6391             nan     0.0500 -3279.0976
   100  8864324.6610             nan     0.0500 -40722.1920
   120  7954331.3996             nan     0.0500 -53611.0225
   140  7437541.3995             nan     0.0500 -31916.5405
   160  6917246.0348             nan     0.0500 -18331.1505
   180  6452509.7183             nan     0.0500 -15258.4852
   200  6066634.5598             nan     0.0500 -17799.0549
   220  5676378.5779             nan     0.0500 -24954.2030
   240  5315405.9392             nan     0.0500 -29638.3521
   260  5049910.1966             nan     0.0500 -20927.2694
   280  4736226.0091             nan     0.0500 -2062.5290
   300  4494128.3678             nan     0.0500 -26517.5922

- Fold06.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 14519364.6710             nan     0.0500 -16228.7171
     2 14391275.5281             nan     0.0500 37053.0910
     3 14164517.1240             nan     0.0500 97129.7021
     4 14087539.9963             nan     0.0500 -28382.3768
     5 13982674.2868             nan     0.0500 -5949.7409
     6 13687283.3541             nan     0.0500 -67967.6962
     7 13427314.8112             nan     0.0500 29763.7723
     8 13351142.4850             nan     0.0500 -19362.0485
     9 13229178.0090             nan     0.0500 51416.1200
    10 13059571.5184             nan     0.0500 -16147.0808
    20 11889370.0222             nan     0.0500 -17743.0918
    40  9839978.5231             nan     0.0500 -9523.0260
    60  8554464.4303             nan     0.0500 -16640.7951
    80  7718458.0961             nan     0.0500 -22106.8832
   100  6736988.3617             nan     0.0500 -25580.1656
   120  6103872.8651             nan     0.0500 -37551.2203
   140  5477370.7658             nan     0.0500 -16586.5544
   160  4884768.0453             nan     0.0500 -25110.3265
   180  4436855.2641             nan     0.0500 -16234.1569
   200  4048792.0385             nan     0.0500 1192.2763
   220  3647231.1233             nan     0.0500 -13144.7757
   240  3322262.4170             nan     0.0500 -16951.0339
   260  3006422.4566             nan     0.0500 -20496.8935
   280  2776017.1741             nan     0.0500 -11613.1873
   300  2553344.1229             nan     0.0500 -15583.1695

- Fold06.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19631437.1796             nan     0.0100 -10530.1726
     2 19611709.6587             nan     0.0100 -2825.2010
     3 19574499.7407             nan     0.0100 -1746.6769
     4 19563653.9906             nan     0.0100 7547.8337
     5 19549290.5044             nan     0.0100 -2047.6193
     6 19518658.9354             nan     0.0100 6270.1940
     7 19512864.5916             nan     0.0100 -4994.9456
     8 19491017.5829             nan     0.0100 -3691.2322
     9 19470375.9689             nan     0.0100 6462.4072
    10 19459810.8412             nan     0.0100 -7288.1777
    20 19284496.5942             nan     0.0100 4678.2909
    40 18936957.3111             nan     0.0100 -6104.3383
    60 18676182.4254             nan     0.0100 -7063.6370
    80 18432872.7673             nan     0.0100 -5541.6127
   100 18212434.0119             nan     0.0100 -808.3483
   120 17947534.2856             nan     0.0100  752.0226
   140 17747927.2946             nan     0.0100 3688.0734
   160 17586361.2741             nan     0.0100 -4986.6592
   180 17398416.1950             nan     0.0100 5523.7766
   200 17243226.2236             nan     0.0100 -10518.0199
   220 17103543.4186             nan     0.0100 3094.8744
   240 16961500.9958             nan     0.0100 1741.4232
   260 16831263.3191             nan     0.0100 -672.7518
   280 16727057.4544             nan     0.0100 -9313.6121
   300 16616747.3577             nan     0.0100 -415.5946

- Fold07.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19631061.9916             nan     0.0100  -46.4826
     2 19593330.0947             nan     0.0100 -8455.8448
     3 19542483.4210             nan     0.0100 4628.0277
     4 19509644.8549             nan     0.0100 17481.9298
     5 19443843.4909             nan     0.0100 -5871.9284
     6 19397619.3930             nan     0.0100 7846.9319
     7 19354867.4922             nan     0.0100 24250.2536
     8 19319499.5631             nan     0.0100 8773.2633
     9 19304961.7348             nan     0.0100 4636.3424
    10 19284453.4995             nan     0.0100 14393.3599
    20 18891359.0409             nan     0.0100 -7247.2742
    40 18189053.4813             nan     0.0100 10115.2937
    60 17692416.5758             nan     0.0100 -4718.0157
    80 17085856.8147             nan     0.0100 1991.6177
   100 16570320.8857             nan     0.0100   87.6281
   120 16169156.2614             nan     0.0100  148.5130
   140 15859113.4961             nan     0.0100 -10668.9568
   160 15540241.5181             nan     0.0100 -8296.1396
   180 15203025.8117             nan     0.0100 -9275.3784
   200 14878032.4518             nan     0.0100 -8131.5553
   220 14520414.3274             nan     0.0100 -5801.4573
   240 14298455.8828             nan     0.0100 -14592.6713
   260 14079799.7184             nan     0.0100 -405.5566
   280 13845176.6696             nan     0.0100 -9308.3525
   300 13642234.2185             nan     0.0100 -16452.1100

- Fold07.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19610631.9831             nan     0.0100 -4652.3274
     2 19533849.9448             nan     0.0100 17901.4741
     3 19487261.7015             nan     0.0100 17532.5368
     4 19446580.7406             nan     0.0100 -5862.2313
     5 19402381.6860             nan     0.0100 19163.5117
     6 19371994.3963             nan     0.0100 9053.8909
     7 19339447.8896             nan     0.0100 10211.5545
     8 19286858.7528             nan     0.0100 -1580.3917
     9 19252091.7257             nan     0.0100 16433.6789
    10 19170687.8921             nan     0.0100   66.9906
    20 18791298.7679             nan     0.0100 4397.3772
    40 18080100.8410             nan     0.0100 -3294.3150
    60 17463984.0577             nan     0.0100 -10963.6102
    80 16880202.6408             nan     0.0100 8871.9821
   100 16405390.4679             nan     0.0100 -11682.2250
   120 15952884.2982             nan     0.0100 -4671.2602
   140 15366101.4637             nan     0.0100 -6986.0402
   160 15043994.3361             nan     0.0100 -9932.8435
   180 14672578.4792             nan     0.0100 -4679.3215
   200 14283274.8351             nan     0.0100 -13440.9983
   220 13918193.5686             nan     0.0100 12381.3246
   240 13601371.1774             nan     0.0100 -9438.0965
   260 13229533.6317             nan     0.0100 -5454.7453
   280 12890997.2110             nan     0.0100 -12512.3659
   300 12648930.0194             nan     0.0100 -14631.6844

- Fold07.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19626594.7832             nan     0.0200 5277.4008
     2 19574855.4897             nan     0.0200 1750.1026
     3 19507551.1222             nan     0.0200 -26397.6651
     4 19463847.7893             nan     0.0200 24125.5262
     5 19416977.7495             nan     0.0200 -15549.8711
     6 19364827.5733             nan     0.0200 -21332.1637
     7 19321917.3678             nan     0.0200 24756.1825
     8 19282714.1041             nan     0.0200 5531.1635
     9 19216901.1714             nan     0.0200 16258.7017
    10 19189083.3337             nan     0.0200  609.7396
    20 18941852.8466             nan     0.0200  -36.7654
    40 18377037.5008             nan     0.0200 -418.9173
    60 17946966.7719             nan     0.0200 -14999.9583
    80 17543479.7941             nan     0.0200 -557.5680
   100 17247733.8014             nan     0.0200 -29619.8577
   120 17007849.0224             nan     0.0200 -8975.8776
   140 16788098.7832             nan     0.0200 -15408.0752
   160 16586734.7829             nan     0.0200 -28619.6356
   180 16399410.4353             nan     0.0200 -10441.1095
   200 16224673.9677             nan     0.0200 -10427.3622
   220 16112540.8425             nan     0.0200 -16428.2256
   240 15996892.3098             nan     0.0200 -18280.7408
   260 15870625.9535             nan     0.0200 -21589.5703
   280 15764283.5100             nan     0.0200 -16182.0591
   300 15642753.7907             nan     0.0200 -21870.6716

- Fold07.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19538155.6844             nan     0.0200 19064.9705
     2 19436668.0541             nan     0.0200 -13132.3292
     3 19400564.0785             nan     0.0200 -6745.9321
     4 19333339.9067             nan     0.0200 -19419.6383
     5 19292985.2017             nan     0.0200 20613.6513
     6 19193327.0271             nan     0.0200 -19957.7048
     7 19122895.6298             nan     0.0200 -2069.7979
     8 18989803.6895             nan     0.0200 -3035.2665
     9 18889850.5642             nan     0.0200 8696.6727
    10 18820627.7754             nan     0.0200 15056.2232
    20 18146325.3636             nan     0.0200 18444.5024
    40 17138548.9638             nan     0.0200 -27286.0537
    60 16331648.3001             nan     0.0200 -13058.9427
    80 15497537.8326             nan     0.0200 -5784.9906
   100 14674433.1401             nan     0.0200 -24410.4977
   120 14120381.3665             nan     0.0200 -44811.7057
   140 13633598.6003             nan     0.0200 -24134.5470
   160 13251675.0509             nan     0.0200 -21391.0900
   180 12779191.6169             nan     0.0200 -15082.5447
   200 12415137.1690             nan     0.0200 -15197.6513
   220 11962957.4153             nan     0.0200 -15102.7189
   240 11623758.1047             nan     0.0200 -24991.7355
   260 11259487.8600             nan     0.0200 13663.5708
   280 11001941.1615             nan     0.0200 -26536.0469
   300 10747785.6572             nan     0.0200 -24196.7707

- Fold07.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19582434.4874             nan     0.0200 38446.8960
     2 19499691.0549             nan     0.0200 23245.1088
     3 19457959.7178             nan     0.0200 15784.6305
     4 19340458.2397             nan     0.0200 -26875.8689
     5 19269929.8788             nan     0.0200 24144.6696
     6 19216867.1115             nan     0.0200 -5933.7769
     7 19190464.9753             nan     0.0200 -7222.6410
     8 19142418.7803             nan     0.0200 4873.0116
     9 19083677.6623             nan     0.0200 19644.4694
    10 18983454.2015             nan     0.0200 -2066.3452
    20 18221943.9522             nan     0.0200 -13210.6863
    40 17106888.8293             nan     0.0200 -27407.4686
    60 16086899.4953             nan     0.0200 -23569.6484
    80 15232037.3394             nan     0.0200 -13654.3229
   100 14459430.5097             nan     0.0200 -31566.5775
   120 13762946.5485             nan     0.0200 -14565.2330
   140 13034441.5230             nan     0.0200 -23534.4945
   160 12487473.6454             nan     0.0200 -40627.1575
   180 11987976.4041             nan     0.0200 -19785.5853
   200 11518043.6145             nan     0.0200 -7946.5598
   220 10979613.5375             nan     0.0200 -21112.1132
   240 10528524.6911             nan     0.0200 -48974.0239
   260 10160584.3691             nan     0.0200 -18132.7464
   280  9779450.2950             nan     0.0200 -16951.6037
   300  9422243.3434             nan     0.0200 -11754.7064

- Fold07.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19596137.2764             nan     0.0500 -39650.5634
     2 19556447.0958             nan     0.0500 -28897.6641
     3 19430670.6772             nan     0.0500 2488.3038
     4 19314352.9902             nan     0.0500 15738.6360
     5 19255580.8650             nan     0.0500 58750.6944
     6 19192467.6149             nan     0.0500 -19163.9938
     7 19092410.6646             nan     0.0500 48262.2475
     8 19028380.4045             nan     0.0500 -19029.7967
     9 18983786.9472             nan     0.0500 -36466.6275
    10 18938680.0314             nan     0.0500 3434.1447
    20 18220020.4309             nan     0.0500 -48483.1678
    40 17314915.5138             nan     0.0500 -29742.3432
    60 16576879.0714             nan     0.0500 -13240.1511
    80 16145993.4553             nan     0.0500 5737.3996
   100 15890983.3143             nan     0.0500 -33859.5095
   120 15672065.6900             nan     0.0500 -1305.0182
   140 15378406.6948             nan     0.0500 -55197.0562
   160 15096742.1489             nan     0.0500 -49374.0775
   180 14907632.3893             nan     0.0500 -49625.5896
   200 14712776.5991             nan     0.0500 -14102.2486
   220 14500138.0849             nan     0.0500 -36554.9138
   240 14321238.2286             nan     0.0500 -46566.1452
   260 14114336.0102             nan     0.0500 -24161.9391
   280 13983994.2352             nan     0.0500 -31882.5541
   300 13778839.8989             nan     0.0500 -57716.2055

- Fold07.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19550699.8740             nan     0.0500 -26240.1083
     2 19429907.5084             nan     0.0500 27666.1126
     3 19223646.6004             nan     0.0500 -13742.6724
     4 19030175.3129             nan     0.0500  598.0523
     5 18933762.3231             nan     0.0500 23370.8444
     6 18672651.3280             nan     0.0500 -13357.6068
     7 18455160.6176             nan     0.0500 -2829.2452
     8 18402442.4717             nan     0.0500 -14009.4886
     9 18340148.4645             nan     0.0500 -3787.4972
    10 18134087.8187             nan     0.0500 5920.7920
    20 16486738.1943             nan     0.0500 -30408.8297
    40 14794690.6919             nan     0.0500 -77146.4124
    60 13248408.1613             nan     0.0500 -7869.6705
    80 12188725.0669             nan     0.0500 -44194.2109
   100 11202037.0182             nan     0.0500 -40821.4258
   120 10383804.0216             nan     0.0500 -17904.9872
   140  9603052.5628             nan     0.0500 -46264.8926
   160  8986608.0325             nan     0.0500 12708.5712
   180  8491033.2298             nan     0.0500 -54293.6072
   200  7915731.9012             nan     0.0500 -21850.7000
   220  7344121.5281             nan     0.0500 -41886.3579
   240  6934660.8001             nan     0.0500 -14673.5402
   260  6528321.5530             nan     0.0500 -51998.4147
   280  6137099.4296             nan     0.0500 -27608.6202
   300  5794126.2228             nan     0.0500 -28325.3346

- Fold07.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19383663.5004             nan     0.0500 79524.4678
     2 19177304.4630             nan     0.0500 32905.2368
     3 18923763.4417             nan     0.0500 -66368.1784
     4 18732517.3900             nan     0.0500 -20301.0604
     5 18421263.3202             nan     0.0500 47443.2243
     6 18283545.9644             nan     0.0500 -6318.1007
     7 18144931.6694             nan     0.0500  752.3784
     8 18015475.7797             nan     0.0500 43902.9112
     9 17945700.5752             nan     0.0500 -48800.6035
    10 17733396.2434             nan     0.0500 -49011.9830
    20 16570530.2466             nan     0.0500 -28037.8064
    40 14463141.5676             nan     0.0500 -12817.5092
    60 12586561.6034             nan     0.0500 -57040.0517
    80 11192761.3186             nan     0.0500 -4438.7444
   100  9854535.0188             nan     0.0500 -69247.9600
   120  8925085.8693             nan     0.0500 -18855.0814
   140  8174904.4287             nan     0.0500 -38964.3362
   160  7418957.5183             nan     0.0500 -37322.0202
   180  6771247.9410             nan     0.0500 -53320.4888
   200  6380173.2535             nan     0.0500 -25782.1439
   220  5841385.6803             nan     0.0500 -46799.2938
   240  5452858.4495             nan     0.0500 -33984.3005
   260  5040797.6537             nan     0.0500 -19829.7748
   280  4592597.7056             nan     0.0500 -14306.5035
   300  4283674.7097             nan     0.0500 -30718.7920

- Fold07.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19121011.7814             nan     0.0100 3040.2332
     2 19091749.0003             nan     0.0100 -1773.6868
     3 19065488.1430             nan     0.0100 -161.1831
     4 19043923.9461             nan     0.0100 9574.6699
     5 19037989.0309             nan     0.0100 -6169.6082
     6 19019040.6800             nan     0.0100 3590.3716
     7 19009271.1778             nan     0.0100 6196.4243
     8 18983801.2101             nan     0.0100 -2207.7132
     9 18953199.5284             nan     0.0100  890.7943
    10 18948019.5855             nan     0.0100 -6672.0114
    20 18794521.9868             nan     0.0100 4124.6600
    40 18442407.9534             nan     0.0100 3013.4449
    60 18128796.7564             nan     0.0100 -368.1507
    80 17837805.6299             nan     0.0100 -4120.6080
   100 17562461.3134             nan     0.0100 3049.1789
   120 17359402.6511             nan     0.0100 -1621.6019
   140 17132049.9920             nan     0.0100 3566.8841
   160 16926682.4465             nan     0.0100 -175.2054
   180 16748422.8677             nan     0.0100 -1255.7101
   200 16605877.6975             nan     0.0100 -5536.1730
   220 16481092.2301             nan     0.0100 -2129.5931
   240 16353855.4248             nan     0.0100 -8690.5270
   260 16254997.7529             nan     0.0100 -17003.6213
   280 16133405.7477             nan     0.0100 -2707.3187
   300 16038059.7354             nan     0.0100 -1652.3639

- Fold08.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19090243.9691             nan     0.0100 3666.8683
     2 19030764.0326             nan     0.0100 3339.6041
     3 18974144.5590             nan     0.0100 -4055.6317
     4 18949411.1781             nan     0.0100 7009.1749
     5 18912184.2157             nan     0.0100 -5683.4772
     6 18872484.0020             nan     0.0100 1248.5008
     7 18815119.5066             nan     0.0100 -3191.0397
     8 18763489.3123             nan     0.0100 11673.7712
     9 18704474.4828             nan     0.0100 -2583.4134
    10 18692860.7287             nan     0.0100 -8234.5837
    20 18340886.2839             nan     0.0100 -2957.2927
    40 17772439.4982             nan     0.0100 -2194.2383
    60 17222119.2602             nan     0.0100 3181.4747
    80 16732834.1735             nan     0.0100 -514.2644
   100 16334829.7944             nan     0.0100 -22717.9100
   120 15959611.2173             nan     0.0100 5965.8140
   140 15624570.7781             nan     0.0100 -17887.1685
   160 15359392.9220             nan     0.0100 -6838.3229
   180 15076435.1877             nan     0.0100 8620.0847
   200 14724705.3517             nan     0.0100 -17903.2497
   220 14489141.1502             nan     0.0100 -11895.4202
   240 14041029.6255             nan     0.0100 -23197.6969
   260 13769581.3085             nan     0.0100 2887.0169
   280 13528296.3967             nan     0.0100 -13274.5906
   300 13281638.7576             nan     0.0100 -1944.1035

- Fold08.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19101666.9908             nan     0.0100 6555.2874
     2 19067133.8918             nan     0.0100 16033.3019
     3 19015144.7682             nan     0.0100 39639.6772
     4 18964396.9834             nan     0.0100 25459.6667
     5 18892591.9233             nan     0.0100 20641.5926
     6 18863969.3951             nan     0.0100 -5359.5867
     7 18815506.9107             nan     0.0100 25722.8285
     8 18796829.0338             nan     0.0100 -8204.1321
     9 18778948.6657             nan     0.0100 -1971.5649
    10 18740848.2939             nan     0.0100 11331.3376
    20 18389579.9339             nan     0.0100 -648.1480
    40 17740306.4702             nan     0.0100 9666.0103
    60 17047850.8598             nan     0.0100 -1248.7550
    80 16507180.9281             nan     0.0100 4266.6572
   100 15981593.5714             nan     0.0100 -13896.2275
   120 15397326.4686             nan     0.0100 -3704.8487
   140 15016282.2250             nan     0.0100 -7129.8470
   160 14575300.3491             nan     0.0100 17485.1108
   180 14202415.8589             nan     0.0100 -13551.7523
   200 13828467.3126             nan     0.0100 -21802.5011
   220 13440900.2111             nan     0.0100 -8294.6730
   240 13175409.4582             nan     0.0100 -21615.1605
   260 12934132.9113             nan     0.0100 -11617.1257
   280 12636064.0894             nan     0.0100 -14423.6311
   300 12348969.6115             nan     0.0100 -11757.1237

- Fold08.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19097611.0869             nan     0.0200 1140.9601
     2 19050750.0952             nan     0.0200 5133.6270
     3 19027633.7792             nan     0.0200 -17866.5073
     4 19009140.3403             nan     0.0200 -6035.3371
     5 18965771.8552             nan     0.0200 9514.5743
     6 18908268.4993             nan     0.0200  807.9151
     7 18860084.5133             nan     0.0200 -2797.8790
     8 18843609.9966             nan     0.0200 -5974.3306
     9 18820451.7174             nan     0.0200 6849.4973
    10 18791084.3682             nan     0.0200 -8150.9739
    20 18479563.7502             nan     0.0200 6816.8773
    40 17951316.7143             nan     0.0200 3273.6133
    60 17455290.6964             nan     0.0200 -17447.3943
    80 17076387.6148             nan     0.0200 -19200.8488
   100 16786367.6315             nan     0.0200 -28137.7780
   120 16560952.5074             nan     0.0200 -20401.3043
   140 16309184.9007             nan     0.0200 -13787.2564
   160 16058961.9887             nan     0.0200 -19173.8032
   180 15895643.8724             nan     0.0200 -18840.9485
   200 15719448.6277             nan     0.0200 -12717.0172
   220 15593152.1691             nan     0.0200 2706.4780
   240 15434238.2603             nan     0.0200 -23996.1673
   260 15314805.8697             nan     0.0200 -39520.1856
   280 15155269.1013             nan     0.0200 -22864.7965
   300 15054780.7332             nan     0.0200 -2703.6964

- Fold08.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19053408.4339             nan     0.0200 -7652.3006
     2 18965931.5611             nan     0.0200 44427.8039
     3 18878756.5284             nan     0.0200 -3368.5441
     4 18833217.0222             nan     0.0200 -11008.1623
     5 18706262.9424             nan     0.0200 -1255.2685
     6 18646641.4298             nan     0.0200 3601.4098
     7 18580723.0965             nan     0.0200 -14560.4558
     8 18522340.7698             nan     0.0200 18846.5153
     9 18440234.8402             nan     0.0200 -18773.9813
    10 18377233.2992             nan     0.0200 36450.3807
    20 17887963.8432             nan     0.0200 -28832.1218
    40 16846191.1992             nan     0.0200 11228.2519
    60 15799062.4785             nan     0.0200 -20301.7971
    80 15046774.6930             nan     0.0200 -28312.3388
   100 14525610.5801             nan     0.0200 -19743.5131
   120 14054550.2090             nan     0.0200 16256.2775
   140 13601109.8372             nan     0.0200 -38914.8110
   160 13201267.1695             nan     0.0200 -37060.1784
   180 12787474.0400             nan     0.0200 -15692.6768
   200 12317525.3337             nan     0.0200 -32707.8854
   220 11863114.8388             nan     0.0200 -18040.3148
   240 11516437.2790             nan     0.0200 -37605.5268
   260 11182764.9324             nan     0.0200 -33158.6438
   280 10792608.0092             nan     0.0200 -2910.6691
   300 10571445.4950             nan     0.0200 -18103.5913

- Fold08.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19047397.6069             nan     0.0200 31262.6780
     2 18932426.2009             nan     0.0200 29789.4042
     3 18811335.7177             nan     0.0200 8397.2154
     4 18770072.2845             nan     0.0200 11946.1894
     5 18696326.2598             nan     0.0200 37991.5186
     6 18591418.8957             nan     0.0200 19147.5042
     7 18546193.4298             nan     0.0200 -24808.5993
     8 18434183.1902             nan     0.0200 35891.2137
     9 18349413.6119             nan     0.0200 20806.8923
    10 18286642.3133             nan     0.0200 5637.3994
    20 17797392.6280             nan     0.0200 -5031.1489
    40 16609430.3004             nan     0.0200 40270.4170
    60 15714038.6136             nan     0.0200 -6505.9635
    80 14858659.2428             nan     0.0200 -16454.0343
   100 14063768.7730             nan     0.0200 -23217.4190
   120 13446048.7818             nan     0.0200 -22848.6926
   140 12865347.6728             nan     0.0200 -13128.2074
   160 12286848.2925             nan     0.0200 -17520.9034
   180 11758614.7824             nan     0.0200 -33205.8327
   200 11276349.1651             nan     0.0200 -16324.7153
   220 10792445.1831             nan     0.0200 -45204.5113
   240 10412677.0650             nan     0.0200 -16204.3617
   260  9914849.9223             nan     0.0200 -30599.2223
   280  9516130.7796             nan     0.0200 -22706.2924
   300  9206741.3023             nan     0.0200 -17083.8950

- Fold08.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19017868.1452             nan     0.0500 13264.9099
     2 18914510.4487             nan     0.0500 13793.1720
     3 18810925.2295             nan     0.0500 24615.7710
     4 18745907.8459             nan     0.0500 -1752.7558
     5 18645571.2634             nan     0.0500 16477.9633
     6 18530997.5563             nan     0.0500 -45141.5322
     7 18422688.3648             nan     0.0500 37435.3466
     8 18344441.2196             nan     0.0500 28506.6679
     9 18263071.9922             nan     0.0500 -43197.0722
    10 18233505.1639             nan     0.0500 -10488.8425
    20 17651926.3306             nan     0.0500 -26008.6141
    40 16768007.5040             nan     0.0500 -20412.4693
    60 16182325.6042             nan     0.0500 -38580.1574
    80 15794386.2420             nan     0.0500 -30497.6150
   100 15385006.4701             nan     0.0500 -33058.8109
   120 15114541.3660             nan     0.0500 -56445.4622
   140 14929286.6556             nan     0.0500 -24548.2545
   160 14695410.7885             nan     0.0500 -10733.4188
   180 14448849.6528             nan     0.0500 -50650.7579
   200 14249665.1469             nan     0.0500 -75307.2995
   220 14112758.5305             nan     0.0500 -63786.5274
   240 13826741.2770             nan     0.0500 -20433.3700
   260 13646628.3056             nan     0.0500 -35300.3873
   280 13446839.7783             nan     0.0500 -66009.8875
   300 13312488.1901             nan     0.0500 -41579.3032

- Fold08.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19016334.1982             nan     0.0500 -13481.2048
     2 18927073.2991             nan     0.0500 40309.1481
     3 18782645.1506             nan     0.0500 88521.6116
     4 18594901.8471             nan     0.0500 -24703.5203
     5 18515520.8876             nan     0.0500 59503.4554
     6 18412403.7477             nan     0.0500 -29593.1501
     7 18275614.6105             nan     0.0500 -29759.7427
     8 18194622.9438             nan     0.0500 -43724.3720
     9 18123688.3048             nan     0.0500 -32540.9481
    10 17918398.9933             nan     0.0500 11383.5206
    20 16563756.6485             nan     0.0500 18990.5325
    40 15047402.9947             nan     0.0500 -88300.7104
    60 13531445.9635             nan     0.0500 32722.5582
    80 12496515.9341             nan     0.0500 -57221.2053
   100 11524335.1901             nan     0.0500 -58425.8202
   120 10560286.3173             nan     0.0500 -16587.3176
   140 10037899.3714             nan     0.0500 -34907.0111
   160  9274339.0760             nan     0.0500 -63842.9495
   180  8605394.1500             nan     0.0500 -29916.6874
   200  8017860.0597             nan     0.0500 -32107.7290
   220  7549462.8547             nan     0.0500 -4319.1963
   240  6999145.6867             nan     0.0500 -34705.6822
   260  6583597.1253             nan     0.0500 -27267.7170
   280  6232631.8683             nan     0.0500 -26357.1702
   300  5856343.1851             nan     0.0500 -14211.7835

- Fold08.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18890180.7003             nan     0.0500 158687.1858
     2 18429459.9504             nan     0.0500 5458.3183
     3 18228668.1308             nan     0.0500 -27570.6980
     4 18061382.5060             nan     0.0500 54506.2531
     5 17936795.3128             nan     0.0500 -25550.5676
     6 17818456.8976             nan     0.0500 95617.1377
     7 17520675.8976             nan     0.0500 103802.8614
     8 17420897.0933             nan     0.0500 13239.7406
     9 17267948.0780             nan     0.0500 -63243.1438
    10 17166740.5966             nan     0.0500 -26572.9085
    20 16051834.9856             nan     0.0500 -4655.5186
    40 13825875.3117             nan     0.0500 -52724.7568
    60 12397201.7652             nan     0.0500 -60115.1278
    80 10920855.7342             nan     0.0500 -30885.2173
   100  9833762.7001             nan     0.0500 -58296.4311
   120  8912148.9170             nan     0.0500 -47785.3893
   140  8186724.7662             nan     0.0500 -39127.8030
   160  7659275.9405             nan     0.0500 -41523.4147
   180  6992231.2063             nan     0.0500 -30961.8052
   200  6449607.1475             nan     0.0500 -53386.6552
   220  5776173.3588             nan     0.0500 -33562.5937
   240  5369505.7205             nan     0.0500 -35139.2640
   260  4997215.8232             nan     0.0500 -21141.9739
   280  4672992.2388             nan     0.0500 -9646.8771
   300  4310485.9531             nan     0.0500 -24447.4159

- Fold08.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17273574.0648             nan     0.0100  951.9967
     2 17252025.8684             nan     0.0100 2781.9875
     3 17235335.6197             nan     0.0100 7268.3928
     4 17224143.6661             nan     0.0100 5894.5685
     5 17211748.5692             nan     0.0100 2869.3023
     6 17189432.0555             nan     0.0100 16855.7082
     7 17177311.4841             nan     0.0100 1075.0365
     8 17168573.2329             nan     0.0100 -3289.5716
     9 17150697.6648             nan     0.0100 9339.1136
    10 17138886.5566             nan     0.0100 -5893.6586
    20 16990974.0455             nan     0.0100 9750.3605
    40 16729662.5777             nan     0.0100 5992.3352
    60 16469504.3194             nan     0.0100 -8941.0305
    80 16294948.7895             nan     0.0100 -6760.0108
   100 16082071.3928             nan     0.0100 1943.3847
   120 15908686.1799             nan     0.0100 4632.2765
   140 15744361.0456             nan     0.0100 -988.8579
   160 15575669.9345             nan     0.0100 -1065.2723
   180 15431344.1343             nan     0.0100 -2074.7110
   200 15298640.5891             nan     0.0100 -4734.6896
   220 15183658.1614             nan     0.0100 -5817.2547
   240 15054871.7442             nan     0.0100 -4639.5091
   260 14961065.7690             nan     0.0100 -1866.9362
   280 14860649.0278             nan     0.0100 -3711.0246
   300 14763205.9308             nan     0.0100 -1100.6995

- Fold09.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17265349.1467             nan     0.0100 -3162.7493
     2 17248793.4613             nan     0.0100 9321.7518
     3 17230092.1402             nan     0.0100 -1845.2567
     4 17213791.8942             nan     0.0100 -248.8079
     5 17187101.2253             nan     0.0100 23623.4717
     6 17171835.8761             nan     0.0100 -4226.4009
     7 17137776.4579             nan     0.0100 -5766.5352
     8 17110131.4208             nan     0.0100 9690.5629
     9 17082269.8448             nan     0.0100 9232.7894
    10 17039907.6202             nan     0.0100 -4157.2012
    20 16794907.3743             nan     0.0100 -4875.3480
    40 16297886.1067             nan     0.0100 1691.2405
    60 15863176.8133             nan     0.0100 7573.1372
    80 15480312.4677             nan     0.0100 -8528.2561
   100 15127179.6056             nan     0.0100 -8006.9477
   120 14832793.7337             nan     0.0100 -14414.6862
   140 14532249.4795             nan     0.0100 -7776.6610
   160 14242055.4650             nan     0.0100 -4080.4779
   180 14034233.3466             nan     0.0100 -10298.5452
   200 13787094.6600             nan     0.0100 -10842.5324
   220 13592334.9622             nan     0.0100 -25216.4989
   240 13337960.5318             nan     0.0100 1065.2352
   260 13069487.6626             nan     0.0100 1959.6645
   280 12880583.6499             nan     0.0100 -14105.0352
   300 12642844.4861             nan     0.0100 -663.8634

- Fold09.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17243480.8236             nan     0.0100 10488.7823
     2 17203971.1530             nan     0.0100 5661.6186
     3 17157555.7417             nan     0.0100 23085.0402
     4 17128324.1307             nan     0.0100   55.0114
     5 17105705.6327             nan     0.0100 -12978.3675
     6 17067918.7237             nan     0.0100 14022.8958
     7 17037242.0223             nan     0.0100 -2987.2749
     8 17006617.2614             nan     0.0100 11869.5848
     9 16980174.9737             nan     0.0100 17308.6956
    10 16946055.8975             nan     0.0100 -950.4422
    20 16676140.8488             nan     0.0100 21121.3907
    40 16132171.7742             nan     0.0100 6214.8124
    60 15605017.8512             nan     0.0100 -3290.1896
    80 15167424.5113             nan     0.0100 7769.8119
   100 14803776.0555             nan     0.0100 -18582.9935
   120 14475017.0242             nan     0.0100 -12288.5456
   140 14155467.3683             nan     0.0100 -19137.7082
   160 13748801.6843             nan     0.0100 -10540.1332
   180 13464732.4387             nan     0.0100 -19391.9315
   200 13113413.3257             nan     0.0100 3039.4432
   220 12823528.2724             nan     0.0100 -14090.7360
   240 12548503.4707             nan     0.0100 -13872.5980
   260 12304127.3260             nan     0.0100 -12865.0596
   280 12028807.2439             nan     0.0100 -3602.4266
   300 11782874.4626             nan     0.0100 -12405.0639

- Fold09.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17236173.3361             nan     0.0200 15515.8232
     2 17198340.4010             nan     0.0200 -13813.6580
     3 17173286.0666             nan     0.0200 5472.8038
     4 17156492.6594             nan     0.0200 -4319.5799
     5 17113188.0077             nan     0.0200 5095.5449
     6 17090972.7142             nan     0.0200 19432.3639
     7 17045182.4205             nan     0.0200 -5655.4643
     8 17016326.9697             nan     0.0200 -8727.1069
     9 16973275.4187             nan     0.0200 5589.3129
    10 16944561.8996             nan     0.0200 14697.5447
    20 16664337.0740             nan     0.0200 -3382.3863
    40 16202877.2196             nan     0.0200 -11438.1945
    60 15866629.6555             nan     0.0200 -6993.6445
    80 15522565.5425             nan     0.0200  634.3971
   100 15281340.1000             nan     0.0200 3025.0469
   120 15060010.2963             nan     0.0200 -35798.5961
   140 14837825.9774             nan     0.0200 -1167.3430
   160 14663108.1374             nan     0.0200 2182.3650
   180 14487628.8930             nan     0.0200 -23787.3129
   200 14330548.5165             nan     0.0200 -2778.5925
   220 14210858.1573             nan     0.0200 -24076.1407
   240 14080095.5558             nan     0.0200 -19221.3014
   260 13970099.9430             nan     0.0200 -6092.7826
   280 13865709.0369             nan     0.0200 -5110.3297
   300 13767853.1389             nan     0.0200 -16841.3648

- Fold09.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17209606.5328             nan     0.0200 10843.5291
     2 17165432.8775             nan     0.0200 -7567.1490
     3 17090801.8340             nan     0.0200 10913.2769
     4 17008371.9891             nan     0.0200 -15218.3899
     5 16947214.9044             nan     0.0200 10541.7936
     6 16922416.7124             nan     0.0200 -17848.0923
     7 16875162.4438             nan     0.0200 13390.2463
     8 16863120.1453             nan     0.0200 -30146.0928
     9 16836564.2117             nan     0.0200 18073.1749
    10 16803532.8414             nan     0.0200 -13136.1117
    20 16297399.1485             nan     0.0200 7739.2346
    40 15508939.4828             nan     0.0200 -3668.9796
    60 14964306.5692             nan     0.0200 -10889.3774
    80 14376235.7628             nan     0.0200 28013.1226
   100 13882449.8368             nan     0.0200 -9438.3965
   120 13534770.3281             nan     0.0200 -21231.8450
   140 13079960.4793             nan     0.0200 -15676.3599
   160 12663881.3121             nan     0.0200 -15325.5266
   180 12275965.5839             nan     0.0200 -11544.1126
   200 12001523.2351             nan     0.0200 -19125.2145
   220 11625253.2293             nan     0.0200 -10692.1649
   240 11368382.2390             nan     0.0200 -25056.5473
   260 11102379.3200             nan     0.0200 -25168.2305
   280 10848215.1258             nan     0.0200 -12345.1711
   300 10563099.8714             nan     0.0200 -28633.9266

- Fold09.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17217378.8237             nan     0.0200 2947.3545
     2 17154823.2974             nan     0.0200 32607.4487
     3 17079860.6787             nan     0.0200 -16885.7161
     4 17060748.3587             nan     0.0200 -10288.8628
     5 17012914.6971             nan     0.0200 14128.2437
     6 16939708.1129             nan     0.0200 41289.7300
     7 16866375.7485             nan     0.0200 30101.3452
     8 16792516.2880             nan     0.0200 -2809.6632
     9 16725902.6782             nan     0.0200 9259.6414
    10 16662794.7405             nan     0.0200 -9364.8800
    20 15970981.8653             nan     0.0200 -7631.0196
    40 14970635.5249             nan     0.0200 -20792.3077
    60 14278361.0000             nan     0.0200 -4271.2588
    80 13624749.2350             nan     0.0200 -18296.6257
   100 13038907.8114             nan     0.0200 -1913.6429
   120 12406809.7286             nan     0.0200 -2097.1826
   140 11839599.8845             nan     0.0200 -33108.1458
   160 11258040.4333             nan     0.0200 -7901.4260
   180 10939840.4699             nan     0.0200 -6643.2341
   200 10556418.7756             nan     0.0200 -18893.7620
   220 10130352.0599             nan     0.0200 -26580.9684
   240  9839645.1453             nan     0.0200 -13779.9703
   260  9579896.0040             nan     0.0200 -20849.6154
   280  9256848.3855             nan     0.0200 -22568.6056
   300  9014339.0428             nan     0.0200 -23442.5168

- Fold09.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17167505.4809             nan     0.0500 22596.5739
     2 17137397.8656             nan     0.0500 8326.4238
     3 17076284.0661             nan     0.0500 -22048.6409
     4 17021925.6684             nan     0.0500 -12160.9229
     5 17001484.5152             nan     0.0500 -17524.7711
     6 16933221.9739             nan     0.0500 -56920.8392
     7 16834499.4800             nan     0.0500 6278.9888
     8 16797410.2863             nan     0.0500 -53463.5565
     9 16775413.4046             nan     0.0500 1036.8862
    10 16661334.2943             nan     0.0500 12302.3550
    20 16183907.7351             nan     0.0500 19811.1627
    40 15325844.0189             nan     0.0500 -5915.6863
    60 14835073.0604             nan     0.0500 -14588.8965
    80 14432914.7183             nan     0.0500 -45282.4966
   100 14115563.8094             nan     0.0500 -2184.6820
   120 13854618.0860             nan     0.0500 8929.6710
   140 13669686.5754             nan     0.0500 -34859.6872
   160 13480296.2322             nan     0.0500 -57575.9153
   180 13257397.4469             nan     0.0500 -45886.7933
   200 13046811.6552             nan     0.0500 -27750.8970
   220 12870478.7322             nan     0.0500 -40621.6684
   240 12715267.1539             nan     0.0500 -23735.3763
   260 12551497.1634             nan     0.0500 -49254.7505
   280 12419142.7465             nan     0.0500 -32662.3979
   300 12277366.6837             nan     0.0500 -27436.0624

- Fold09.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17126005.5787             nan     0.0500 39718.2211
     2 17015986.2310             nan     0.0500 64634.2902
     3 16897533.6502             nan     0.0500 54233.6100
     4 16775267.7829             nan     0.0500 -9942.1924
     5 16669944.7359             nan     0.0500 -19658.6759
     6 16543017.4817             nan     0.0500 -27691.4548
     7 16444961.6009             nan     0.0500 -28782.4225
     8 16275644.6896             nan     0.0500 24495.6671
     9 16115523.7207             nan     0.0500 -25762.2162
    10 15995015.4026             nan     0.0500 60575.4625
    20 14923501.2812             nan     0.0500 -30134.7043
    40 13590810.5513             nan     0.0500 -35347.1654
    60 12577573.1711             nan     0.0500 -20837.4189
    80 11683893.1972             nan     0.0500 -23471.5865
   100 10866053.9691             nan     0.0500 -14126.4710
   120 10167627.9987             nan     0.0500 -43919.9099
   140  9464031.0762             nan     0.0500 -29423.6907
   160  8830529.5130             nan     0.0500 -31395.4150
   180  8387458.9036             nan     0.0500 -74671.7171
   200  7878295.6596             nan     0.0500 -43597.1835
   220  7494372.1105             nan     0.0500 -47685.0599
   240  7092825.2791             nan     0.0500 -34349.1304
   260  6641551.6439             nan     0.0500 -16761.3628
   280  6226521.9296             nan     0.0500 -20871.2952
   300  5842478.8749             nan     0.0500 -13291.5613

- Fold09.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 17154479.9213             nan     0.0500 36551.7040
     2 16992355.9299             nan     0.0500 35968.8395
     3 16824640.4720             nan     0.0500 3379.0932
     4 16675781.9270             nan     0.0500 83234.5069
     5 16564410.8041             nan     0.0500 25340.7559
     6 16400442.1120             nan     0.0500 5569.5479
     7 16321228.8793             nan     0.0500 2990.8311
     8 16226584.9971             nan     0.0500 25679.4752
     9 16130856.4133             nan     0.0500 -30758.2272
    10 16030580.1111             nan     0.0500 -15069.7044
    20 15055584.5317             nan     0.0500 -43303.7487
    40 12908719.3308             nan     0.0500 -29964.2013
    60 11629628.8078             nan     0.0500 -38717.0260
    80 10616221.1263             nan     0.0500 -39010.5050
   100  9807937.8333             nan     0.0500 -45379.6741
   120  8920899.5651             nan     0.0500 -20673.4078
   140  8114039.6635             nan     0.0500 -29304.8373
   160  7301155.3873             nan     0.0500 -14022.2613
   180  6764323.2289             nan     0.0500 -39101.6843
   200  6305865.0523             nan     0.0500 -44104.6754
   220  5883000.0679             nan     0.0500 -28548.9317
   240  5443451.6454             nan     0.0500 -38762.4887
   260  4955847.8678             nan     0.0500 -15950.4500
   280  4620933.0405             nan     0.0500 -25796.4983
   300  4331497.4112             nan     0.0500 -22339.9573

- Fold09.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19633400.4903             nan     0.0100 7014.5573
     2 19621580.0859             nan     0.0100 -871.5503
     3 19609334.5596             nan     0.0100 10789.2491
     4 19595580.1646             nan     0.0100  827.0949
     5 19582330.8978             nan     0.0100 -297.9050
     6 19559932.0917             nan     0.0100 5904.6115
     7 19538782.6853             nan     0.0100 1609.2529
     8 19515010.4877             nan     0.0100 3160.0884
     9 19491900.5496             nan     0.0100 -2629.6471
    10 19465676.4930             nan     0.0100 -12089.6705
    20 19263749.5390             nan     0.0100 8696.8479
    40 18956788.5429             nan     0.0100 1014.1868
    60 18633874.3182             nan     0.0100 6396.7922
    80 18353492.8342             nan     0.0100 -8906.9345
   100 18128723.9787             nan     0.0100 -5673.6118
   120 17926480.3287             nan     0.0100 -417.9524
   140 17697036.1515             nan     0.0100 -7167.3208
   160 17530161.4635             nan     0.0100  161.7073
   180 17368429.5637             nan     0.0100 1333.6744
   200 17204611.1933             nan     0.0100 -217.2722
   220 17071008.2101             nan     0.0100 3044.9722
   240 16929855.3013             nan     0.0100 -10800.8810
   260 16818758.2244             nan     0.0100  400.7233
   280 16702714.4826             nan     0.0100 -16186.7347
   300 16606053.9237             nan     0.0100 1787.2366

- Fold10.Rep1: shrinkage=0.01, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19615752.4598             nan     0.0100 12433.2214
     2 19588885.6407             nan     0.0100 6488.9077
     3 19565675.0999             nan     0.0100 5838.8220
     4 19537718.5070             nan     0.0100 -1520.1461
     5 19493831.5591             nan     0.0100 8395.8081
     6 19463687.8441             nan     0.0100 -5752.1928
     7 19422340.1061             nan     0.0100 8720.4640
     8 19390577.6056             nan     0.0100 12983.9716
     9 19372477.4725             nan     0.0100 -9443.0848
    10 19313655.9135             nan     0.0100 33099.4698
    20 18888289.9572             nan     0.0100 6194.7698
    40 18134704.7075             nan     0.0100 -4755.2365
    60 17627387.7517             nan     0.0100 -10369.1043
    80 17219165.6202             nan     0.0100 -7129.8329
   100 16717486.4588             nan     0.0100 -10939.2444
   120 16287020.7007             nan     0.0100 2037.4065
   140 15910915.9502             nan     0.0100 -6567.8755
   160 15512357.9195             nan     0.0100 -13173.3906
   180 15132331.7653             nan     0.0100 -11959.3615
   200 14801336.7008             nan     0.0100 -13155.8165
   220 14551503.1147             nan     0.0100 -12705.9191
   240 14282285.4654             nan     0.0100 -7435.2529
   260 14011104.9902             nan     0.0100 -14736.9212
   280 13747090.3670             nan     0.0100 -4063.7199
   300 13471139.1000             nan     0.0100 -12853.6996

- Fold10.Rep1: shrinkage=0.01, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19616499.2363             nan     0.0100 20982.2746
     2 19581441.5688             nan     0.0100 15853.8215
     3 19511378.1634             nan     0.0100 -12834.3162
     4 19458495.5461             nan     0.0100 10472.7601
     5 19412314.3507             nan     0.0100 14747.8248
     6 19392677.5060             nan     0.0100 -3415.9586
     7 19344034.4734             nan     0.0100 9527.4605
     8 19313591.2958             nan     0.0100 5521.8356
     9 19272331.7524             nan     0.0100 -223.9611
    10 19226460.7934             nan     0.0100 15637.4326
    20 18723207.6828             nan     0.0100 3452.5442
    40 17962372.4807             nan     0.0100 -2397.8500
    60 17322066.6223             nan     0.0100 -5025.5785
    80 16728209.6953             nan     0.0100 31212.3117
   100 16261581.6505             nan     0.0100 -5340.7927
   120 15828264.3233             nan     0.0100 -3962.1511
   140 15384086.2328             nan     0.0100 -4347.6902
   160 14871268.3877             nan     0.0100 -5437.9282
   180 14444641.8294             nan     0.0100 -19368.5159
   200 14129791.6524             nan     0.0100 -7859.7655
   220 13726132.3885             nan     0.0100 11529.7401
   240 13399711.3550             nan     0.0100 -10245.1297
   260 13083451.3692             nan     0.0100 -3758.2504
   280 12776469.9143             nan     0.0100 -20732.4796
   300 12488959.4370             nan     0.0100 1177.0778

- Fold10.Rep1: shrinkage=0.01, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19633164.9211             nan     0.0200 4647.5318
     2 19571038.4670             nan     0.0200 -32347.6322
     3 19549659.0654             nan     0.0200 2038.6612
     4 19493492.0836             nan     0.0200 18410.2718
     5 19465088.7616             nan     0.0200 -8713.6090
     6 19420665.2754             nan     0.0200 17987.4239
     7 19365065.6369             nan     0.0200 24054.6163
     8 19345087.2350             nan     0.0200 4156.0758
     9 19290469.6853             nan     0.0200 -6221.6562
    10 19236060.1577             nan     0.0200 -775.2575
    20 18837122.4529             nan     0.0200 13887.5165
    40 18319641.2463             nan     0.0200 -28776.3859
    60 17855227.9672             nan     0.0200 15691.0666
    80 17429729.1561             nan     0.0200 -53840.6340
   100 17066304.4206             nan     0.0200  193.5212
   120 16841535.5284             nan     0.0200 -11034.5936
   140 16611290.7600             nan     0.0200 -15962.9513
   160 16409132.3516             nan     0.0200 -5200.4145
   180 16248536.2464             nan     0.0200 -17356.5656
   200 16127668.9066             nan     0.0200 -7611.6666
   220 15973904.0174             nan     0.0200 -16230.0685
   240 15821593.1246             nan     0.0200 -14334.5315
   260 15703588.8690             nan     0.0200 -20640.8065
   280 15580325.6982             nan     0.0200 -16432.1079
   300 15472306.8565             nan     0.0200 -9554.9293

- Fold10.Rep1: shrinkage=0.02, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19588998.3721             nan     0.0200 19458.5045
     2 19533301.8341             nan     0.0200 12212.4300
     3 19405244.7601             nan     0.0200 -19882.2344
     4 19265212.4825             nan     0.0200 68057.3503
     5 19169147.4231             nan     0.0200 26119.7343
     6 19093701.6609             nan     0.0200 13731.1185
     7 19039564.8191             nan     0.0200 15297.5398
     8 18991982.8597             nan     0.0200 -2062.3376
     9 18876088.2018             nan     0.0200 6237.6159
    10 18829440.7220             nan     0.0200 31287.0899
    20 18194458.5782             nan     0.0200 -30080.1594
    40 17087180.7020             nan     0.0200 -195.4252
    60 16080869.5425             nan     0.0200 -15776.4021
    80 15384596.1851             nan     0.0200 -20187.0808
   100 14884033.4865             nan     0.0200 -36505.7584
   120 14243729.9298             nan     0.0200 -24448.9043
   140 13736205.9901             nan     0.0200 -34671.7372
   160 13352091.7866             nan     0.0200 -15213.6142
   180 12943313.8298             nan     0.0200 -17337.3771
   200 12508118.3459             nan     0.0200 -42245.8333
   220 12007996.1159             nan     0.0200 -25229.9809
   240 11640477.5815             nan     0.0200 -10626.3205
   260 11326887.7399             nan     0.0200 -17762.4403
   280 11082155.8260             nan     0.0200 -17602.0645
   300 10824502.6142             nan     0.0200 -10067.7406

- Fold10.Rep1: shrinkage=0.02, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19555169.9432             nan     0.0200 21923.8493
     2 19442794.0807             nan     0.0200 -15371.2325
     3 19411011.8362             nan     0.0200 -4963.8617
     4 19300937.7469             nan     0.0200 34350.6695
     5 19232422.9614             nan     0.0200 19132.1953
     6 19177578.7703             nan     0.0200 26072.7246
     7 19094040.9952             nan     0.0200 46714.7468
     8 19022682.7823             nan     0.0200 31920.7623
     9 18962323.1313             nan     0.0200  313.7962
    10 18889690.0839             nan     0.0200 27160.0865
    20 18247333.4801             nan     0.0200 37019.8853
    40 16934556.9804             nan     0.0200 -119.7561
    60 15874773.5796             nan     0.0200 -20643.4459
    80 14987673.0783             nan     0.0200 -7261.5453
   100 14342201.4872             nan     0.0200 -32509.7877
   120 13801259.4118             nan     0.0200 -8433.3096
   140 13181369.1050             nan     0.0200 -24688.0664
   160 12563751.3242             nan     0.0200 -35095.7226
   180 11942758.7817             nan     0.0200 -3857.7151
   200 11484979.2611             nan     0.0200 -31132.5749
   220 11036136.7556             nan     0.0200 -17055.9085
   240 10565633.7040             nan     0.0200 -8026.1286
   260 10225020.3583             nan     0.0200 -36707.2023
   280  9768120.0868             nan     0.0200 -27456.6546
   300  9278883.8851             nan     0.0200 -27272.7088

- Fold10.Rep1: shrinkage=0.02, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19506563.5041             nan     0.0500 36762.0509
     2 19460168.4850             nan     0.0500 -34560.7384
     3 19417946.6535             nan     0.0500 2873.0861
     4 19357398.1279             nan     0.0500 -25449.3473
     5 19313170.1366             nan     0.0500 18044.5402
     6 19213334.6794             nan     0.0500 55094.2417
     7 19113469.2435             nan     0.0500 31087.0743
     8 19076464.4779             nan     0.0500 6627.5404
     9 19061940.8192             nan     0.0500 -24134.1731
    10 18958755.3133             nan     0.0500 14705.4489
    20 18400488.8771             nan     0.0500 -11607.7280
    40 17247336.5990             nan     0.0500 -3494.7741
    60 16612257.4601             nan     0.0500 -4246.5271
    80 16149861.8265             nan     0.0500 -65273.0190
   100 15807623.4397             nan     0.0500 -39628.7242
   120 15476758.2093             nan     0.0500 -41104.1294
   140 15179660.0073             nan     0.0500 -34433.9682
   160 14951826.3816             nan     0.0500 -37058.2248
   180 14737465.3962             nan     0.0500 -31395.5288
   200 14559727.3578             nan     0.0500 -121548.6611
   220 14345969.8934             nan     0.0500 -16389.6348
   240 14201094.1901             nan     0.0500 -19140.3318
   260 13973140.8184             nan     0.0500 -46071.8016
   280 13794137.6088             nan     0.0500 -39654.6551
   300 13638096.1981             nan     0.0500 -21358.7236

- Fold10.Rep1: shrinkage=0.05, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19483489.9801             nan     0.0500 30174.9510
     2 19375272.2251             nan     0.0500 -34879.0133
     3 19176008.5542             nan     0.0500 45049.5037
     4 18992562.6343             nan     0.0500 71501.3847
     5 18829603.9624             nan     0.0500 -30753.4948
     6 18685597.8362             nan     0.0500 9175.8685
     7 18512345.9487             nan     0.0500 22065.0995
     8 18328532.5346             nan     0.0500 47476.1427
     9 18238340.4421             nan     0.0500 61508.1277
    10 18049091.7113             nan     0.0500 -37501.8834
    20 16767794.0221             nan     0.0500 20702.1232
    40 14765926.5531             nan     0.0500 -51873.9938
    60 13200300.8434             nan     0.0500 -28793.8156
    80 12058499.3775             nan     0.0500 -48708.9325
   100 11151614.3653             nan     0.0500 -32762.1435
   120 10608080.4461             nan     0.0500 -46521.5200
   140  9747586.2762             nan     0.0500 -28110.4555
   160  9207460.2431             nan     0.0500 -50340.3423
   180  8602213.3371             nan     0.0500 -27239.0494
   200  8091607.6517             nan     0.0500 -38101.8701
   220  7597165.5537             nan     0.0500 -34878.2202
   240  6961193.9324             nan     0.0500 -56956.6697
   260  6553993.1196             nan     0.0500 -17817.4111
   280  6176790.4652             nan     0.0500 -26385.7488
   300  5744950.6794             nan     0.0500 -47856.4839

- Fold10.Rep1: shrinkage=0.05, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 19362115.7159             nan     0.0500 -117536.1731
     2 19189195.6894             nan     0.0500 8423.9547
     3 18981187.4400             nan     0.0500 94825.3972
     4 18841069.4166             nan     0.0500 -30039.6706
     5 18629671.6032             nan     0.0500 -15528.2369
     6 18512033.6507             nan     0.0500 -55216.2788
     7 18382645.0636             nan     0.0500 30293.9750
     8 18216254.4122             nan     0.0500 32120.3254
     9 18068911.4419             nan     0.0500 75978.8660
    10 17786394.2418             nan     0.0500 -15849.7264
    20 16480128.2005             nan     0.0500 -18370.6860
    40 14220660.3552             nan     0.0500  -71.6554
    60 12677562.3846             nan     0.0500 -82883.9937
    80 11467009.7041             nan     0.0500 -22607.3407
   100 10415733.4910             nan     0.0500 -77156.9531
   120  9398433.4525             nan     0.0500 -59137.0187
   140  8519403.9696             nan     0.0500 -41658.3669
   160  7691479.5260             nan     0.0500 -30306.2372
   180  7088807.0369             nan     0.0500 -41497.9809
   200  6465697.0383             nan     0.0500 -42550.4791
   220  5891299.3128             nan     0.0500 -28976.7273
   240  5456429.5443             nan     0.0500 -37182.4931
   260  4985231.0836             nan     0.0500 -18423.7702
   280  4660848.7771             nan     0.0500 -20750.1716
   300  4325407.6776             nan     0.0500 -38572.1109

- Fold10.Rep1: shrinkage=0.05, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Aggregating results
Selecting tuning parameters
Fitting n.trees = 100, interaction.depth = 5, shrinkage = 0.01, n.minobsinnode = 10 on full training set
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1 18111555.6975             nan     0.0100 11636.3163
     2 18094038.5018             nan     0.0100 2541.3950
     3 18061887.8053             nan     0.0100 8855.0355
     4 18025801.3875             nan     0.0100  725.4351
     5 17962545.8501             nan     0.0100 -4274.0094
     6 17928163.5178             nan     0.0100 -255.0436
     7 17891739.2583             nan     0.0100 28838.1131
     8 17864106.8605             nan     0.0100 4131.5506
     9 17792977.1531             nan     0.0100 -9472.4075
    10 17757394.2776             nan     0.0100 -193.9742
    20 17425630.4328             nan     0.0100 -289.1747
    40 16672012.2862             nan     0.0100 31892.1872
    60 16172710.9316             nan     0.0100 8228.9791
    80 15639978.9771             nan     0.0100 -7063.0076
   100 15211017.7911             nan     0.0100 -5547.7967

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[239]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">RMSE_Value_2</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">lasso_error2</span><span class="p">,</span> <span class="n">dt_error2.1</span><span class="p">,</span> <span class="n">dt_error2.2</span><span class="p">,</span> <span class="n">dt_error2.3</span><span class="p">,</span> <span class="n">rf_error2</span><span class="p">,</span> <span class="n">sgb_error2</span><span class="p">)</span>

<span class="n">table2</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span><span class="n">RMSE_Value_2</span><span class="p">)</span>
<span class="n">table2</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>Model</th><th scope=col>RMSE_Value_2</th></tr></thead>
<tbody>
	<tr><td>Lasso Reg        </td><td>11694.98         </td></tr>
	<tr><td>Decision Tree 1  </td><td>12043.56         </td></tr>
	<tr><td>Decision Tree 2  </td><td>11934.91         </td></tr>
	<tr><td>Decision Tree 3  </td><td>11937.40         </td></tr>
	<tr><td>Random Forest    </td><td>11648.65         </td></tr>
	<tr><td>Gradient Boosting</td><td>11663.83         </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>For this data set, random forest model has the smallest RMSE value.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Data-Set-3:-Drug-Consumption">Data Set 3: Drug Consumption<a class="anchor-link" href="#Data-Set-3:-Drug-Consumption">&#182;</a></h3><p>Attribute Information:</p>
<ol>
<li>ID is number of record in original database. Cannot be related to participant. It can be used for reference only.</li>
<li>Age (Real) is age of participant and has one of the values</li>
<li>Gender (Real) is gender of participant</li>
<li>Education (Real) is level of education of participant </li>
<li>Country (Real) is country of current residence of participant </li>
<li>Ethnicity (Real) is ethnicity of participant </li>
<li>Nscore (Real) is NEO-FFI-R Neuroticism. </li>
<li>Escore (Real) is NEO-FFI-R Extraversion. </li>
<li>Oscore (Real) is NEO-FFI-R Openness to experience. </li>
<li>Ascore (Real) is NEO-FFI-R Agreeableness. </li>
<li>Cscore (Real) is NEO-FFI-R Conscientiousness. </li>
<li>Impulsive (Real) is impulsiveness measured by BIS-11. </li>
<li>SS (Real) is sensation seeing measured by ImpSS. </li>
<li>Amphet is class of amphetamines consumption.</li>
<li>Amyl is class of amyl nitrite consumption. </li>
<li>Benzos is class of benzodiazepine consumption. </li>
<li>Caff is class of caffeine consumption. </li>
<li>Cannabis is class of cannabis consumption. </li>
<li>Choc is class of chocolate consumption. </li>
<li>Coke is class of cocaine consumption. </li>
<li>Crack is class of crack consumption. </li>
<li>Ecstasy is class of ecstasy consumption. </li>
<li>Heroin is class of heroin consumption. </li>
<li>Ketamine is class of ketamine consumption. </li>
<li>Legalh is class of legal highs consumption. </li>
<li>LSD is class of alcohol consumption. </li>
<li>Meth is class of methadone consumption. </li>
<li>Mushrooms is class of magic mushrooms consumption. </li>
<li>Nicotine is class of nicotine consumption. </li>
<li>Semer is class of fictitious drug Semeron consumption. </li>
<li>VSA is class of volatile substance abuse consumption. </li>
</ol>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[280]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;MLmetrics&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>package &#39;MLmetrics&#39; successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\lenovo\AppData\Local\Temp\RtmpmY4E4B\downloaded_packages
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[323]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data3</span> <span class="o">&lt;-</span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;DataSet3/DrugConsumption.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="bp">T</span><span class="p">)</span>
<span class="n">data3</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="o">&lt;-</span> <span class="kc">NULL</span>
<span class="nf">head</span><span class="p">(</span><span class="n">data3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>Age</th><th scope=col>Gender</th><th scope=col>Education</th><th scope=col>Country</th><th scope=col>Ethnicity</th><th scope=col>Nscore</th><th scope=col>Escore</th><th scope=col>Oscore</th><th scope=col>Ascore</th><th scope=col>Cscore</th><th scope=col>...</th><th scope=col>Ecstasy</th><th scope=col>Heroin</th><th scope=col>Ketamine</th><th scope=col>Legalh</th><th scope=col>LSD</th><th scope=col>Meth</th><th scope=col>Mushrooms</th><th scope=col>Nicotine</th><th scope=col>Semer</th><th scope=col>VSA</th></tr></thead>
<tbody>
	<tr><td> 0.49788</td><td> 0.48246</td><td>-0.05921</td><td>0.96082 </td><td> 0.12600</td><td> 0.31287</td><td>-0.57545</td><td>-0.58331</td><td>-0.91699</td><td>-0.00665</td><td>...     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL2     </td><td>CL0     </td><td>CL0     </td></tr>
	<tr><td>-0.07854</td><td>-0.48246</td><td> 1.98437</td><td>0.96082 </td><td>-0.31685</td><td>-0.67825</td><td> 1.93886</td><td> 1.43533</td><td> 0.76096</td><td>-0.14277</td><td>...     </td><td>CL4     </td><td>CL0     </td><td>CL2     </td><td>CL0     </td><td>CL2     </td><td>CL3     </td><td>CL0     </td><td>CL4     </td><td>CL0     </td><td>CL0     </td></tr>
	<tr><td> 0.49788</td><td>-0.48246</td><td>-0.05921</td><td>0.96082 </td><td>-0.31685</td><td>-0.46725</td><td> 0.80523</td><td>-0.84732</td><td>-1.62090</td><td>-1.01450</td><td>...     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL1     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td></tr>
	<tr><td>-0.95197</td><td> 0.48246</td><td> 1.16365</td><td>0.96082 </td><td>-0.31685</td><td>-0.14882</td><td>-0.80615</td><td>-0.01928</td><td> 0.59042</td><td> 0.58489</td><td>...     </td><td>CL0     </td><td>CL0     </td><td>CL2     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL2     </td><td>CL0     </td><td>CL0     </td></tr>
	<tr><td> 0.49788</td><td> 0.48246</td><td> 1.98437</td><td>0.96082 </td><td>-0.31685</td><td> 0.73545</td><td>-1.63340</td><td>-0.45174</td><td>-0.30172</td><td> 1.30612</td><td>...     </td><td>CL1     </td><td>CL0     </td><td>CL0     </td><td>CL1     </td><td>CL0     </td><td>CL0     </td><td>CL2     </td><td>CL2     </td><td>CL0     </td><td>CL0     </td></tr>
	<tr><td> 2.59171</td><td> 0.48246</td><td>-1.22751</td><td>0.24923 </td><td>-0.31685</td><td>-0.67825</td><td>-0.30033</td><td>-1.55521</td><td> 2.03972</td><td> 1.63088</td><td>...     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL0     </td><td>CL6     </td><td>CL0     </td><td>CL0     </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[316]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">any</span><span class="p">(</span><span class="nf">is.na</span><span class="p">(</span><span class="n">data3</span><span class="p">)</span><span class="o">==</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
FALSE
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[306]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">str</span><span class="p">(</span><span class="n">data3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>&#39;data.frame&#39;:	1885 obs. of  31 variables:
 $ Age      : num  0.4979 -0.0785 0.4979 -0.952 0.4979 ...
 $ Gender   : num  0.482 -0.482 -0.482 0.482 0.482 ...
 $ Education: num  -0.0592 1.9844 -0.0592 1.1637 1.9844 ...
 $ Country  : num  0.961 0.961 0.961 0.961 0.961 ...
 $ Ethnicity: num  0.126 -0.317 -0.317 -0.317 -0.317 ...
 $ Nscore   : num  0.313 -0.678 -0.467 -0.149 0.735 ...
 $ Escore   : num  -0.575 1.939 0.805 -0.806 -1.633 ...
 $ Oscore   : num  -0.5833 1.4353 -0.8473 -0.0193 -0.4517 ...
 $ Ascore   : num  -0.917 0.761 -1.621 0.59 -0.302 ...
 $ Cscore   : num  -0.00665 -0.14277 -1.0145 0.58489 1.30612 ...
 $ Impulsive: num  -0.217 -0.711 -1.38 -1.38 -0.217 ...
 $ SS       : num  -1.181 -0.216 0.401 -1.181 -0.216 ...
 $ Alcohol  : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 6 6 7 5 5 3 7 6 5 7 ...
 $ Amphet   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 3 3 1 1 2 1 1 1 1 2 ...
 $ Amyl     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 3 1 1 2 1 1 1 1 1 ...
 $ Benzos   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 3 1 1 4 1 1 1 1 1 2 ...
 $ Caff     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 7 7 7 6 7 7 7 7 7 7 ...
 $ Cannabis : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 5 4 3 4 1 2 1 1 2 ...
 $ Choc     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 6 7 5 5 7 5 6 5 7 7 ...
 $ Coke     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 4 1 3 1 1 1 1 1 1 ...
 $ Crack    : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Ecstasy  : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 5 1 1 2 1 1 1 1 1 ...
 $ Heroin   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Ketamine : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 3 1 3 1 1 1 1 1 1 ...
 $ Legalh   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 1 1 2 1 1 1 1 1 ...
 $ LSD      : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 3 1 1 1 1 1 1 1 1 ...
 $ Meth     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 4 1 1 1 1 1 1 1 1 ...
 $ Mushrooms: Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 2 1 3 1 1 1 1 1 ...
 $ Nicotine : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 3 5 1 3 3 7 7 1 7 7 ...
 $ Semer    : Factor w/ 5 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...
 $ VSA      : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Explanation of levels for variable VSA</p>
<p>CL0 Never Used 428 22.71% 1877 99.58% 1455 77.19%</p>
<p>CL1 Used over a Decade Ago 193 10.24% 2 0.11% 200 10.61%</p>
<p>CL2 Used in Last Decade 204 10.82% 3 0.16% 135 7.16%</p>
<p>CL3 Used in Last Year 185 9.81% 2 0.11% 61 3.24%</p>
<p>CL4 Used in Last Month 108 5.73% 1 0.05% 13 0.69%</p>
<p>CL5 Used in Last Week 157 8.33% 0 0.00% 14 0.74%</p>
<p>CL6 Used in Last Day 610 32.36% 0 0.00% 7 0.37%</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[324]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">table</span><span class="p">(</span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>
 CL0  CL1  CL2  CL3  CL4  CL5  CL6 
1455  200  135   61   13   14    7 </pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[325]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span> <span class="o">&lt;-</span> <span class="nf">as.character</span><span class="p">(</span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[326]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span><span class="p">[</span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span> <span class="o">!=</span> <span class="s">&quot;CL0&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="s">&quot;VSAused&quot;</span>
<span class="n">data3</span><span class="o">$</span><span class="n">VSA</span><span class="p">[</span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span> <span class="o">==</span> <span class="s">&quot;CL0&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="s">&quot;VSAneverused&quot;</span>
<span class="nf">head</span><span class="p">(</span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<ol class=list-inline>
	<li>'VSAneverused'</li>
	<li>'VSAneverused'</li>
	<li>'VSAneverused'</li>
	<li>'VSAneverused'</li>
	<li>'VSAneverused'</li>
	<li>'VSAneverused'</li>
</ol>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[327]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">table</span><span class="p">(</span><span class="n">data3</span><span class="o">$</span><span class="n">VSA</span><span class="p">)</span> <span class="c1">## class imbalance problem (a ratio of 3:1)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>
VSAneverused      VSAused 
        1455          430 </pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[356]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">names</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">31</span><span class="p">)</span>
<span class="n">data3</span><span class="p">[,</span><span class="n">names</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="nf">lapply</span><span class="p">(</span><span class="n">data3</span><span class="p">[,</span><span class="n">names</span><span class="p">]</span> <span class="p">,</span> <span class="n">factor</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[357]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">colnames</span><span class="p">(</span><span class="n">data3</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">make.names</span><span class="p">(</span><span class="nf">colnames</span><span class="p">(</span><span class="n">data3</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[358]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">nearZeroVar</span><span class="p">(</span><span class="n">data3</span><span class="p">,</span> <span class="n">saveMetrics</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th></th><th scope=col>freqRatio</th><th scope=col>percentUnique</th><th scope=col>zeroVar</th><th scope=col>nzv</th></tr></thead>
<tbody>
	<tr><th scope=row>Age</th><td>  1.336798</td><td>0.3183024 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Gender</th><td>  1.001062</td><td>0.1061008 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Education</th><td>  1.054167</td><td>0.4774536 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Country</th><td>  1.874327</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Ethnicity</th><td> 27.301587</td><td>0.3713528 </td><td>FALSE     </td><td> TRUE     </td></tr>
	<tr><th scope=row>Nscore</th><td>  1.087500</td><td>2.5994695 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Escore</th><td>  1.120690</td><td>2.2281167 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Oscore</th><td>  1.155172</td><td>1.8567639 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Ascore</th><td>  1.035088</td><td>2.1750663 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Cscore</th><td>  1.018018</td><td>2.1750663 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Impulsive</th><td>  1.156352</td><td>0.5305040 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>SS</th><td>  1.116592</td><td>0.5835544 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Alcohol</th><td>  1.502970</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Amphet</th><td>  4.016461</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Amyl</th><td>  5.506329</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Benzos</th><td>  4.237288</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Caff</th><td>  5.073260</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Cannabis</th><td>  1.121065</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Choc</th><td>  1.181552</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Coke</th><td>  3.844444</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Crack</th><td> 14.526786</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Ecstasy</th><td>  3.685921</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Heroin</th><td> 17.074468</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Ketamine</th><td> 10.492958</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Legalh</th><td>  3.386997</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>LSD</th><td>  4.127413</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Meth</th><td>  9.590604</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Mushrooms</th><td>  3.570909</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Nicotine</th><td>  1.425234</td><td>0.3713528 </td><td>FALSE     </td><td>FALSE     </td></tr>
	<tr><th scope=row>Semer</th><td>625.666667</td><td>0.2652520 </td><td>FALSE     </td><td> TRUE     </td></tr>
	<tr><th scope=row>VSA</th><td>  3.383721</td><td>0.1061008 </td><td>FALSE     </td><td>FALSE     </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[359]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data3</span><span class="p">),</span> <span class="n">size</span> <span class="o">=</span> <span class="nf">floor</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">data3</span><span class="p">)</span><span class="o">*</span><span class="m">0.77</span><span class="p">),</span> <span class="n">replace</span> <span class="o">=</span> <span class="bp">F</span><span class="p">)</span>
<span class="n">train3</span> <span class="o">&lt;-</span> <span class="n">data3</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
<span class="n">test3</span>  <span class="o">&lt;-</span> <span class="n">data3</span><span class="p">[</span><span class="o">-</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[373]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">fold3</span> <span class="o">&lt;-</span> <span class="nf">createMultiFolds</span><span class="p">(</span><span class="n">train3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="n">times</span> <span class="o">=</span><span class="m">1</span><span class="p">)</span>

<span class="n">control3</span><span class="o">&lt;-</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;cv&quot;</span><span class="p">,</span><span class="n">verboseIter</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">classProbs</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">savePredictions</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">fold3</span><span class="p">,</span><span class="n">allowParallel</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[364]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">str</span><span class="p">(</span><span class="n">train3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>&#39;data.frame&#39;:	1451 obs. of  31 variables:
 $ Age      : Factor w/ 6 levels &#34;-0.95197&#34;,&#34;-0.07854&#34;,..: 2 3 4 3 2 3 1 3 3 1 ...
 $ Gender   : Factor w/ 2 levels &#34;-0.48246&#34;,&#34;0.48246&#34;: 1 1 1 1 2 2 1 2 2 2 ...
 $ Education: Factor w/ 9 levels &#34;-2.43591&#34;,&#34;-1.7379&#34;,..: 4 5 9 9 7 5 8 6 8 5 ...
 $ Country  : Factor w/ 7 levels &#34;-0.57009&#34;,&#34;-0.46841&#34;,..: 3 3 7 7 4 5 7 1 7 6 ...
 $ Ethnicity: Factor w/ 7 levels &#34;-1.10702&#34;,&#34;-0.50212&#34;,..: 3 3 3 2 3 3 4 3 1 3 ...
 $ Nscore   : num  0.2239 -0.348 0.2239 0.0426 0.7355 ...
 $ Escore   : num  1.58487 0.00332 -0.80615 0.63779 -0.69509 ...
 $ Oscore   : num  0.293 0.723 -0.178 0.141 1.24 ...
 $ Ascore   : num  -1.4795 0.2878 -0.0173 0.1314 0.9416 ...
 $ Cscore   : num  -0.00665 0.12331 -2.04506 0.25953 0.41594 ...
 $ Impulsive: num  -0.217 -0.217 -0.711 -0.217 0.53 ...
 $ SS       : num  0.765 0.765 -2.078 -1.181 0.765 ...
 $ Alcohol  : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 7 7 1 5 6 6 6 5 5 ...
 $ Amphet   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 5 3 7 1 3 4 3 1 1 7 ...
 $ Amyl     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 2 1 2 1 1 3 3 1 1 1 ...
 $ Benzos   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 3 4 4 3 2 1 3 1 3 1 ...
 $ Caff     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 7 7 7 2 7 7 7 5 3 6 ...
 $ Cannabis : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 7 7 2 1 3 5 7 1 1 4 ...
 $ Choc     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 6 6 5 4 6 6 6 6 5 5 ...
 $ Coke     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 3 5 4 1 2 4 3 1 1 4 ...
 $ Crack    : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 5 4 1 1 1 1 1 1 1 ...
 $ Ecstasy  : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 7 3 7 1 2 5 4 1 1 5 ...
 $ Heroin   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 4 4 1 2 1 1 1 1 1 ...
 $ Ketamine : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 6 1 4 1 5 4 1 1 1 1 ...
 $ Legalh   : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 5 4 4 1 3 4 3 1 1 3 ...
 $ LSD      : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 7 5 3 1 3 2 4 1 1 1 ...
 $ Meth     : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 3 3 1 1 1 1 1 1 1 ...
 $ Mushrooms: Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 3 5 3 1 3 2 4 1 1 1 ...
 $ Nicotine : Factor w/ 7 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 7 1 2 7 6 7 1 1 5 ...
 $ Semer    : Factor w/ 5 levels &#34;CL0&#34;,&#34;CL1&#34;,&#34;CL2&#34;,..: 1 1 1 1 1 1 1 1 1 1 ...
 $ VSA      : Factor w/ 2 levels &#34;VSAneverused&#34;,..: 2 2 1 1 1 2 1 1 1 2 ...
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[374]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">lasso_grid3</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">lambda</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">6</span><span class="p">)))</span>
<span class="n">reg3</span><span class="o">&lt;-</span><span class="nf">train</span><span class="p">(</span><span class="n">VSA</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">train3</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;glmnet&quot;</span><span class="p">,</span><span class="n">tuneGrid</span><span class="o">=</span><span class="n">lasso_grid3</span><span class="p">,</span>
               <span class="n">trControl</span><span class="o">=</span><span class="n">control3</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold1.Rep1: alpha=1, lambda=0.1 
- Fold1.Rep1: alpha=1, lambda=0.1 
+ Fold2.Rep1: alpha=1, lambda=0.1 
- Fold2.Rep1: alpha=1, lambda=0.1 
+ Fold3.Rep1: alpha=1, lambda=0.1 
- Fold3.Rep1: alpha=1, lambda=0.1 
+ Fold4.Rep1: alpha=1, lambda=0.1 
- Fold4.Rep1: alpha=1, lambda=0.1 
+ Fold5.Rep1: alpha=1, lambda=0.1 
- Fold5.Rep1: alpha=1, lambda=0.1 
Aggregating results
Selecting tuning parameters
Fitting alpha = 1, lambda = 0.0208 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[375]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">lasso_pred3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">reg3</span><span class="p">,</span><span class="n">test3</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>

<span class="n">lasso_error3</span> <span class="o">=</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">lasso_pred3</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = VSAneverused, case = VSAused
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[388]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt_grid3</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.1</span><span class="p">))</span>
<span class="n">dt3.1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">VSA</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train3</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid3</span> <span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control3</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">)))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold1.Rep1: cp=0.001 
- Fold1.Rep1: cp=0.001 
+ Fold2.Rep1: cp=0.001 
- Fold2.Rep1: cp=0.001 
+ Fold3.Rep1: cp=0.001 
- Fold3.Rep1: cp=0.001 
+ Fold4.Rep1: cp=0.001 
- Fold4.Rep1: cp=0.001 
+ Fold5.Rep1: cp=0.001 
- Fold5.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[389]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt_pred3.1</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt3.1</span><span class="p">,</span><span class="n">test3</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>

<span class="n">dt_error3.1</span> <span class="o">=</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">dt_pred3.1</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = VSAneverused, case = VSAused
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[392]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt3.2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">VSA</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train3</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid3</span> <span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control3</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">8</span><span class="p">)))</span>
<span class="n">dt_pred3.2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt3.2</span><span class="p">,</span><span class="n">test3</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>

<span class="n">dt_error3.2</span> <span class="o">=</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">dt_pred3.2</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold1.Rep1: cp=0.001 
- Fold1.Rep1: cp=0.001 
+ Fold2.Rep1: cp=0.001 
- Fold2.Rep1: cp=0.001 
+ Fold3.Rep1: cp=0.001 
- Fold3.Rep1: cp=0.001 
+ Fold4.Rep1: cp=0.001 
- Fold4.Rep1: cp=0.001 
+ Fold5.Rep1: cp=0.001 
- Fold5.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = VSAneverused, case = VSAused
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[381]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt3.3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">VSA</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train3</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid3</span> <span class="p">,</span>
             <span class="n">trControl</span><span class="o">=</span><span class="n">control3</span><span class="p">,</span> <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">)))</span>
<span class="n">dt_pred3.3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt3.3</span><span class="p">,</span><span class="n">test3</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>

<span class="n">dt_error3.3</span> <span class="o">=</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">dt_pred3.3</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold1.Rep1: cp=0.001 
- Fold1.Rep1: cp=0.001 
+ Fold2.Rep1: cp=0.001 
- Fold2.Rep1: cp=0.001 
+ Fold3.Rep1: cp=0.001 
- Fold3.Rep1: cp=0.001 
+ Fold4.Rep1: cp=0.001 
- Fold4.Rep1: cp=0.001 
+ Fold5.Rep1: cp=0.001 
- Fold5.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = VSAneverused, case = VSAused
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[383]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">rf3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">VSA</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;ranger&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">rf_grid3</span><span class="p">,</span>
                 <span class="n">trControl</span><span class="o">=</span> <span class="n">control3</span><span class="p">)</span>
<span class="n">rf_pred3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">rf3</span><span class="p">,</span><span class="n">test3</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>

<span class="n">rf_error3</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">rf_pred3</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold1.Rep1: mtry=2, min.node.size=10, splitrule=gini 
- Fold1.Rep1: mtry=2, min.node.size=10, splitrule=gini 
+ Fold1.Rep1: mtry=3, min.node.size=10, splitrule=gini 
- Fold1.Rep1: mtry=3, min.node.size=10, splitrule=gini 
+ Fold1.Rep1: mtry=4, min.node.size=10, splitrule=gini 
- Fold1.Rep1: mtry=4, min.node.size=10, splitrule=gini 
+ Fold2.Rep1: mtry=2, min.node.size=10, splitrule=gini 
- Fold2.Rep1: mtry=2, min.node.size=10, splitrule=gini 
+ Fold2.Rep1: mtry=3, min.node.size=10, splitrule=gini 
- Fold2.Rep1: mtry=3, min.node.size=10, splitrule=gini 
+ Fold2.Rep1: mtry=4, min.node.size=10, splitrule=gini 
- Fold2.Rep1: mtry=4, min.node.size=10, splitrule=gini 
+ Fold3.Rep1: mtry=2, min.node.size=10, splitrule=gini 
- Fold3.Rep1: mtry=2, min.node.size=10, splitrule=gini 
+ Fold3.Rep1: mtry=3, min.node.size=10, splitrule=gini 
- Fold3.Rep1: mtry=3, min.node.size=10, splitrule=gini 
+ Fold3.Rep1: mtry=4, min.node.size=10, splitrule=gini 
- Fold3.Rep1: mtry=4, min.node.size=10, splitrule=gini 
+ Fold4.Rep1: mtry=2, min.node.size=10, splitrule=gini 
- Fold4.Rep1: mtry=2, min.node.size=10, splitrule=gini 
+ Fold4.Rep1: mtry=3, min.node.size=10, splitrule=gini 
- Fold4.Rep1: mtry=3, min.node.size=10, splitrule=gini 
+ Fold4.Rep1: mtry=4, min.node.size=10, splitrule=gini 
- Fold4.Rep1: mtry=4, min.node.size=10, splitrule=gini 
+ Fold5.Rep1: mtry=2, min.node.size=10, splitrule=gini 
- Fold5.Rep1: mtry=2, min.node.size=10, splitrule=gini 
+ Fold5.Rep1: mtry=3, min.node.size=10, splitrule=gini 
- Fold5.Rep1: mtry=3, min.node.size=10, splitrule=gini 
+ Fold5.Rep1: mtry=4, min.node.size=10, splitrule=gini 
- Fold5.Rep1: mtry=4, min.node.size=10, splitrule=gini 
Aggregating results
Selecting tuning parameters
Fitting mtry = 4, splitrule = gini, min.node.size = 10 on full training set
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = VSAneverused, case = VSAused
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[385]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">sgb_grid3</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">300</span><span class="p">),</span><span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.1</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span> <span class="m">0.001</span><span class="p">),</span> <span class="n">n.minobsinnode</span><span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="n">sgb3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">VSA</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">sgb_grid3</span><span class="p">,</span>
              <span class="n">trControl</span><span class="o">=</span> <span class="n">control3</span><span class="p">)</span>
<span class="n">sgb_pred3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sgb3</span><span class="p">,</span><span class="n">test3</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>

<span class="n">sgb_error3</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test3</span><span class="o">$</span><span class="n">VSA</span><span class="p">,</span><span class="n">sgb_pred3</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold1.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0678             nan     0.0010    0.0001
     2        1.0677             nan     0.0010    0.0001
     3        1.0675             nan     0.0010    0.0001
     4        1.0674             nan     0.0010    0.0001
     5        1.0673             nan     0.0010    0.0001
     6        1.0671             nan     0.0010    0.0001
     7        1.0670             nan     0.0010    0.0000
     8        1.0668             nan     0.0010    0.0000
     9        1.0667             nan     0.0010    0.0001
    10        1.0666             nan     0.0010    0.0000
    20        1.0652             nan     0.0010    0.0001
    40        1.0628             nan     0.0010    0.0001
    60        1.0602             nan     0.0010    0.0001
    80        1.0578             nan     0.0010    0.0001
   100        1.0555             nan     0.0010    0.0000
   120        1.0532             nan     0.0010    0.0000
   140        1.0511             nan     0.0010    0.0000
   160        1.0489             nan     0.0010    0.0000
   180        1.0467             nan     0.0010    0.0001
   200        1.0446             nan     0.0010    0.0001
   220        1.0426             nan     0.0010    0.0000
   240        1.0405             nan     0.0010    0.0000
   260        1.0385             nan     0.0010    0.0000
   280        1.0367             nan     0.0010    0.0000
   300        1.0349             nan     0.0010    0.0000

- Fold1.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0678             nan     0.0010    0.0001
     2        1.0676             nan     0.0010    0.0001
     3        1.0673             nan     0.0010    0.0001
     4        1.0670             nan     0.0010    0.0001
     5        1.0668             nan     0.0010    0.0001
     6        1.0666             nan     0.0010    0.0001
     7        1.0663             nan     0.0010    0.0001
     8        1.0661             nan     0.0010    0.0001
     9        1.0659             nan     0.0010    0.0001
    10        1.0656             nan     0.0010    0.0001
    20        1.0631             nan     0.0010    0.0001
    40        1.0587             nan     0.0010    0.0001
    60        1.0543             nan     0.0010    0.0001
    80        1.0497             nan     0.0010    0.0001
   100        1.0453             nan     0.0010    0.0001
   120        1.0413             nan     0.0010    0.0001
   140        1.0371             nan     0.0010    0.0001
   160        1.0330             nan     0.0010    0.0001
   180        1.0291             nan     0.0010    0.0000
   200        1.0254             nan     0.0010    0.0001
   220        1.0215             nan     0.0010    0.0001
   240        1.0179             nan     0.0010    0.0001
   260        1.0144             nan     0.0010    0.0001
   280        1.0109             nan     0.0010    0.0001
   300        1.0077             nan     0.0010    0.0001

- Fold1.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0677             nan     0.0010    0.0001
     2        1.0674             nan     0.0010    0.0001
     3        1.0671             nan     0.0010    0.0001
     4        1.0668             nan     0.0010    0.0001
     5        1.0665             nan     0.0010    0.0001
     6        1.0662             nan     0.0010    0.0001
     7        1.0660             nan     0.0010    0.0001
     8        1.0657             nan     0.0010    0.0001
     9        1.0654             nan     0.0010    0.0001
    10        1.0651             nan     0.0010    0.0001
    20        1.0621             nan     0.0010    0.0001
    40        1.0562             nan     0.0010    0.0001
    60        1.0504             nan     0.0010    0.0001
    80        1.0448             nan     0.0010    0.0001
   100        1.0390             nan     0.0010    0.0001
   120        1.0337             nan     0.0010    0.0001
   140        1.0283             nan     0.0010    0.0001
   160        1.0231             nan     0.0010    0.0001
   180        1.0182             nan     0.0010    0.0001
   200        1.0134             nan     0.0010    0.0001
   220        1.0084             nan     0.0010    0.0001
   240        1.0037             nan     0.0010    0.0001
   260        0.9991             nan     0.0010    0.0001
   280        0.9946             nan     0.0010    0.0001
   300        0.9901             nan     0.0010    0.0001

- Fold1.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0666             nan     0.0100    0.0005
     2        1.0655             nan     0.0100    0.0006
     3        1.0642             nan     0.0100    0.0006
     4        1.0627             nan     0.0100    0.0006
     5        1.0612             nan     0.0100    0.0006
     6        1.0601             nan     0.0100    0.0006
     7        1.0589             nan     0.0100    0.0006
     8        1.0581             nan     0.0100    0.0001
     9        1.0570             nan     0.0100    0.0005
    10        1.0558             nan     0.0100    0.0006
    20        1.0446             nan     0.0100    0.0004
    40        1.0261             nan     0.0100    0.0001
    60        1.0093             nan     0.0100    0.0002
    80        0.9962             nan     0.0100    0.0002
   100        0.9841             nan     0.0100    0.0001
   120        0.9737             nan     0.0100    0.0001
   140        0.9635             nan     0.0100    0.0002
   160        0.9554             nan     0.0100   -0.0000
   180        0.9477             nan     0.0100    0.0001
   200        0.9406             nan     0.0100    0.0001
   220        0.9337             nan     0.0100   -0.0000
   240        0.9274             nan     0.0100   -0.0000
   260        0.9214             nan     0.0100    0.0001
   280        0.9161             nan     0.0100    0.0000
   300        0.9108             nan     0.0100    0.0000

- Fold1.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0655             nan     0.0100    0.0008
     2        1.0632             nan     0.0100    0.0010
     3        1.0605             nan     0.0100    0.0010
     4        1.0582             nan     0.0100    0.0010
     5        1.0563             nan     0.0100    0.0005
     6        1.0538             nan     0.0100    0.0009
     7        1.0518             nan     0.0100    0.0008
     8        1.0496             nan     0.0100    0.0010
     9        1.0473             nan     0.0100    0.0011
    10        1.0456             nan     0.0100    0.0005
    20        1.0255             nan     0.0100    0.0005
    40        0.9925             nan     0.0100    0.0003
    60        0.9640             nan     0.0100    0.0005
    80        0.9400             nan     0.0100    0.0003
   100        0.9197             nan     0.0100    0.0002
   120        0.9033             nan     0.0100    0.0002
   140        0.8887             nan     0.0100    0.0000
   160        0.8746             nan     0.0100    0.0002
   180        0.8627             nan     0.0100   -0.0001
   200        0.8522             nan     0.0100   -0.0001
   220        0.8416             nan     0.0100   -0.0000
   240        0.8318             nan     0.0100    0.0001
   260        0.8235             nan     0.0100   -0.0001
   280        0.8159             nan     0.0100    0.0001
   300        0.8084             nan     0.0100   -0.0000

- Fold1.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0649             nan     0.0100    0.0010
     2        1.0615             nan     0.0100    0.0013
     3        1.0585             nan     0.0100    0.0010
     4        1.0554             nan     0.0100    0.0011
     5        1.0527             nan     0.0100    0.0012
     6        1.0493             nan     0.0100    0.0012
     7        1.0465             nan     0.0100    0.0012
     8        1.0436             nan     0.0100    0.0011
     9        1.0409             nan     0.0100    0.0012
    10        1.0378             nan     0.0100    0.0010
    20        1.0098             nan     0.0100    0.0009
    40        0.9680             nan     0.0100    0.0010
    60        0.9349             nan     0.0100    0.0003
    80        0.9073             nan     0.0100    0.0003
   100        0.8829             nan     0.0100    0.0003
   120        0.8622             nan     0.0100    0.0000
   140        0.8439             nan     0.0100    0.0001
   160        0.8275             nan     0.0100    0.0001
   180        0.8122             nan     0.0100    0.0001
   200        0.7989             nan     0.0100   -0.0000
   220        0.7866             nan     0.0100    0.0001
   240        0.7754             nan     0.0100   -0.0001
   260        0.7649             nan     0.0100   -0.0001
   280        0.7546             nan     0.0100    0.0000
   300        0.7450             nan     0.0100   -0.0001

- Fold1.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0550             nan     0.1000    0.0063
     2        1.0447             nan     0.1000    0.0023
     3        1.0346             nan     0.1000    0.0046
     4        1.0248             nan     0.1000    0.0036
     5        1.0160             nan     0.1000    0.0018
     6        1.0065             nan     0.1000    0.0022
     7        0.9985             nan     0.1000    0.0035
     8        0.9946             nan     0.1000    0.0013
     9        0.9875             nan     0.1000    0.0022
    10        0.9821             nan     0.1000    0.0026
    20        0.9387             nan     0.1000    0.0010
    40        0.8873             nan     0.1000   -0.0005
    60        0.8558             nan     0.1000    0.0003
    80        0.8345             nan     0.1000   -0.0005
   100        0.8181             nan     0.1000   -0.0005
   120        0.8057             nan     0.1000   -0.0003
   140        0.7930             nan     0.1000   -0.0006
   160        0.7842             nan     0.1000   -0.0010
   180        0.7776             nan     0.1000   -0.0008
   200        0.7718             nan     0.1000   -0.0007
   220        0.7663             nan     0.1000   -0.0007
   240        0.7603             nan     0.1000   -0.0003
   260        0.7535             nan     0.1000   -0.0008
   280        0.7486             nan     0.1000   -0.0008
   300        0.7439             nan     0.1000   -0.0004

- Fold1.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0475             nan     0.1000    0.0060
     2        1.0280             nan     0.1000    0.0091
     3        1.0105             nan     0.1000    0.0063
     4        0.9952             nan     0.1000    0.0047
     5        0.9816             nan     0.1000    0.0050
     6        0.9655             nan     0.1000    0.0033
     7        0.9540             nan     0.1000    0.0037
     8        0.9420             nan     0.1000    0.0042
     9        0.9323             nan     0.1000    0.0037
    10        0.9248             nan     0.1000    0.0013
    20        0.8513             nan     0.1000    0.0011
    40        0.7772             nan     0.1000   -0.0006
    60        0.7247             nan     0.1000   -0.0010
    80        0.6874             nan     0.1000   -0.0006
   100        0.6607             nan     0.1000   -0.0014
   120        0.6361             nan     0.1000   -0.0020
   140        0.6089             nan     0.1000   -0.0016
   160        0.5881             nan     0.1000   -0.0016
   180        0.5703             nan     0.1000   -0.0010
   200        0.5511             nan     0.1000   -0.0003
   220        0.5338             nan     0.1000   -0.0015
   240        0.5163             nan     0.1000   -0.0012
   260        0.5022             nan     0.1000   -0.0013
   280        0.4907             nan     0.1000   -0.0004
   300        0.4765             nan     0.1000   -0.0011

- Fold1.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold1.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 138: SemerCL3 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0366             nan     0.1000    0.0124
     2        1.0082             nan     0.1000    0.0112
     3        0.9853             nan     0.1000    0.0088
     4        0.9648             nan     0.1000    0.0080
     5        0.9497             nan     0.1000    0.0030
     6        0.9343             nan     0.1000    0.0046
     7        0.9196             nan     0.1000    0.0042
     8        0.9083             nan     0.1000    0.0022
     9        0.8985             nan     0.1000    0.0003
    10        0.8870             nan     0.1000    0.0015
    20        0.8047             nan     0.1000    0.0007
    40        0.7153             nan     0.1000   -0.0015
    60        0.6600             nan     0.1000   -0.0015
    80        0.6071             nan     0.1000   -0.0007
   100        0.5585             nan     0.1000   -0.0013
   120        0.5202             nan     0.1000   -0.0009
   140        0.4874             nan     0.1000   -0.0006
   160        0.4582             nan     0.1000   -0.0015
   180        0.4370             nan     0.1000   -0.0018
   200        0.4080             nan     0.1000   -0.0009
   220        0.3843             nan     0.1000   -0.0005
   240        0.3616             nan     0.1000   -0.0010
   260        0.3405             nan     0.1000   -0.0008
   280        0.3240             nan     0.1000   -0.0006
   300        0.3094             nan     0.1000   -0.0011

- Fold1.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0674             nan     0.0010    0.0000
     2        1.0673             nan     0.0010    0.0000
     3        1.0672             nan     0.0010    0.0001
     4        1.0671             nan     0.0010    0.0001
     5        1.0670             nan     0.0010    0.0000
     6        1.0668             nan     0.0010    0.0000
     7        1.0667             nan     0.0010    0.0000
     8        1.0666             nan     0.0010    0.0000
     9        1.0666             nan     0.0010    0.0000
    10        1.0664             nan     0.0010    0.0000
    20        1.0654             nan     0.0010    0.0000
    40        1.0633             nan     0.0010    0.0000
    60        1.0612             nan     0.0010    0.0000
    80        1.0593             nan     0.0010    0.0000
   100        1.0571             nan     0.0010    0.0000
   120        1.0551             nan     0.0010    0.0000
   140        1.0532             nan     0.0010    0.0000
   160        1.0512             nan     0.0010    0.0000
   180        1.0494             nan     0.0010    0.0000
   200        1.0475             nan     0.0010    0.0000
   220        1.0456             nan     0.0010    0.0000
   240        1.0439             nan     0.0010    0.0000
   260        1.0421             nan     0.0010    0.0000
   280        1.0405             nan     0.0010    0.0000
   300        1.0388             nan     0.0010    0.0000

- Fold2.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0673             nan     0.0010    0.0001
     2        1.0670             nan     0.0010    0.0001
     3        1.0668             nan     0.0010    0.0001
     4        1.0665             nan     0.0010    0.0001
     5        1.0663             nan     0.0010    0.0001
     6        1.0661             nan     0.0010    0.0001
     7        1.0659             nan     0.0010    0.0001
     8        1.0657             nan     0.0010    0.0001
     9        1.0655             nan     0.0010    0.0001
    10        1.0652             nan     0.0010    0.0001
    20        1.0631             nan     0.0010    0.0001
    40        1.0588             nan     0.0010    0.0001
    60        1.0547             nan     0.0010    0.0001
    80        1.0506             nan     0.0010    0.0001
   100        1.0466             nan     0.0010    0.0001
   120        1.0426             nan     0.0010    0.0001
   140        1.0389             nan     0.0010    0.0001
   160        1.0351             nan     0.0010    0.0001
   180        1.0316             nan     0.0010    0.0000
   200        1.0279             nan     0.0010    0.0001
   220        1.0243             nan     0.0010    0.0001
   240        1.0209             nan     0.0010    0.0001
   260        1.0175             nan     0.0010    0.0000
   280        1.0142             nan     0.0010    0.0000
   300        1.0109             nan     0.0010    0.0001

- Fold2.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0673             nan     0.0010    0.0001
     2        1.0669             nan     0.0010    0.0001
     3        1.0666             nan     0.0010    0.0001
     4        1.0664             nan     0.0010    0.0001
     5        1.0661             nan     0.0010    0.0001
     6        1.0659             nan     0.0010    0.0001
     7        1.0656             nan     0.0010    0.0001
     8        1.0653             nan     0.0010    0.0001
     9        1.0650             nan     0.0010    0.0001
    10        1.0647             nan     0.0010    0.0001
    20        1.0617             nan     0.0010    0.0001
    40        1.0563             nan     0.0010    0.0001
    60        1.0507             nan     0.0010    0.0001
    80        1.0453             nan     0.0010    0.0001
   100        1.0401             nan     0.0010    0.0001
   120        1.0349             nan     0.0010    0.0001
   140        1.0298             nan     0.0010    0.0001
   160        1.0248             nan     0.0010    0.0001
   180        1.0201             nan     0.0010    0.0000
   200        1.0155             nan     0.0010    0.0000
   220        1.0109             nan     0.0010    0.0001
   240        1.0066             nan     0.0010    0.0001
   260        1.0021             nan     0.0010    0.0001
   280        0.9979             nan     0.0010    0.0000
   300        0.9937             nan     0.0010    0.0001

- Fold2.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0665             nan     0.0100    0.0003
     2        1.0655             nan     0.0100    0.0004
     3        1.0643             nan     0.0100    0.0004
     4        1.0635             nan     0.0100    0.0002
     5        1.0622             nan     0.0100    0.0005
     6        1.0611             nan     0.0100    0.0005
     7        1.0600             nan     0.0100    0.0004
     8        1.0589             nan     0.0100    0.0005
     9        1.0581             nan     0.0100    0.0005
    10        1.0573             nan     0.0100    0.0002
    20        1.0478             nan     0.0100    0.0001
    40        1.0305             nan     0.0100    0.0003
    60        1.0174             nan     0.0100    0.0002
    80        1.0036             nan     0.0100    0.0003
   100        0.9916             nan     0.0100    0.0001
   120        0.9812             nan     0.0100    0.0001
   140        0.9713             nan     0.0100    0.0002
   160        0.9623             nan     0.0100    0.0001
   180        0.9540             nan     0.0100    0.0002
   200        0.9466             nan     0.0100    0.0001
   220        0.9393             nan     0.0100    0.0000
   240        0.9329             nan     0.0100    0.0000
   260        0.9263             nan     0.0100   -0.0000
   280        0.9205             nan     0.0100    0.0000
   300        0.9148             nan     0.0100    0.0000

- Fold2.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0653             nan     0.0100    0.0008
     2        1.0633             nan     0.0100    0.0009
     3        1.0605             nan     0.0100    0.0008
     4        1.0582             nan     0.0100    0.0009
     5        1.0560             nan     0.0100    0.0011
     6        1.0540             nan     0.0100    0.0005
     7        1.0522             nan     0.0100    0.0007
     8        1.0504             nan     0.0100    0.0008
     9        1.0486             nan     0.0100    0.0008
    10        1.0468             nan     0.0100    0.0004
    20        1.0280             nan     0.0100    0.0007
    40        0.9955             nan     0.0100    0.0004
    60        0.9683             nan     0.0100    0.0003
    80        0.9458             nan     0.0100    0.0003
   100        0.9254             nan     0.0100    0.0003
   120        0.9082             nan     0.0100    0.0002
   140        0.8931             nan     0.0100    0.0002
   160        0.8791             nan     0.0100    0.0003
   180        0.8671             nan     0.0100    0.0000
   200        0.8553             nan     0.0100    0.0002
   220        0.8446             nan     0.0100    0.0001
   240        0.8351             nan     0.0100    0.0000
   260        0.8265             nan     0.0100   -0.0000
   280        0.8180             nan     0.0100    0.0001
   300        0.8109             nan     0.0100    0.0000

- Fold2.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0651             nan     0.0100    0.0009
     2        1.0625             nan     0.0100    0.0010
     3        1.0593             nan     0.0100    0.0012
     4        1.0568             nan     0.0100    0.0010
     5        1.0536             nan     0.0100    0.0010
     6        1.0512             nan     0.0100    0.0008
     7        1.0485             nan     0.0100    0.0009
     8        1.0458             nan     0.0100    0.0010
     9        1.0435             nan     0.0100    0.0007
    10        1.0406             nan     0.0100    0.0011
    20        1.0169             nan     0.0100    0.0007
    40        0.9763             nan     0.0100    0.0003
    60        0.9403             nan     0.0100    0.0007
    80        0.9118             nan     0.0100    0.0004
   100        0.8874             nan     0.0100    0.0002
   120        0.8665             nan     0.0100    0.0002
   140        0.8478             nan     0.0100    0.0001
   160        0.8313             nan     0.0100   -0.0000
   180        0.8167             nan     0.0100   -0.0000
   200        0.8029             nan     0.0100   -0.0000
   220        0.7904             nan     0.0100    0.0001
   240        0.7794             nan     0.0100    0.0000
   260        0.7689             nan     0.0100    0.0000
   280        0.7586             nan     0.0100    0.0000
   300        0.7488             nan     0.0100   -0.0001

- Fold2.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0577             nan     0.1000    0.0028
     2        1.0462             nan     0.1000    0.0037
     3        1.0363             nan     0.1000    0.0039
     4        1.0258             nan     0.1000    0.0040
     5        1.0184             nan     0.1000    0.0034
     6        1.0116             nan     0.1000    0.0031
     7        1.0061             nan     0.1000    0.0020
     8        1.0024             nan     0.1000    0.0005
     9        0.9986             nan     0.1000    0.0008
    10        0.9940             nan     0.1000    0.0014
    20        0.9479             nan     0.1000   -0.0010
    40        0.8897             nan     0.1000    0.0004
    60        0.8568             nan     0.1000    0.0005
    80        0.8335             nan     0.1000    0.0002
   100        0.8158             nan     0.1000   -0.0002
   120        0.8030             nan     0.1000   -0.0006
   140        0.7887             nan     0.1000   -0.0005
   160        0.7796             nan     0.1000   -0.0003
   180        0.7716             nan     0.1000   -0.0005
   200        0.7645             nan     0.1000   -0.0008
   220        0.7565             nan     0.1000   -0.0011
   240        0.7505             nan     0.1000   -0.0006
   260        0.7442             nan     0.1000   -0.0008
   280        0.7389             nan     0.1000   -0.0008
   300        0.7334             nan     0.1000   -0.0010

- Fold2.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0436             nan     0.1000    0.0104
     2        1.0275             nan     0.1000    0.0047
     3        1.0065             nan     0.1000    0.0073
     4        0.9909             nan     0.1000    0.0051
     5        0.9767             nan     0.1000    0.0053
     6        0.9637             nan     0.1000    0.0038
     7        0.9539             nan     0.1000    0.0026
     8        0.9425             nan     0.1000    0.0031
     9        0.9312             nan     0.1000    0.0048
    10        0.9205             nan     0.1000    0.0032
    20        0.8536             nan     0.1000    0.0001
    40        0.7790             nan     0.1000   -0.0012
    60        0.7330             nan     0.1000   -0.0002
    80        0.6984             nan     0.1000   -0.0017
   100        0.6651             nan     0.1000   -0.0012
   120        0.6329             nan     0.1000    0.0004
   140        0.6069             nan     0.1000   -0.0006
   160        0.5844             nan     0.1000   -0.0014
   180        0.5649             nan     0.1000   -0.0023
   200        0.5457             nan     0.1000   -0.0010
   220        0.5297             nan     0.1000   -0.0003
   240        0.5120             nan     0.1000   -0.0015
   260        0.4962             nan     0.1000   -0.0009
   280        0.4837             nan     0.1000   -0.0007
   300        0.4687             nan     0.1000   -0.0008

- Fold2.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold2.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0382             nan     0.1000    0.0096
     2        1.0185             nan     0.1000    0.0074
     3        0.9988             nan     0.1000    0.0057
     4        0.9821             nan     0.1000    0.0046
     5        0.9621             nan     0.1000    0.0075
     6        0.9448             nan     0.1000    0.0059
     7        0.9293             nan     0.1000    0.0047
     8        0.9132             nan     0.1000    0.0060
     9        0.8983             nan     0.1000    0.0045
    10        0.8855             nan     0.1000    0.0037
    20        0.8023             nan     0.1000    0.0000
    40        0.7097             nan     0.1000   -0.0024
    60        0.6518             nan     0.1000   -0.0011
    80        0.6058             nan     0.1000   -0.0006
   100        0.5646             nan     0.1000   -0.0007
   120        0.5259             nan     0.1000   -0.0012
   140        0.4971             nan     0.1000   -0.0008
   160        0.4676             nan     0.1000   -0.0018
   180        0.4385             nan     0.1000   -0.0010
   200        0.4112             nan     0.1000   -0.0004
   220        0.3860             nan     0.1000   -0.0008
   240        0.3632             nan     0.1000   -0.0005
   260        0.3445             nan     0.1000   -0.0012
   280        0.3227             nan     0.1000   -0.0007
   300        0.3072             nan     0.1000   -0.0010

- Fold2.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0662             nan     0.0010    0.0001
     2        1.0661             nan     0.0010    0.0001
     3        1.0660             nan     0.0010    0.0000
     4        1.0658             nan     0.0010    0.0001
     5        1.0657             nan     0.0010    0.0001
     6        1.0656             nan     0.0010    0.0000
     7        1.0654             nan     0.0010    0.0001
     8        1.0653             nan     0.0010    0.0001
     9        1.0652             nan     0.0010    0.0001
    10        1.0650             nan     0.0010    0.0001
    20        1.0637             nan     0.0010    0.0001
    40        1.0614             nan     0.0010    0.0000
    60        1.0588             nan     0.0010    0.0001
    80        1.0564             nan     0.0010    0.0001
   100        1.0538             nan     0.0010    0.0000
   120        1.0515             nan     0.0010    0.0000
   140        1.0491             nan     0.0010    0.0000
   160        1.0469             nan     0.0010    0.0000
   180        1.0445             nan     0.0010    0.0000
   200        1.0423             nan     0.0010    0.0001
   220        1.0401             nan     0.0010    0.0000
   240        1.0380             nan     0.0010    0.0000
   260        1.0359             nan     0.0010    0.0001
   280        1.0338             nan     0.0010    0.0000
   300        1.0318             nan     0.0010    0.0000

- Fold3.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0661             nan     0.0010    0.0001
     2        1.0659             nan     0.0010    0.0001
     3        1.0656             nan     0.0010    0.0001
     4        1.0654             nan     0.0010    0.0001
     5        1.0651             nan     0.0010    0.0001
     6        1.0649             nan     0.0010    0.0001
     7        1.0646             nan     0.0010    0.0001
     8        1.0643             nan     0.0010    0.0001
     9        1.0640             nan     0.0010    0.0001
    10        1.0638             nan     0.0010    0.0001
    20        1.0612             nan     0.0010    0.0001
    40        1.0562             nan     0.0010    0.0001
    60        1.0515             nan     0.0010    0.0001
    80        1.0469             nan     0.0010    0.0001
   100        1.0425             nan     0.0010    0.0001
   120        1.0382             nan     0.0010    0.0001
   140        1.0339             nan     0.0010    0.0000
   160        1.0299             nan     0.0010    0.0001
   180        1.0260             nan     0.0010    0.0001
   200        1.0219             nan     0.0010    0.0001
   220        1.0179             nan     0.0010    0.0001
   240        1.0141             nan     0.0010    0.0001
   260        1.0104             nan     0.0010    0.0000
   280        1.0067             nan     0.0010    0.0001
   300        1.0030             nan     0.0010    0.0000

- Fold3.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0660             nan     0.0010    0.0002
     2        1.0656             nan     0.0010    0.0001
     3        1.0653             nan     0.0010    0.0001
     4        1.0650             nan     0.0010    0.0001
     5        1.0646             nan     0.0010    0.0001
     6        1.0643             nan     0.0010    0.0001
     7        1.0640             nan     0.0010    0.0001
     8        1.0637             nan     0.0010    0.0001
     9        1.0634             nan     0.0010    0.0001
    10        1.0631             nan     0.0010    0.0001
    20        1.0598             nan     0.0010    0.0001
    40        1.0535             nan     0.0010    0.0001
    60        1.0472             nan     0.0010    0.0001
    80        1.0415             nan     0.0010    0.0001
   100        1.0358             nan     0.0010    0.0001
   120        1.0302             nan     0.0010    0.0001
   140        1.0250             nan     0.0010    0.0001
   160        1.0196             nan     0.0010    0.0001
   180        1.0145             nan     0.0010    0.0001
   200        1.0094             nan     0.0010    0.0001
   220        1.0047             nan     0.0010    0.0001
   240        1.0001             nan     0.0010    0.0001
   260        0.9953             nan     0.0010    0.0001
   280        0.9906             nan     0.0010    0.0001
   300        0.9860             nan     0.0010    0.0001

- Fold3.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0651             nan     0.0100    0.0006
     2        1.0638             nan     0.0100    0.0005
     3        1.0627             nan     0.0100    0.0003
     4        1.0619             nan     0.0100    0.0001
     5        1.0607             nan     0.0100    0.0004
     6        1.0593             nan     0.0100    0.0006
     7        1.0584             nan     0.0100    0.0004
     8        1.0570             nan     0.0100    0.0006
     9        1.0557             nan     0.0100    0.0006
    10        1.0545             nan     0.0100    0.0006
    20        1.0433             nan     0.0100    0.0005
    40        1.0223             nan     0.0100    0.0004
    60        1.0056             nan     0.0100    0.0002
    80        0.9902             nan     0.0100    0.0003
   100        0.9769             nan     0.0100    0.0001
   120        0.9654             nan     0.0100    0.0002
   140        0.9553             nan     0.0100    0.0001
   160        0.9444             nan     0.0100    0.0001
   180        0.9351             nan     0.0100    0.0001
   200        0.9268             nan     0.0100    0.0001
   220        0.9194             nan     0.0100    0.0001
   240        0.9125             nan     0.0100    0.0000
   260        0.9060             nan     0.0100    0.0001
   280        0.8997             nan     0.0100    0.0000
   300        0.8938             nan     0.0100    0.0001

- Fold3.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0638             nan     0.0100    0.0010
     2        1.0615             nan     0.0100    0.0010
     3        1.0590             nan     0.0100    0.0008
     4        1.0563             nan     0.0100    0.0011
     5        1.0540             nan     0.0100    0.0009
     6        1.0513             nan     0.0100    0.0009
     7        1.0491             nan     0.0100    0.0009
     8        1.0467             nan     0.0100    0.0008
     9        1.0447             nan     0.0100    0.0008
    10        1.0424             nan     0.0100    0.0009
    20        1.0212             nan     0.0100    0.0007
    40        0.9859             nan     0.0100    0.0007
    60        0.9560             nan     0.0100    0.0005
    80        0.9311             nan     0.0100    0.0004
   100        0.9094             nan     0.0100    0.0004
   120        0.8915             nan     0.0100    0.0002
   140        0.8752             nan     0.0100    0.0001
   160        0.8609             nan     0.0100    0.0000
   180        0.8479             nan     0.0100    0.0001
   200        0.8367             nan     0.0100    0.0001
   220        0.8260             nan     0.0100    0.0001
   240        0.8161             nan     0.0100    0.0002
   260        0.8068             nan     0.0100    0.0000
   280        0.7983             nan     0.0100    0.0000
   300        0.7898             nan     0.0100    0.0001

- Fold3.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0632             nan     0.0100    0.0012
     2        1.0593             nan     0.0100    0.0017
     3        1.0563             nan     0.0100    0.0011
     4        1.0531             nan     0.0100    0.0012
     5        1.0505             nan     0.0100    0.0008
     6        1.0475             nan     0.0100    0.0012
     7        1.0444             nan     0.0100    0.0011
     8        1.0414             nan     0.0100    0.0012
     9        1.0381             nan     0.0100    0.0011
    10        1.0350             nan     0.0100    0.0009
    20        1.0079             nan     0.0100    0.0008
    40        0.9637             nan     0.0100    0.0006
    60        0.9268             nan     0.0100    0.0002
    80        0.8974             nan     0.0100    0.0005
   100        0.8718             nan     0.0100    0.0002
   120        0.8497             nan     0.0100   -0.0000
   140        0.8308             nan     0.0100    0.0002
   160        0.8140             nan     0.0100    0.0001
   180        0.7991             nan     0.0100    0.0001
   200        0.7851             nan     0.0100    0.0000
   220        0.7731             nan     0.0100   -0.0001
   240        0.7610             nan     0.0100    0.0001
   260        0.7505             nan     0.0100   -0.0002
   280        0.7409             nan     0.0100   -0.0001
   300        0.7310             nan     0.0100    0.0001

- Fold3.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0532             nan     0.1000    0.0058
     2        1.0467             nan     0.1000    0.0013
     3        1.0339             nan     0.1000    0.0051
     4        1.0233             nan     0.1000    0.0048
     5        1.0157             nan     0.1000    0.0030
     6        1.0068             nan     0.1000    0.0040
     7        0.9996             nan     0.1000    0.0025
     8        0.9903             nan     0.1000    0.0039
     9        0.9824             nan     0.1000    0.0032
    10        0.9758             nan     0.1000    0.0019
    20        0.9274             nan     0.1000    0.0017
    40        0.8636             nan     0.1000    0.0002
    60        0.8289             nan     0.1000   -0.0002
    80        0.8051             nan     0.1000   -0.0015
   100        0.7875             nan     0.1000   -0.0007
   120        0.7732             nan     0.1000   -0.0002
   140        0.7601             nan     0.1000   -0.0004
   160        0.7527             nan     0.1000   -0.0006
   180        0.7450             nan     0.1000   -0.0000
   200        0.7392             nan     0.1000   -0.0006
   220        0.7319             nan     0.1000   -0.0004
   240        0.7281             nan     0.1000   -0.0006
   260        0.7217             nan     0.1000   -0.0008
   280        0.7172             nan     0.1000   -0.0006
   300        0.7146             nan     0.1000   -0.0010

- Fold3.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0366             nan     0.1000    0.0117
     2        1.0171             nan     0.1000    0.0071
     3        1.0007             nan     0.1000    0.0058
     4        0.9821             nan     0.1000    0.0048
     5        0.9684             nan     0.1000    0.0028
     6        0.9562             nan     0.1000    0.0042
     7        0.9432             nan     0.1000    0.0043
     8        0.9328             nan     0.1000    0.0011
     9        0.9208             nan     0.1000    0.0032
    10        0.9072             nan     0.1000    0.0039
    20        0.8375             nan     0.1000   -0.0001
    40        0.7574             nan     0.1000    0.0003
    60        0.7077             nan     0.1000   -0.0006
    80        0.6715             nan     0.1000   -0.0021
   100        0.6424             nan     0.1000   -0.0015
   120        0.6184             nan     0.1000   -0.0010
   140        0.5932             nan     0.1000   -0.0006
   160        0.5749             nan     0.1000   -0.0014
   180        0.5580             nan     0.1000   -0.0012
   200        0.5387             nan     0.1000   -0.0016
   220        0.5200             nan     0.1000   -0.0007
   240        0.5010             nan     0.1000   -0.0007
   260        0.4819             nan     0.1000   -0.0005
   280        0.4701             nan     0.1000   -0.0012
   300        0.4581             nan     0.1000   -0.0010

- Fold3.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold3.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 87: CrackCL6 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0370             nan     0.1000    0.0084
     2        1.0106             nan     0.1000    0.0080
     3        0.9857             nan     0.1000    0.0087
     4        0.9644             nan     0.1000    0.0065
     5        0.9437             nan     0.1000    0.0077
     6        0.9268             nan     0.1000    0.0054
     7        0.9109             nan     0.1000    0.0030
     8        0.8958             nan     0.1000    0.0043
     9        0.8830             nan     0.1000    0.0029
    10        0.8727             nan     0.1000    0.0026
    20        0.7903             nan     0.1000    0.0014
    40        0.6943             nan     0.1000    0.0003
    60        0.6278             nan     0.1000   -0.0011
    80        0.5736             nan     0.1000   -0.0008
   100        0.5315             nan     0.1000   -0.0013
   120        0.4944             nan     0.1000   -0.0008
   140        0.4603             nan     0.1000    0.0001
   160        0.4268             nan     0.1000   -0.0004
   180        0.4040             nan     0.1000   -0.0005
   200        0.3788             nan     0.1000   -0.0004
   220        0.3560             nan     0.1000   -0.0004
   240        0.3368             nan     0.1000   -0.0008
   260        0.3189             nan     0.1000   -0.0007
   280        0.3004             nan     0.1000   -0.0008
   300        0.2851             nan     0.1000   -0.0007

- Fold3.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0662             nan     0.0010    0.0001
     2        1.0660             nan     0.0010    0.0001
     3        1.0659             nan     0.0010    0.0000
     4        1.0658             nan     0.0010    0.0001
     5        1.0656             nan     0.0010    0.0001
     6        1.0655             nan     0.0010    0.0000
     7        1.0654             nan     0.0010    0.0001
     8        1.0652             nan     0.0010    0.0001
     9        1.0651             nan     0.0010    0.0001
    10        1.0650             nan     0.0010    0.0001
    20        1.0636             nan     0.0010    0.0001
    40        1.0609             nan     0.0010    0.0001
    60        1.0582             nan     0.0010    0.0001
    80        1.0556             nan     0.0010    0.0001
   100        1.0531             nan     0.0010    0.0001
   120        1.0506             nan     0.0010    0.0001
   140        1.0482             nan     0.0010    0.0000
   160        1.0460             nan     0.0010    0.0000
   180        1.0438             nan     0.0010    0.0000
   200        1.0415             nan     0.0010    0.0001
   220        1.0392             nan     0.0010    0.0001
   240        1.0370             nan     0.0010    0.0000
   260        1.0350             nan     0.0010    0.0000
   280        1.0329             nan     0.0010    0.0000
   300        1.0308             nan     0.0010    0.0000

- Fold4.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0661             nan     0.0010    0.0001
     2        1.0658             nan     0.0010    0.0001
     3        1.0655             nan     0.0010    0.0001
     4        1.0653             nan     0.0010    0.0001
     5        1.0650             nan     0.0010    0.0001
     6        1.0648             nan     0.0010    0.0001
     7        1.0645             nan     0.0010    0.0001
     8        1.0643             nan     0.0010    0.0001
     9        1.0640             nan     0.0010    0.0001
    10        1.0637             nan     0.0010    0.0001
    20        1.0612             nan     0.0010    0.0002
    40        1.0561             nan     0.0010    0.0001
    60        1.0511             nan     0.0010    0.0001
    80        1.0466             nan     0.0010    0.0001
   100        1.0418             nan     0.0010    0.0001
   120        1.0372             nan     0.0010    0.0001
   140        1.0329             nan     0.0010    0.0001
   160        1.0287             nan     0.0010    0.0001
   180        1.0245             nan     0.0010    0.0001
   200        1.0203             nan     0.0010    0.0000
   220        1.0163             nan     0.0010    0.0001
   240        1.0126             nan     0.0010    0.0000
   260        1.0086             nan     0.0010    0.0001
   280        1.0049             nan     0.0010    0.0001
   300        1.0013             nan     0.0010    0.0001

- Fold4.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0660             nan     0.0010    0.0001
     2        1.0657             nan     0.0010    0.0001
     3        1.0653             nan     0.0010    0.0002
     4        1.0650             nan     0.0010    0.0001
     5        1.0646             nan     0.0010    0.0001
     6        1.0643             nan     0.0010    0.0001
     7        1.0639             nan     0.0010    0.0002
     8        1.0636             nan     0.0010    0.0001
     9        1.0633             nan     0.0010    0.0001
    10        1.0629             nan     0.0010    0.0002
    20        1.0593             nan     0.0010    0.0002
    40        1.0528             nan     0.0010    0.0001
    60        1.0467             nan     0.0010    0.0001
    80        1.0406             nan     0.0010    0.0001
   100        1.0346             nan     0.0010    0.0001
   120        1.0289             nan     0.0010    0.0001
   140        1.0231             nan     0.0010    0.0001
   160        1.0175             nan     0.0010    0.0001
   180        1.0123             nan     0.0010    0.0001
   200        1.0071             nan     0.0010    0.0001
   220        1.0023             nan     0.0010    0.0001
   240        0.9976             nan     0.0010    0.0000
   260        0.9930             nan     0.0010    0.0001
   280        0.9883             nan     0.0010    0.0001
   300        0.9840             nan     0.0010    0.0000

- Fold4.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0648             nan     0.0100    0.0007
     2        1.0636             nan     0.0100    0.0006
     3        1.0626             nan     0.0100    0.0004
     4        1.0609             nan     0.0100    0.0007
     5        1.0597             nan     0.0100    0.0005
     6        1.0583             nan     0.0100    0.0007
     7        1.0569             nan     0.0100    0.0005
     8        1.0557             nan     0.0100    0.0005
     9        1.0540             nan     0.0100    0.0005
    10        1.0531             nan     0.0100    0.0004
    20        1.0420             nan     0.0100    0.0002
    40        1.0214             nan     0.0100    0.0005
    60        1.0035             nan     0.0100    0.0003
    80        0.9875             nan     0.0100    0.0003
   100        0.9736             nan     0.0100    0.0001
   120        0.9623             nan     0.0100    0.0002
   140        0.9523             nan     0.0100    0.0002
   160        0.9436             nan     0.0100    0.0001
   180        0.9348             nan     0.0100    0.0002
   200        0.9266             nan     0.0100    0.0001
   220        0.9194             nan     0.0100   -0.0000
   240        0.9120             nan     0.0100    0.0000
   260        0.9050             nan     0.0100    0.0001
   280        0.8987             nan     0.0100    0.0001
   300        0.8929             nan     0.0100   -0.0001

- Fold4.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0643             nan     0.0100    0.0005
     2        1.0613             nan     0.0100    0.0011
     3        1.0582             nan     0.0100    0.0013
     4        1.0563             nan     0.0100    0.0007
     5        1.0534             nan     0.0100    0.0012
     6        1.0512             nan     0.0100    0.0008
     7        1.0489             nan     0.0100    0.0008
     8        1.0463             nan     0.0100    0.0011
     9        1.0438             nan     0.0100    0.0010
    10        1.0414             nan     0.0100    0.0009
    20        1.0208             nan     0.0100    0.0008
    40        0.9852             nan     0.0100    0.0006
    60        0.9567             nan     0.0100    0.0004
    80        0.9321             nan     0.0100    0.0003
   100        0.9113             nan     0.0100    0.0003
   120        0.8927             nan     0.0100    0.0002
   140        0.8767             nan     0.0100    0.0002
   160        0.8623             nan     0.0100    0.0002
   180        0.8492             nan     0.0100    0.0000
   200        0.8371             nan     0.0100    0.0001
   220        0.8261             nan     0.0100   -0.0000
   240        0.8164             nan     0.0100   -0.0001
   260        0.8068             nan     0.0100    0.0001
   280        0.7980             nan     0.0100   -0.0000
   300        0.7895             nan     0.0100    0.0000

- Fold4.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0631             nan     0.0100    0.0012
     2        1.0597             nan     0.0100    0.0011
     3        1.0562             nan     0.0100    0.0012
     4        1.0529             nan     0.0100    0.0014
     5        1.0503             nan     0.0100    0.0010
     6        1.0471             nan     0.0100    0.0013
     7        1.0440             nan     0.0100    0.0011
     8        1.0408             nan     0.0100    0.0013
     9        1.0382             nan     0.0100    0.0011
    10        1.0353             nan     0.0100    0.0012
    20        1.0070             nan     0.0100    0.0010
    40        0.9620             nan     0.0100    0.0007
    60        0.9284             nan     0.0100    0.0004
    80        0.8980             nan     0.0100    0.0001
   100        0.8715             nan     0.0100    0.0003
   120        0.8495             nan     0.0100    0.0004
   140        0.8307             nan     0.0100    0.0001
   160        0.8140             nan     0.0100    0.0000
   180        0.7990             nan     0.0100    0.0001
   200        0.7849             nan     0.0100   -0.0001
   220        0.7717             nan     0.0100   -0.0000
   240        0.7593             nan     0.0100    0.0000
   260        0.7485             nan     0.0100    0.0001
   280        0.7378             nan     0.0100    0.0000
   300        0.7279             nan     0.0100    0.0000

- Fold4.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0520             nan     0.1000    0.0068
     2        1.0463             nan     0.1000   -0.0002
     3        1.0392             nan     0.1000    0.0022
     4        1.0274             nan     0.1000    0.0053
     5        1.0180             nan     0.1000    0.0045
     6        1.0096             nan     0.1000    0.0035
     7        1.0017             nan     0.1000    0.0035
     8        0.9924             nan     0.1000    0.0041
     9        0.9853             nan     0.1000    0.0032
    10        0.9795             nan     0.1000    0.0023
    20        0.9231             nan     0.1000    0.0017
    40        0.8649             nan     0.1000    0.0001
    60        0.8312             nan     0.1000   -0.0002
    80        0.8095             nan     0.1000   -0.0005
   100        0.7883             nan     0.1000   -0.0001
   120        0.7747             nan     0.1000   -0.0001
   140        0.7617             nan     0.1000   -0.0007
   160        0.7510             nan     0.1000   -0.0003
   180        0.7427             nan     0.1000   -0.0008
   200        0.7337             nan     0.1000   -0.0005
   220        0.7280             nan     0.1000   -0.0007
   240        0.7220             nan     0.1000   -0.0003
   260        0.7169             nan     0.1000   -0.0005
   280        0.7126             nan     0.1000   -0.0004
   300        0.7092             nan     0.1000   -0.0009

- Fold4.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0434             nan     0.1000    0.0111
     2        1.0197             nan     0.1000    0.0104
     3        0.9975             nan     0.1000    0.0091
     4        0.9807             nan     0.1000    0.0054
     5        0.9660             nan     0.1000    0.0052
     6        0.9521             nan     0.1000    0.0039
     7        0.9391             nan     0.1000    0.0036
     8        0.9284             nan     0.1000    0.0032
     9        0.9172             nan     0.1000    0.0027
    10        0.9072             nan     0.1000    0.0030
    20        0.8400             nan     0.1000   -0.0008
    40        0.7583             nan     0.1000   -0.0001
    60        0.7097             nan     0.1000   -0.0011
    80        0.6755             nan     0.1000   -0.0004
   100        0.6466             nan     0.1000   -0.0008
   120        0.6213             nan     0.1000   -0.0012
   140        0.5976             nan     0.1000   -0.0007
   160        0.5768             nan     0.1000   -0.0009
   180        0.5589             nan     0.1000   -0.0014
   200        0.5351             nan     0.1000   -0.0017
   220        0.5185             nan     0.1000   -0.0016
   240        0.4990             nan     0.1000   -0.0012
   260        0.4819             nan     0.1000   -0.0006
   280        0.4664             nan     0.1000   -0.0007
   300        0.4539             nan     0.1000   -0.0007

- Fold4.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold4.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = &#34;bernoulli&#34;, :
&#34;variable 139: SemerCL4 has no variation.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0338             nan     0.1000    0.0130
     2        1.0043             nan     0.1000    0.0126
     3        0.9742             nan     0.1000    0.0110
     4        0.9546             nan     0.1000    0.0075
     5        0.9367             nan     0.1000    0.0075
     6        0.9186             nan     0.1000    0.0049
     7        0.9035             nan     0.1000    0.0024
     8        0.8902             nan     0.1000    0.0038
     9        0.8803             nan     0.1000   -0.0001
    10        0.8674             nan     0.1000    0.0042
    20        0.7877             nan     0.1000    0.0023
    40        0.6909             nan     0.1000   -0.0013
    60        0.6315             nan     0.1000   -0.0006
    80        0.5837             nan     0.1000   -0.0011
   100        0.5400             nan     0.1000   -0.0013
   120        0.5035             nan     0.1000   -0.0012
   140        0.4717             nan     0.1000   -0.0019
   160        0.4414             nan     0.1000   -0.0007
   180        0.4152             nan     0.1000   -0.0005
   200        0.3906             nan     0.1000   -0.0004
   220        0.3695             nan     0.1000   -0.0012
   240        0.3491             nan     0.1000   -0.0013
   260        0.3273             nan     0.1000   -0.0003
   280        0.3100             nan     0.1000   -0.0009
   300        0.2904             nan     0.1000   -0.0008

- Fold4.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0678             nan     0.0010    0.0000
     2        1.0677             nan     0.0010    0.0001
     3        1.0676             nan     0.0010    0.0000
     4        1.0675             nan     0.0010    0.0001
     5        1.0674             nan     0.0010    0.0000
     6        1.0673             nan     0.0010    0.0000
     7        1.0671             nan     0.0010    0.0001
     8        1.0670             nan     0.0010    0.0001
     9        1.0670             nan     0.0010    0.0000
    10        1.0668             nan     0.0010    0.0001
    20        1.0655             nan     0.0010    0.0001
    40        1.0631             nan     0.0010    0.0001
    60        1.0606             nan     0.0010    0.0001
    80        1.0583             nan     0.0010    0.0000
   100        1.0561             nan     0.0010    0.0000
   120        1.0538             nan     0.0010    0.0001
   140        1.0516             nan     0.0010    0.0000
   160        1.0495             nan     0.0010    0.0000
   180        1.0473             nan     0.0010    0.0000
   200        1.0453             nan     0.0010    0.0000
   220        1.0433             nan     0.0010    0.0000
   240        1.0413             nan     0.0010    0.0000
   260        1.0394             nan     0.0010    0.0000
   280        1.0374             nan     0.0010    0.0000
   300        1.0355             nan     0.0010    0.0000

- Fold5.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0677             nan     0.0010    0.0001
     2        1.0674             nan     0.0010    0.0001
     3        1.0672             nan     0.0010    0.0001
     4        1.0670             nan     0.0010    0.0001
     5        1.0668             nan     0.0010    0.0001
     6        1.0665             nan     0.0010    0.0001
     7        1.0663             nan     0.0010    0.0001
     8        1.0660             nan     0.0010    0.0001
     9        1.0658             nan     0.0010    0.0001
    10        1.0656             nan     0.0010    0.0001
    20        1.0632             nan     0.0010    0.0001
    40        1.0585             nan     0.0010    0.0001
    60        1.0539             nan     0.0010    0.0001
    80        1.0495             nan     0.0010    0.0001
   100        1.0451             nan     0.0010    0.0000
   120        1.0407             nan     0.0010    0.0001
   140        1.0368             nan     0.0010    0.0001
   160        1.0328             nan     0.0010    0.0001
   180        1.0289             nan     0.0010    0.0001
   200        1.0253             nan     0.0010    0.0001
   220        1.0216             nan     0.0010    0.0000
   240        1.0180             nan     0.0010    0.0001
   260        1.0145             nan     0.0010    0.0001
   280        1.0112             nan     0.0010    0.0001
   300        1.0076             nan     0.0010    0.0001

- Fold5.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0677             nan     0.0010    0.0001
     2        1.0673             nan     0.0010    0.0001
     3        1.0670             nan     0.0010    0.0001
     4        1.0667             nan     0.0010    0.0001
     5        1.0664             nan     0.0010    0.0001
     6        1.0660             nan     0.0010    0.0001
     7        1.0658             nan     0.0010    0.0001
     8        1.0655             nan     0.0010    0.0001
     9        1.0652             nan     0.0010    0.0001
    10        1.0650             nan     0.0010    0.0001
    20        1.0619             nan     0.0010    0.0001
    40        1.0557             nan     0.0010    0.0001
    60        1.0500             nan     0.0010    0.0001
    80        1.0444             nan     0.0010    0.0001
   100        1.0388             nan     0.0010    0.0001
   120        1.0334             nan     0.0010    0.0001
   140        1.0284             nan     0.0010    0.0001
   160        1.0234             nan     0.0010    0.0001
   180        1.0185             nan     0.0010    0.0001
   200        1.0138             nan     0.0010    0.0001
   220        1.0092             nan     0.0010    0.0000
   240        1.0046             nan     0.0010    0.0001
   260        1.0001             nan     0.0010    0.0001
   280        0.9957             nan     0.0010    0.0001
   300        0.9915             nan     0.0010    0.0000

- Fold5.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0666             nan     0.0100    0.0005
     2        1.0653             nan     0.0100    0.0005
     3        1.0644             nan     0.0100    0.0004
     4        1.0633             nan     0.0100    0.0005
     5        1.0621             nan     0.0100    0.0005
     6        1.0610             nan     0.0100    0.0004
     7        1.0597             nan     0.0100    0.0006
     8        1.0585             nan     0.0100    0.0006
     9        1.0573             nan     0.0100    0.0005
    10        1.0565             nan     0.0100    0.0003
    20        1.0459             nan     0.0100    0.0004
    40        1.0285             nan     0.0100    0.0002
    60        1.0124             nan     0.0100    0.0004
    80        0.9976             nan     0.0100    0.0001
   100        0.9851             nan     0.0100    0.0001
   120        0.9745             nan     0.0100    0.0002
   140        0.9645             nan     0.0100    0.0001
   160        0.9555             nan     0.0100    0.0002
   180        0.9473             nan     0.0100    0.0001
   200        0.9397             nan     0.0100    0.0001
   220        0.9329             nan     0.0100    0.0001
   240        0.9270             nan     0.0100   -0.0000
   260        0.9209             nan     0.0100    0.0001
   280        0.9151             nan     0.0100    0.0000
   300        0.9095             nan     0.0100    0.0001

- Fold5.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0655             nan     0.0100    0.0011
     2        1.0635             nan     0.0100    0.0009
     3        1.0610             nan     0.0100    0.0012
     4        1.0585             nan     0.0100    0.0010
     5        1.0566             nan     0.0100    0.0007
     6        1.0547             nan     0.0100    0.0007
     7        1.0524             nan     0.0100    0.0007
     8        1.0503             nan     0.0100    0.0008
     9        1.0480             nan     0.0100    0.0007
    10        1.0459             nan     0.0100    0.0007
    20        1.0264             nan     0.0100    0.0005
    40        0.9933             nan     0.0100    0.0004
    60        0.9656             nan     0.0100    0.0005
    80        0.9420             nan     0.0100    0.0005
   100        0.9223             nan     0.0100    0.0002
   120        0.9048             nan     0.0100    0.0001
   140        0.8888             nan     0.0100    0.0002
   160        0.8754             nan     0.0100    0.0002
   180        0.8627             nan     0.0100    0.0001
   200        0.8517             nan     0.0100   -0.0000
   220        0.8414             nan     0.0100   -0.0001
   240        0.8323             nan     0.0100   -0.0000
   260        0.8233             nan     0.0100    0.0000
   280        0.8154             nan     0.0100   -0.0000
   300        0.8075             nan     0.0100   -0.0001

- Fold5.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0647             nan     0.0100    0.0012
     2        1.0619             nan     0.0100    0.0013
     3        1.0592             nan     0.0100    0.0010
     4        1.0560             nan     0.0100    0.0010
     5        1.0529             nan     0.0100    0.0013
     6        1.0497             nan     0.0100    0.0011
     7        1.0470             nan     0.0100    0.0010
     8        1.0443             nan     0.0100    0.0009
     9        1.0411             nan     0.0100    0.0012
    10        1.0384             nan     0.0100    0.0008
    20        1.0141             nan     0.0100    0.0009
    40        0.9715             nan     0.0100    0.0006
    60        0.9364             nan     0.0100    0.0005
    80        0.9082             nan     0.0100    0.0004
   100        0.8836             nan     0.0100    0.0003
   120        0.8630             nan     0.0100    0.0001
   140        0.8446             nan     0.0100    0.0001
   160        0.8284             nan     0.0100    0.0000
   180        0.8145             nan     0.0100    0.0000
   200        0.8018             nan     0.0100   -0.0001
   220        0.7904             nan     0.0100   -0.0000
   240        0.7788             nan     0.0100    0.0001
   260        0.7688             nan     0.0100    0.0000
   280        0.7587             nan     0.0100   -0.0000
   300        0.7498             nan     0.0100   -0.0001

- Fold5.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0560             nan     0.1000    0.0054
     2        1.0477             nan     0.1000    0.0031
     3        1.0369             nan     0.1000    0.0056
     4        1.0270             nan     0.1000    0.0036
     5        1.0164             nan     0.1000    0.0030
     6        1.0103             nan     0.1000    0.0023
     7        1.0031             nan     0.1000    0.0019
     8        0.9949             nan     0.1000    0.0039
     9        0.9888             nan     0.1000    0.0027
    10        0.9842             nan     0.1000    0.0004
    20        0.9452             nan     0.1000    0.0012
    40        0.8884             nan     0.1000    0.0000
    60        0.8534             nan     0.1000   -0.0003
    80        0.8288             nan     0.1000   -0.0007
   100        0.8134             nan     0.1000   -0.0001
   120        0.8006             nan     0.1000   -0.0008
   140        0.7881             nan     0.1000   -0.0003
   160        0.7798             nan     0.1000   -0.0006
   180        0.7734             nan     0.1000   -0.0011
   200        0.7663             nan     0.1000   -0.0001
   220        0.7610             nan     0.1000   -0.0002
   240        0.7575             nan     0.1000   -0.0005
   260        0.7528             nan     0.1000   -0.0011
   280        0.7503             nan     0.1000   -0.0011
   300        0.7471             nan     0.1000   -0.0013

- Fold5.Rep1: shrinkage=0.100, interaction.depth=1, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0460             nan     0.1000    0.0087
     2        1.0279             nan     0.1000    0.0084
     3        1.0102             nan     0.1000    0.0040
     4        0.9941             nan     0.1000    0.0050
     5        0.9840             nan     0.1000    0.0016
     6        0.9704             nan     0.1000    0.0049
     7        0.9551             nan     0.1000    0.0069
     8        0.9428             nan     0.1000    0.0038
     9        0.9310             nan     0.1000    0.0034
    10        0.9206             nan     0.1000    0.0030
    20        0.8538             nan     0.1000    0.0002
    40        0.7814             nan     0.1000   -0.0005
    60        0.7354             nan     0.1000   -0.0005
    80        0.6978             nan     0.1000   -0.0006
   100        0.6660             nan     0.1000   -0.0008
   120        0.6406             nan     0.1000   -0.0010
   140        0.6234             nan     0.1000   -0.0018
   160        0.6011             nan     0.1000   -0.0004
   180        0.5760             nan     0.1000   -0.0012
   200        0.5563             nan     0.1000   -0.0016
   220        0.5348             nan     0.1000   -0.0016
   240        0.5189             nan     0.1000   -0.0001
   260        0.5014             nan     0.1000   -0.0006
   280        0.4856             nan     0.1000   -0.0009
   300        0.4713             nan     0.1000   -0.0018

- Fold5.Rep1: shrinkage=0.100, interaction.depth=3, n.minobsinnode=10, n.trees=300 
+ Fold5.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0418             nan     0.1000    0.0071
     2        1.0180             nan     0.1000    0.0054
     3        0.9931             nan     0.1000    0.0092
     4        0.9758             nan     0.1000    0.0065
     5        0.9570             nan     0.1000    0.0057
     6        0.9384             nan     0.1000    0.0054
     7        0.9281             nan     0.1000    0.0028
     8        0.9150             nan     0.1000    0.0033
     9        0.8999             nan     0.1000    0.0037
    10        0.8878             nan     0.1000    0.0031
    20        0.8021             nan     0.1000   -0.0023
    40        0.7130             nan     0.1000   -0.0012
    60        0.6514             nan     0.1000   -0.0009
    80        0.6037             nan     0.1000   -0.0016
   100        0.5658             nan     0.1000   -0.0017
   120        0.5287             nan     0.1000   -0.0016
   140        0.4893             nan     0.1000   -0.0012
   160        0.4609             nan     0.1000   -0.0003
   180        0.4359             nan     0.1000   -0.0012
   200        0.4129             nan     0.1000   -0.0007
   220        0.3856             nan     0.1000   -0.0005
   240        0.3645             nan     0.1000   -0.0008
   260        0.3425             nan     0.1000   -0.0010
   280        0.3237             nan     0.1000   -0.0004
   300        0.3088             nan     0.1000   -0.0012

- Fold5.Rep1: shrinkage=0.100, interaction.depth=5, n.minobsinnode=10, n.trees=300 
Aggregating results
Selecting tuning parameters
Fitting n.trees = 100, interaction.depth = 1, shrinkage = 0.1, n.minobsinnode = 10 on full training set
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0554             nan     0.1000    0.0059
     2        1.0457             nan     0.1000    0.0047
     3        1.0371             nan     0.1000    0.0030
     4        1.0299             nan     0.1000    0.0025
     5        1.0210             nan     0.1000    0.0036
     6        1.0130             nan     0.1000    0.0033
     7        1.0055             nan     0.1000    0.0041
     8        0.9978             nan     0.1000    0.0038
     9        0.9910             nan     0.1000    0.0032
    10        0.9850             nan     0.1000    0.0023
    20        0.9424             nan     0.1000    0.0006
    40        0.8903             nan     0.1000   -0.0010
    60        0.8575             nan     0.1000    0.0003
    80        0.8340             nan     0.1000   -0.0000
   100        0.8189             nan     0.1000   -0.0006

</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = VSAneverused, case = VSAused
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[393]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">AUC_Value</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">lasso_error3</span><span class="p">,</span> <span class="n">dt_error3.1</span><span class="p">,</span> <span class="n">dt_error3.2</span><span class="p">,</span> <span class="n">dt_error3.3</span><span class="p">,</span> <span class="n">rf_error3</span><span class="p">,</span> <span class="n">sgb_error3</span><span class="p">)</span>

<span class="n">table3</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span><span class="n">AUC_Value</span><span class="p">)</span>
<span class="n">table3</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>Model</th><th scope=col>AUC_Value</th></tr></thead>
<tbody>
	<tr><td>Lasso Reg        </td><td>0.7813627        </td></tr>
	<tr><td>Decision Tree 1  </td><td>0.6637140        </td></tr>
	<tr><td>Decision Tree 2  </td><td>0.6646966        </td></tr>
	<tr><td>Decision Tree 3  </td><td>0.6608981        </td></tr>
	<tr><td>Random Forest    </td><td>0.8004869        </td></tr>
	<tr><td>Gradient Boosting</td><td>0.7801455        </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>According to AUC value, random forest model is the best option</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Data-Set:-Sports-articles-for-objectivity">Data Set: Sports articles for objectivity<a class="anchor-link" href="#Data-Set:-Sports-articles-for-objectivity">&#182;</a></h3>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[110]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data4</span><span class="o">=</span><span class="nf">read_excel</span><span class="p">(</span><span class="s">&quot;DataSet4/objectivity.xlsx&quot;</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">data4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>TextID</th><th scope=col>URL</th><th scope=col>Label</th><th scope=col>totalWordsCount</th><th scope=col>semanticobjscore</th><th scope=col>semanticsubjscore</th><th scope=col>CC</th><th scope=col>CD</th><th scope=col>DT</th><th scope=col>EX</th><th scope=col>...</th><th scope=col>pronouns2nd</th><th scope=col>pronouns3rd</th><th scope=col>compsupadjadv</th><th scope=col>past</th><th scope=col>imperative</th><th scope=col>present3rd</th><th scope=col>present1st2nd</th><th scope=col>sentence1st</th><th scope=col>sentencelast</th><th scope=col>txtcomplexity</th></tr></thead>
<tbody>
	<tr><td>Text0001                                                                                                                                </td><td>http://msn.foxsports.com/foxsoccer/mexico/story/mexican-review-jan-19-toluca-secures-first-victory-beats-leon-011913                    </td><td>objective                                                                                                                               </td><td>109                                                                                                                                     </td><td> 0                                                                                                                                      </td><td>1                                                                                                                                       </td><td> 7                                                                                                                                      </td><td> 9                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 5                                                                                                                                      </td><td>...                                                                                                                                     </td><td>0                                                                                                                                       </td><td> 3                                                                                                                                      </td><td>0                                                                                                                                       </td><td>11                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 0                                                                                                                                      </td><td>0                                                                                                                                       </td><td>0                                                                                                                                       </td><td>1                                                                                                                                       </td><td>18                                                                                                                                      </td></tr>
	<tr><td>Text0002                                                                                                                                </td><td>http://msn.foxsports.com/foxsoccer/premierleague/story/manchester-city-chief-david-platt-plays-down-mario-balotelli-ac-milan-link-012813</td><td>objective                                                                                                                               </td><td>309                                                                                                                                     </td><td>21                                                                                                                                      </td><td>4                                                                                                                                       </td><td> 1                                                                                                                                      </td><td>19                                                                                                                                      </td><td>1                                                                                                                                       </td><td> 4                                                                                                                                      </td><td>...                                                                                                                                     </td><td>0                                                                                                                                       </td><td>10                                                                                                                                      </td><td>0                                                                                                                                       </td><td>13                                                                                                                                      </td><td>0                                                                                                                                       </td><td>14                                                                                                                                      </td><td>9                                                                                                                                       </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>14                                                                                                                                      </td></tr>
	<tr><td>Text0003                                                                                                                                </td><td>http://uk.eurosport.yahoo.com/04022011/58/fed-cup-britain-shade-danes-dramatic-win.html                                                 </td><td>objective                                                                                                                               </td><td>149                                                                                                                                     </td><td> 6                                                                                                                                      </td><td>1                                                                                                                                       </td><td> 8                                                                                                                                      </td><td>14                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 5                                                                                                                                      </td><td>...                                                                                                                                     </td><td>0                                                                                                                                       </td><td> 2                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 8                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 3                                                                                                                                      </td><td>2                                                                                                                                       </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>18                                                                                                                                      </td></tr>
	<tr><td>Text0004                                                                                                                                </td><td>http://uk.eurosport.yahoo.com/07022011/58/bundesliga-wolfsburg-sack-mcclaren.html                                                       </td><td>objective                                                                                                                               </td><td>305                                                                                                                                     </td><td>18                                                                                                                                      </td><td>5                                                                                                                                       </td><td> 7                                                                                                                                      </td><td>26                                                                                                                                      </td><td>0                                                                                                                                       </td><td>10                                                                                                                                      </td><td>...                                                                                                                                     </td><td>0                                                                                                                                       </td><td> 8                                                                                                                                      </td><td>3                                                                                                                                       </td><td>13                                                                                                                                      </td><td>1                                                                                                                                       </td><td> 7                                                                                                                                      </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>20                                                                                                                                      </td></tr>
	<tr><td>Text0005                                                                                                                                </td><td>http://uk.eurosport.yahoo.com/05022011/58/fed-cup-groth-stuns-schiavone-hobart.html                                                     </td><td>objective                                                                                                                               </td><td>491                                                                                                                                     </td><td>23                                                                                                                                      </td><td>8                                                                                                                                       </td><td>33                                                                                                                                      </td><td>47                                                                                                                                      </td><td>0                                                                                                                                       </td><td>12                                                                                                                                      </td><td>...                                                                                                                                     </td><td>0                                                                                                                                       </td><td>16                                                                                                                                      </td><td>2                                                                                                                                       </td><td>34                                                                                                                                      </td><td>1                                                                                                                                       </td><td> 5                                                                                                                                      </td><td>6                                                                                                                                       </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>24                                                                                                                                      </td></tr>
	<tr><td>Text0006                                                                                                                                </td><td>http://msn.foxsports.com/nba/story/julius-erving-nba-star-accused-of-cheating-woman-out-of-420k-020511                                  </td><td>objective                                                                                                                               </td><td>314                                                                                                                                     </td><td>14                                                                                                                                      </td><td>1                                                                                                                                       </td><td>17                                                                                                                                      </td><td>17                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 0                                                                                                                                      </td><td>...                                                                                                                                     </td><td>0                                                                                                                                       </td><td>16                                                                                                                                      </td><td>3                                                                                                                                       </td><td>24                                                                                                                                      </td><td>0                                                                                                                                       </td><td> 5                                                                                                                                      </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>1                                                                                                                                       </td><td>18                                                                                                                                      </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[111]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data4</span><span class="o">$</span><span class="n">TextID</span> <span class="o">&lt;-</span> <span class="kc">NULL</span>
<span class="n">data4</span><span class="o">$</span><span class="n">URL</span> <span class="o">&lt;-</span> <span class="kc">NULL</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[112]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">str</span><span class="p">(</span><span class="n">data4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:	1000 obs. of  60 variables:
 $ Label            : chr  &#34;objective&#34; &#34;objective&#34; &#34;objective&#34; &#34;objective&#34; ...
 $ totalWordsCount  : num  109 309 149 305 491 314 314 462 808 860 ...
 $ semanticobjscore : num  0 21 6 18 23 14 10 19 40 44 ...
 $ semanticsubjscore: num  1 4 1 5 8 1 6 6 11 22 ...
 $ CC               : num  7 1 8 7 33 17 1 5 49 13 ...
 $ CD               : num  9 19 14 26 47 17 37 47 71 111 ...
 $ DT               : num  0 1 0 0 0 0 1 0 1 0 ...
 $ EX               : num  5 4 5 10 12 0 10 0 6 4 ...
 $ FW               : num  8 35 15 37 61 36 33 40 94 101 ...
 $ INs              : num  6 23 11 21 36 15 20 39 44 56 ...
 $ JJ               : num  0 0 0 1 0 2 0 0 2 3 ...
 $ JJR              : num  0 0 0 1 1 1 0 1 1 2 ...
 $ JJS              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ LS               : num  0 2 0 0 2 0 0 9 0 2 ...
 $ MD               : num  29 93 47 83 142 88 112 101 162 196 ...
 $ NN               : num  0 1 1 2 1 1 3 1 7 2 ...
 $ NNP              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ NNPS             : num  12 17 4 18 15 20 19 31 56 58 ...
 $ NNS              : num  0 0 0 0 0 1 0 0 0 0 ...
 $ PDT              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ POS              : num  1 7 4 6 7 10 4 20 23 15 ...
 $ PRP              : num  2 5 0 2 9 6 2 7 10 15 ...
 $ PRP$             : num  2 16 7 9 10 8 3 16 34 35 ...
 $ RB               : num  0 0 0 1 1 0 0 0 0 4 ...
 $ RBR              : num  0 0 0 0 0 0 0 0 0 1 ...
 $ RBS              : num  2 0 1 1 1 1 0 1 10 11 ...
 $ RP               : num  0 1 0 2 0 0 0 3 8 0 ...
 $ SYM              : num  3 3 4 9 13 4 3 11 20 28 ...
 $ TOs              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ UH               : num  0 0 0 1 1 0 0 3 3 3 ...
 $ VB               : num  11 13 8 13 34 24 13 21 59 73 ...
 $ VBD              : num  0 7 2 12 5 13 5 16 23 17 ...
 $ VBG              : num  2 13 2 6 6 2 7 8 7 9 ...
 $ VBN              : num  0 9 2 1 6 1 3 10 4 6 ...
 $ VBP              : num  0 14 3 7 5 5 1 16 12 8 ...
 $ VBZ              : num  0 0 0 1 0 3 2 1 2 1 ...
 $ WDT              : num  1 0 0 1 3 3 2 2 6 5 ...
 $ WP               : num  0 0 0 0 0 0 0 0 0 2 ...
 $ WP$              : num  1 3 2 1 1 0 0 3 7 1 ...
 $ WRB              : num  0 0 0 0 0 0 0 0 0 0 ...
 $ baseform         : num  2 8 4 5 7 11 4 16 23 30 ...
 $ Quotes           : num  0 7 0 3 4 6 2 9 10 0 ...
 $ questionmarks    : num  0 0 0 0 0 1 0 0 0 0 ...
 $ exclamationmarks : num  0 0 0 0 0 0 0 0 0 0 ...
 $ fullstops        : num  4 19 6 13 18 14 8 24 45 33 ...
 $ commas           : num  2 3 3 17 17 16 8 17 43 28 ...
 $ semicolon        : num  0 0 0 0 0 0 0 0 0 0 ...
 $ colon            : num  0 5 0 0 0 0 8 0 0 0 ...
 $ ellipsis         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ pronouns1st      : num  0 1 0 0 0 0 3 2 1 0 ...
 $ pronouns2nd      : num  0 0 0 0 0 0 0 2 2 0 ...
 $ pronouns3rd      : num  3 10 2 8 16 16 3 13 18 25 ...
 $ compsupadjadv    : num  0 0 0 3 2 3 0 1 3 10 ...
 $ past             : num  11 13 8 13 34 24 13 21 59 73 ...
 $ imperative       : num  0 0 0 1 1 0 0 3 3 3 ...
 $ present3rd       : num  0 14 3 7 5 5 1 16 12 8 ...
 $ present1st2nd    : num  0 9 2 1 6 1 3 10 4 6 ...
 $ sentence1st      : num  0 1 1 1 1 1 1 1 1 1 ...
 $ sentencelast     : num  1 1 1 1 1 1 1 1 1 1 ...
 $ txtcomplexity    : num  18 14 18 20 24 18 31 17 17 24 ...
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[386]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">data4</span><span class="p">[</span><span class="s">&quot;Label&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="nf">lapply</span><span class="p">(</span><span class="n">data4</span><span class="p">[</span><span class="s">&quot;Label&quot;</span><span class="p">]</span> <span class="p">,</span> <span class="n">factor</span><span class="p">)</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">data4</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">make.names</span><span class="p">(</span><span class="nf">colnames</span><span class="p">(</span><span class="n">data4</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[126]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="c1">## &quot;These variables have zero variances: NNP, WRB, ellipsis&quot; </span>

<span class="n">data4</span><span class="o">$</span><span class="n">NNP</span> <span class="o">&lt;-</span> <span class="kc">NULL</span>
<span class="n">data4</span><span class="o">$</span><span class="n">WRB</span> <span class="o">&lt;-</span> <span class="kc">NULL</span>
<span class="n">data4</span><span class="o">$</span><span class="n">ellipsis</span> <span class="o">&lt;-</span> <span class="kc">NULL</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[128]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data4</span><span class="p">),</span> <span class="n">size</span> <span class="o">=</span> <span class="nf">floor</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">data4</span><span class="p">)</span><span class="o">*</span><span class="m">0.77</span><span class="p">),</span> <span class="n">replace</span> <span class="o">=</span> <span class="bp">F</span><span class="p">)</span>
<span class="n">train4</span> <span class="o">&lt;-</span> <span class="n">data4</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
<span class="n">test4</span>  <span class="o">&lt;-</span> <span class="n">data4</span><span class="p">[</span><span class="o">-</span><span class="n">sample</span><span class="p">,</span> <span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[116]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">fold4</span> <span class="o">&lt;-</span> <span class="nf">createMultiFolds</span><span class="p">(</span><span class="n">train4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="m">10</span><span class="p">,</span><span class="n">times</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>

<span class="n">control4</span><span class="o">&lt;-</span><span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;cv&quot;</span><span class="p">,</span><span class="n">verboseIter</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">summaryFunction</span><span class="o">=</span><span class="n">twoClassSummary</span><span class="p">,</span>
                              <span class="n">classProbs</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">savePredictions</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">fold4</span><span class="p">,</span><span class="n">allowParallel</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[146]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">lasso_grid4</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">lambda</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.1</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="m">5</span><span class="p">)))</span>
<span class="n">reg4</span><span class="o">&lt;-</span><span class="nf">train</span><span class="p">(</span><span class="n">Label</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">train4</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;glmnet&quot;</span><span class="p">,</span><span class="n">tuneGrid</span><span class="o">=</span><span class="n">lasso_grid4</span><span class="p">,</span>
               <span class="n">trControl</span><span class="o">=</span><span class="n">control4</span><span class="p">,</span><span class="n">preProcess</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span><span class="s">&quot;scale&quot;</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in train.default(x, y, weights = w, ...):
&#34;The metric &#34;Accuracy&#34; was not in the result set. ROC will be used instead.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: alpha=1, lambda=0.1 
- Fold01.Rep1: alpha=1, lambda=0.1 
+ Fold02.Rep1: alpha=1, lambda=0.1 
- Fold02.Rep1: alpha=1, lambda=0.1 
+ Fold03.Rep1: alpha=1, lambda=0.1 
- Fold03.Rep1: alpha=1, lambda=0.1 
+ Fold04.Rep1: alpha=1, lambda=0.1 
- Fold04.Rep1: alpha=1, lambda=0.1 
+ Fold05.Rep1: alpha=1, lambda=0.1 
- Fold05.Rep1: alpha=1, lambda=0.1 
+ Fold06.Rep1: alpha=1, lambda=0.1 
- Fold06.Rep1: alpha=1, lambda=0.1 
+ Fold07.Rep1: alpha=1, lambda=0.1 
- Fold07.Rep1: alpha=1, lambda=0.1 
+ Fold08.Rep1: alpha=1, lambda=0.1 
- Fold08.Rep1: alpha=1, lambda=0.1 
+ Fold09.Rep1: alpha=1, lambda=0.1 
- Fold09.Rep1: alpha=1, lambda=0.1 
+ Fold10.Rep1: alpha=1, lambda=0.1 
- Fold10.Rep1: alpha=1, lambda=0.1 
Aggregating results
Selecting tuning parameters
Fitting alpha = 1, lambda = 0.0258 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[157]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;pROC&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="s">&quot;pROC&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message:
&#34;package &#39;pROC&#39; is in use and will not be installed&#34;</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[297]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">lasso_pred4</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">reg4</span><span class="p">,</span><span class="n">test4</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="n">lasso_error4</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">lasso_pred4</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = objective, case = subjective
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[296]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">dt_grid4</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">cp</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span><span class="m">0.1</span><span class="p">))</span>
<span class="n">dt4.1</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">Label</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train4</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid4</span><span class="p">,</span><span class="n">trControl</span><span class="o">=</span><span class="n">control4</span><span class="p">,</span>
             <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">)))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in train.default(x, y, weights = w, ...):
&#34;The metric &#34;Accuracy&#34; was not in the result set. ROC will be used instead.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[298]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt_pred4</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt4.1</span><span class="p">,</span><span class="n">test4</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="n">dt_error4.1</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">dt_pred4</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = objective, case = subjective
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[162]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">dt4.2</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">Label</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train4</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid4</span><span class="p">,</span><span class="n">trControl</span><span class="o">=</span><span class="n">control4</span><span class="p">,</span> 
             <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">)))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in train.default(x, y, weights = w, ...):
&#34;The metric &#34;Accuracy&#34; was not in the result set. ROC will be used instead.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[299]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt_pred4.2</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt4.2</span><span class="p">,</span><span class="n">test4</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="n">dt_error4.2</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">dt_pred4.2</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = objective, case = subjective
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[166]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">dt4.3</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">Label</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train4</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&quot;rpart&quot;</span><span class="p">,</span><span class="n">tuneGrid</span> <span class="o">=</span> <span class="n">dt_grid4</span><span class="p">,</span><span class="n">trControl</span><span class="o">=</span><span class="n">control4</span><span class="p">,</span> 
             <span class="n">control</span> <span class="o">=</span> <span class="nf">rpart.control</span><span class="p">(</span><span class="n">minbucket</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">)))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in train.default(x, y, weights = w, ...):
&#34;The metric &#34;Accuracy&#34; was not in the result set. ROC will be used instead.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: cp=0.001 
- Fold01.Rep1: cp=0.001 
+ Fold02.Rep1: cp=0.001 
- Fold02.Rep1: cp=0.001 
+ Fold03.Rep1: cp=0.001 
- Fold03.Rep1: cp=0.001 
+ Fold04.Rep1: cp=0.001 
- Fold04.Rep1: cp=0.001 
+ Fold05.Rep1: cp=0.001 
- Fold05.Rep1: cp=0.001 
+ Fold06.Rep1: cp=0.001 
- Fold06.Rep1: cp=0.001 
+ Fold07.Rep1: cp=0.001 
- Fold07.Rep1: cp=0.001 
+ Fold08.Rep1: cp=0.001 
- Fold08.Rep1: cp=0.001 
+ Fold09.Rep1: cp=0.001 
- Fold09.Rep1: cp=0.001 
+ Fold10.Rep1: cp=0.001 
- Fold10.Rep1: cp=0.001 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.01 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[300]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">dt_pred4.3</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dt4.3</span><span class="p">,</span><span class="n">test4</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="n">dt_error4.3</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">dt_pred4.3</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = objective, case = subjective
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[136]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">rf_grid4</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">mtry</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">6</span><span class="p">)</span> <span class="p">,</span><span class="n">min.node.size</span><span class="o">=</span><span class="m">5</span><span class="p">,</span> <span class="n">splitrule</span> <span class="o">=</span> <span class="s">&quot;gini&quot;</span><span class="p">)</span>
<span class="n">rf4</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">Label</span> <span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train4</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;ranger&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">rf_grid4</span><span class="p">,</span> 
                 <span class="n">trControl</span><span class="o">=</span> <span class="n">control4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in train.default(x, y, weights = w, ...):
&#34;The metric &#34;Accuracy&#34; was not in the result set. ROC will be used instead.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold01.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold01.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold01.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold01.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold01.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold02.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold02.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold02.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold02.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold02.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold02.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold03.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold03.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold03.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold03.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold03.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold03.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold04.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold04.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold04.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold04.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold04.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold04.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold05.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold05.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold05.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold05.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold05.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold05.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold06.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold06.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold06.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold06.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold06.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold06.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold07.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold07.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold07.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold07.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold07.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold07.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold08.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold08.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold08.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold08.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold08.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold08.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold09.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold09.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold09.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold09.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold09.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold09.Rep1: mtry=6, min.node.size=5, splitrule=gini 
+ Fold10.Rep1: mtry=2, min.node.size=5, splitrule=gini 
- Fold10.Rep1: mtry=2, min.node.size=5, splitrule=gini 
+ Fold10.Rep1: mtry=4, min.node.size=5, splitrule=gini 
- Fold10.Rep1: mtry=4, min.node.size=5, splitrule=gini 
+ Fold10.Rep1: mtry=6, min.node.size=5, splitrule=gini 
- Fold10.Rep1: mtry=6, min.node.size=5, splitrule=gini 
Aggregating results
Selecting tuning parameters
Fitting mtry = 4, splitrule = gini, min.node.size = 5 on full training set
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[301]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">rf_pred4</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">rf4</span><span class="p">,</span><span class="n">test4</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="n">rf_error4</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">rf_pred4</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = objective, case = subjective
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[145]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">sgb_grid4</span> <span class="o">&lt;-</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">interaction.depth</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">6</span><span class="p">),</span> <span class="n">n.trees</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">200</span><span class="p">,</span><span class="m">300</span><span class="p">),</span> <span class="n">shrinkage</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span><span class="m">0.01</span><span class="p">,</span> <span class="m">0.02</span><span class="p">),</span> 
                         <span class="n">n.minobsinnode</span><span class="o">=</span><span class="m">10</span><span class="p">)</span>
<span class="n">sgb4</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">Label</span><span class="o">~</span><span class="n">.</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train4</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;gbm&quot;</span><span class="p">,</span> <span class="n">tuneGrid</span><span class="o">=</span> <span class="n">sgb_grid4</span><span class="p">,</span> <span class="n">trControl</span><span class="o">=</span> <span class="n">control4</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Warning message in train.default(x, y, weights = w, ...):
&#34;The metric &#34;Accuracy&#34; was not in the result set. ROC will be used instead.&#34;</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>+ Fold01.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3052             nan     0.0010    0.0004
     2        1.3046             nan     0.0010    0.0003
     3        1.3038             nan     0.0010    0.0004
     4        1.3030             nan     0.0010    0.0004
     5        1.3023             nan     0.0010    0.0004
     6        1.3015             nan     0.0010    0.0003
     7        1.3008             nan     0.0010    0.0004
     8        1.2999             nan     0.0010    0.0003
     9        1.2992             nan     0.0010    0.0004
    10        1.2984             nan     0.0010    0.0003
    20        1.2906             nan     0.0010    0.0004
    40        1.2759             nan     0.0010    0.0003
    60        1.2613             nan     0.0010    0.0003
    80        1.2476             nan     0.0010    0.0003
   100        1.2343             nan     0.0010    0.0003
   120        1.2211             nan     0.0010    0.0003
   140        1.2084             nan     0.0010    0.0003
   160        1.1964             nan     0.0010    0.0003
   180        1.1846             nan     0.0010    0.0003
   200        1.1732             nan     0.0010    0.0003
   220        1.1622             nan     0.0010    0.0002
   240        1.1517             nan     0.0010    0.0002
   260        1.1415             nan     0.0010    0.0002
   280        1.1313             nan     0.0010    0.0002
   300        1.1216             nan     0.0010    0.0002

- Fold01.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3052             nan     0.0010    0.0004
     2        1.3043             nan     0.0010    0.0004
     3        1.3034             nan     0.0010    0.0004
     4        1.3025             nan     0.0010    0.0004
     5        1.3017             nan     0.0010    0.0004
     6        1.3008             nan     0.0010    0.0004
     7        1.2999             nan     0.0010    0.0004
     8        1.2990             nan     0.0010    0.0004
     9        1.2981             nan     0.0010    0.0004
    10        1.2972             nan     0.0010    0.0004
    20        1.2883             nan     0.0010    0.0004
    40        1.2713             nan     0.0010    0.0003
    60        1.2546             nan     0.0010    0.0004
    80        1.2388             nan     0.0010    0.0004
   100        1.2232             nan     0.0010    0.0003
   120        1.2082             nan     0.0010    0.0003
   140        1.1939             nan     0.0010    0.0003
   160        1.1801             nan     0.0010    0.0003
   180        1.1667             nan     0.0010    0.0003
   200        1.1535             nan     0.0010    0.0003
   220        1.1413             nan     0.0010    0.0003
   240        1.1290             nan     0.0010    0.0003
   260        1.1170             nan     0.0010    0.0002
   280        1.1058             nan     0.0010    0.0002
   300        1.0944             nan     0.0010    0.0003

- Fold01.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3050             nan     0.0010    0.0004
     2        1.3042             nan     0.0010    0.0004
     3        1.3033             nan     0.0010    0.0004
     4        1.3023             nan     0.0010    0.0004
     5        1.3014             nan     0.0010    0.0004
     6        1.3004             nan     0.0010    0.0004
     7        1.2995             nan     0.0010    0.0004
     8        1.2985             nan     0.0010    0.0005
     9        1.2975             nan     0.0010    0.0004
    10        1.2965             nan     0.0010    0.0004
    20        1.2870             nan     0.0010    0.0004
    40        1.2687             nan     0.0010    0.0004
    60        1.2509             nan     0.0010    0.0004
    80        1.2338             nan     0.0010    0.0004
   100        1.2174             nan     0.0010    0.0003
   120        1.2014             nan     0.0010    0.0003
   140        1.1860             nan     0.0010    0.0004
   160        1.1708             nan     0.0010    0.0003
   180        1.1563             nan     0.0010    0.0003
   200        1.1423             nan     0.0010    0.0003
   220        1.1286             nan     0.0010    0.0003
   240        1.1152             nan     0.0010    0.0003
   260        1.1025             nan     0.0010    0.0002
   280        1.0897             nan     0.0010    0.0003
   300        1.0774             nan     0.0010    0.0003

- Fold01.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2979             nan     0.0100    0.0033
     2        1.2905             nan     0.0100    0.0035
     3        1.2829             nan     0.0100    0.0035
     4        1.2745             nan     0.0100    0.0035
     5        1.2683             nan     0.0100    0.0031
     6        1.2613             nan     0.0100    0.0033
     7        1.2538             nan     0.0100    0.0033
     8        1.2469             nan     0.0100    0.0032
     9        1.2401             nan     0.0100    0.0030
    10        1.2332             nan     0.0100    0.0031
    20        1.1719             nan     0.0100    0.0023
    40        1.0749             nan     0.0100    0.0015
    60        1.0026             nan     0.0100    0.0013
    80        0.9449             nan     0.0100    0.0009
   100        0.8982             nan     0.0100    0.0007
   120        0.8605             nan     0.0100    0.0007
   140        0.8308             nan     0.0100    0.0004
   160        0.8058             nan     0.0100    0.0002
   180        0.7850             nan     0.0100    0.0002
   200        0.7661             nan     0.0100    0.0003
   220        0.7499             nan     0.0100    0.0001
   240        0.7354             nan     0.0100    0.0002
   260        0.7231             nan     0.0100    0.0001
   280        0.7118             nan     0.0100    0.0001
   300        0.7018             nan     0.0100   -0.0001

- Fold01.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2968             nan     0.0100    0.0042
     2        1.2877             nan     0.0100    0.0040
     3        1.2794             nan     0.0100    0.0040
     4        1.2697             nan     0.0100    0.0044
     5        1.2614             nan     0.0100    0.0038
     6        1.2532             nan     0.0100    0.0034
     7        1.2447             nan     0.0100    0.0037
     8        1.2367             nan     0.0100    0.0036
     9        1.2285             nan     0.0100    0.0036
    10        1.2206             nan     0.0100    0.0036
    20        1.1508             nan     0.0100    0.0030
    40        1.0411             nan     0.0100    0.0016
    60        0.9584             nan     0.0100    0.0014
    80        0.8933             nan     0.0100    0.0012
   100        0.8401             nan     0.0100    0.0009
   120        0.7990             nan     0.0100    0.0006
   140        0.7626             nan     0.0100    0.0002
   160        0.7317             nan     0.0100    0.0003
   180        0.7065             nan     0.0100    0.0002
   200        0.6841             nan     0.0100    0.0003
   220        0.6635             nan     0.0100   -0.0000
   240        0.6446             nan     0.0100   -0.0000
   260        0.6285             nan     0.0100    0.0000
   280        0.6128             nan     0.0100   -0.0001
   300        0.5993             nan     0.0100   -0.0002

- Fold01.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2967             nan     0.0100    0.0040
     2        1.2878             nan     0.0100    0.0038
     3        1.2787             nan     0.0100    0.0035
     4        1.2700             nan     0.0100    0.0039
     5        1.2607             nan     0.0100    0.0043
     6        1.2516             nan     0.0100    0.0035
     7        1.2433             nan     0.0100    0.0036
     8        1.2342             nan     0.0100    0.0041
     9        1.2260             nan     0.0100    0.0037
    10        1.2176             nan     0.0100    0.0038
    20        1.1432             nan     0.0100    0.0027
    40        1.0235             nan     0.0100    0.0020
    60        0.9322             nan     0.0100    0.0017
    80        0.8602             nan     0.0100    0.0012
   100        0.8042             nan     0.0100    0.0008
   120        0.7564             nan     0.0100    0.0007
   140        0.7159             nan     0.0100    0.0003
   160        0.6811             nan     0.0100    0.0004
   180        0.6521             nan     0.0100    0.0003
   200        0.6256             nan     0.0100    0.0002
   220        0.6019             nan     0.0100    0.0003
   240        0.5807             nan     0.0100    0.0002
   260        0.5628             nan     0.0100    0.0001
   280        0.5446             nan     0.0100    0.0001
   300        0.5275             nan     0.0100   -0.0002

- Fold01.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2911             nan     0.0200    0.0071
     2        1.2772             nan     0.0200    0.0069
     3        1.2626             nan     0.0200    0.0063
     4        1.2482             nan     0.0200    0.0069
     5        1.2350             nan     0.0200    0.0052
     6        1.2214             nan     0.0200    0.0059
     7        1.2091             nan     0.0200    0.0056
     8        1.1966             nan     0.0200    0.0054
     9        1.1846             nan     0.0200    0.0057
    10        1.1725             nan     0.0200    0.0050
    20        1.0750             nan     0.0200    0.0036
    40        0.9483             nan     0.0200    0.0024
    60        0.8638             nan     0.0200    0.0011
    80        0.8079             nan     0.0200    0.0008
   100        0.7721             nan     0.0200    0.0002
   120        0.7420             nan     0.0200   -0.0002
   140        0.7185             nan     0.0200    0.0001
   160        0.6997             nan     0.0200    0.0004
   180        0.6819             nan     0.0200   -0.0001
   200        0.6659             nan     0.0200    0.0001
   220        0.6493             nan     0.0200   -0.0001
   240        0.6354             nan     0.0200   -0.0002
   260        0.6243             nan     0.0200    0.0001
   280        0.6125             nan     0.0200   -0.0003
   300        0.6002             nan     0.0200   -0.0000

- Fold01.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2879             nan     0.0200    0.0079
     2        1.2702             nan     0.0200    0.0068
     3        1.2533             nan     0.0200    0.0072
     4        1.2362             nan     0.0200    0.0063
     5        1.2204             nan     0.0200    0.0077
     6        1.2050             nan     0.0200    0.0072
     7        1.1910             nan     0.0200    0.0064
     8        1.1761             nan     0.0200    0.0063
     9        1.1629             nan     0.0200    0.0051
    10        1.1506             nan     0.0200    0.0057
    20        1.0426             nan     0.0200    0.0036
    40        0.8929             nan     0.0200    0.0020
    60        0.8017             nan     0.0200    0.0010
    80        0.7368             nan     0.0200    0.0005
   100        0.6871             nan     0.0200    0.0002
   120        0.6481             nan     0.0200    0.0001
   140        0.6177             nan     0.0200    0.0002
   160        0.5896             nan     0.0200    0.0002
   180        0.5658             nan     0.0200   -0.0001
   200        0.5437             nan     0.0200   -0.0002
   220        0.5244             nan     0.0200   -0.0004
   240        0.5057             nan     0.0200   -0.0001
   260        0.4860             nan     0.0200   -0.0002
   280        0.4700             nan     0.0200   -0.0004
   300        0.4531             nan     0.0200   -0.0003

- Fold01.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold01.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2864             nan     0.0200    0.0084
     2        1.2675             nan     0.0200    0.0077
     3        1.2485             nan     0.0200    0.0081
     4        1.2320             nan     0.0200    0.0076
     5        1.2150             nan     0.0200    0.0072
     6        1.1993             nan     0.0200    0.0063
     7        1.1839             nan     0.0200    0.0064
     8        1.1707             nan     0.0200    0.0052
     9        1.1569             nan     0.0200    0.0061
    10        1.1437             nan     0.0200    0.0055
    20        1.0260             nan     0.0200    0.0037
    40        0.8630             nan     0.0200    0.0019
    60        0.7595             nan     0.0200    0.0015
    80        0.6853             nan     0.0200    0.0005
   100        0.6279             nan     0.0200    0.0006
   120        0.5817             nan     0.0200    0.0004
   140        0.5433             nan     0.0200   -0.0000
   160        0.5127             nan     0.0200   -0.0002
   180        0.4853             nan     0.0200    0.0001
   200        0.4588             nan     0.0200   -0.0002
   220        0.4364             nan     0.0200   -0.0004
   240        0.4154             nan     0.0200   -0.0006
   260        0.3933             nan     0.0200   -0.0001
   280        0.3739             nan     0.0200   -0.0002
   300        0.3581             nan     0.0200   -0.0003

- Fold01.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3053             nan     0.0010    0.0003
     2        1.3046             nan     0.0010    0.0003
     3        1.3038             nan     0.0010    0.0004
     4        1.3031             nan     0.0010    0.0003
     5        1.3023             nan     0.0010    0.0003
     6        1.3017             nan     0.0010    0.0003
     7        1.3009             nan     0.0010    0.0003
     8        1.3002             nan     0.0010    0.0004
     9        1.2994             nan     0.0010    0.0003
    10        1.2988             nan     0.0010    0.0003
    20        1.2916             nan     0.0010    0.0003
    40        1.2777             nan     0.0010    0.0003
    60        1.2645             nan     0.0010    0.0003
    80        1.2514             nan     0.0010    0.0003
   100        1.2389             nan     0.0010    0.0003
   120        1.2267             nan     0.0010    0.0003
   140        1.2149             nan     0.0010    0.0003
   160        1.2035             nan     0.0010    0.0003
   180        1.1923             nan     0.0010    0.0002
   200        1.1818             nan     0.0010    0.0002
   220        1.1713             nan     0.0010    0.0002
   240        1.1609             nan     0.0010    0.0002
   260        1.1511             nan     0.0010    0.0002
   280        1.1415             nan     0.0010    0.0002
   300        1.1325             nan     0.0010    0.0002

- Fold02.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3052             nan     0.0010    0.0004
     2        1.3042             nan     0.0010    0.0004
     3        1.3034             nan     0.0010    0.0004
     4        1.3025             nan     0.0010    0.0004
     5        1.3017             nan     0.0010    0.0004
     6        1.3008             nan     0.0010    0.0004
     7        1.3000             nan     0.0010    0.0003
     8        1.2992             nan     0.0010    0.0004
     9        1.2983             nan     0.0010    0.0003
    10        1.2975             nan     0.0010    0.0004
    20        1.2894             nan     0.0010    0.0004
    40        1.2736             nan     0.0010    0.0004
    60        1.2581             nan     0.0010    0.0003
    80        1.2432             nan     0.0010    0.0003
   100        1.2289             nan     0.0010    0.0003
   120        1.2146             nan     0.0010    0.0003
   140        1.2007             nan     0.0010    0.0003
   160        1.1878             nan     0.0010    0.0003
   180        1.1754             nan     0.0010    0.0003
   200        1.1631             nan     0.0010    0.0003
   220        1.1513             nan     0.0010    0.0003
   240        1.1394             nan     0.0010    0.0002
   260        1.1283             nan     0.0010    0.0003
   280        1.1172             nan     0.0010    0.0002
   300        1.1066             nan     0.0010    0.0002

- Fold02.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3052             nan     0.0010    0.0004
     2        1.3042             nan     0.0010    0.0004
     3        1.3033             nan     0.0010    0.0004
     4        1.3024             nan     0.0010    0.0004
     5        1.3015             nan     0.0010    0.0004
     6        1.3005             nan     0.0010    0.0004
     7        1.2996             nan     0.0010    0.0004
     8        1.2987             nan     0.0010    0.0004
     9        1.2978             nan     0.0010    0.0004
    10        1.2969             nan     0.0010    0.0004
    20        1.2881             nan     0.0010    0.0003
    40        1.2707             nan     0.0010    0.0004
    60        1.2539             nan     0.0010    0.0004
    80        1.2373             nan     0.0010    0.0003
   100        1.2216             nan     0.0010    0.0003
   120        1.2065             nan     0.0010    0.0003
   140        1.1914             nan     0.0010    0.0003
   160        1.1772             nan     0.0010    0.0002
   180        1.1630             nan     0.0010    0.0003
   200        1.1496             nan     0.0010    0.0003
   220        1.1365             nan     0.0010    0.0003
   240        1.1238             nan     0.0010    0.0002
   260        1.1116             nan     0.0010    0.0003
   280        1.0995             nan     0.0010    0.0002
   300        1.0880             nan     0.0010    0.0002

- Fold02.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2985             nan     0.0100    0.0033
     2        1.2912             nan     0.0100    0.0032
     3        1.2843             nan     0.0100    0.0031
     4        1.2778             nan     0.0100    0.0033
     5        1.2709             nan     0.0100    0.0030
     6        1.2642             nan     0.0100    0.0028
     7        1.2573             nan     0.0100    0.0028
     8        1.2509             nan     0.0100    0.0029
     9        1.2449             nan     0.0100    0.0026
    10        1.2383             nan     0.0100    0.0030
    20        1.1802             nan     0.0100    0.0025
    40        1.0862             nan     0.0100    0.0015
    60        1.0195             nan     0.0100    0.0011
    80        0.9671             nan     0.0100    0.0007
   100        0.9234             nan     0.0100    0.0007
   120        0.8893             nan     0.0100    0.0005
   140        0.8615             nan     0.0100    0.0005
   160        0.8382             nan     0.0100    0.0004
   180        0.8178             nan     0.0100    0.0003
   200        0.7989             nan     0.0100    0.0003
   220        0.7842             nan     0.0100    0.0000
   240        0.7696             nan     0.0100    0.0002
   260        0.7567             nan     0.0100    0.0002
   280        0.7451             nan     0.0100    0.0001
   300        0.7346             nan     0.0100   -0.0000

- Fold02.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2981             nan     0.0100    0.0035
     2        1.2896             nan     0.0100    0.0035
     3        1.2811             nan     0.0100    0.0038
     4        1.2728             nan     0.0100    0.0035
     5        1.2650             nan     0.0100    0.0033
     6        1.2574             nan     0.0100    0.0035
     7        1.2498             nan     0.0100    0.0034
     8        1.2426             nan     0.0100    0.0032
     9        1.2353             nan     0.0100    0.0035
    10        1.2279             nan     0.0100    0.0030
    20        1.1625             nan     0.0100    0.0027
    40        1.0592             nan     0.0100    0.0017
    60        0.9785             nan     0.0100    0.0017
    80        0.9150             nan     0.0100    0.0010
   100        0.8666             nan     0.0100    0.0006
   120        0.8233             nan     0.0100    0.0008
   140        0.7877             nan     0.0100    0.0004
   160        0.7594             nan     0.0100    0.0001
   180        0.7352             nan     0.0100    0.0003
   200        0.7117             nan     0.0100    0.0001
   220        0.6921             nan     0.0100    0.0001
   240        0.6728             nan     0.0100    0.0001
   260        0.6547             nan     0.0100   -0.0001
   280        0.6412             nan     0.0100   -0.0001
   300        0.6278             nan     0.0100   -0.0002

- Fold02.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2969             nan     0.0100    0.0042
     2        1.2878             nan     0.0100    0.0040
     3        1.2785             nan     0.0100    0.0039
     4        1.2696             nan     0.0100    0.0038
     5        1.2611             nan     0.0100    0.0036
     6        1.2523             nan     0.0100    0.0034
     7        1.2440             nan     0.0100    0.0033
     8        1.2355             nan     0.0100    0.0037
     9        1.2282             nan     0.0100    0.0032
    10        1.2200             nan     0.0100    0.0032
    20        1.1477             nan     0.0100    0.0029
    40        1.0322             nan     0.0100    0.0021
    60        0.9457             nan     0.0100    0.0012
    80        0.8766             nan     0.0100    0.0011
   100        0.8206             nan     0.0100    0.0007
   120        0.7761             nan     0.0100    0.0005
   140        0.7380             nan     0.0100    0.0005
   160        0.7053             nan     0.0100    0.0004
   180        0.6771             nan     0.0100   -0.0000
   200        0.6525             nan     0.0100    0.0001
   220        0.6305             nan     0.0100    0.0002
   240        0.6094             nan     0.0100    0.0001
   260        0.5909             nan     0.0100    0.0000
   280        0.5733             nan     0.0100    0.0000
   300        0.5564             nan     0.0100   -0.0001

- Fold02.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2923             nan     0.0200    0.0061
     2        1.2770             nan     0.0200    0.0065
     3        1.2632             nan     0.0200    0.0066
     4        1.2504             nan     0.0200    0.0064
     5        1.2371             nan     0.0200    0.0059
     6        1.2244             nan     0.0200    0.0053
     7        1.2134             nan     0.0200    0.0049
     8        1.2012             nan     0.0200    0.0055
     9        1.1893             nan     0.0200    0.0049
    10        1.1787             nan     0.0200    0.0049
    20        1.0891             nan     0.0200    0.0035
    40        0.9647             nan     0.0200    0.0021
    60        0.8893             nan     0.0200    0.0010
    80        0.8367             nan     0.0200    0.0008
   100        0.8005             nan     0.0200    0.0005
   120        0.7725             nan     0.0200    0.0004
   140        0.7489             nan     0.0200    0.0002
   160        0.7283             nan     0.0200    0.0002
   180        0.7122             nan     0.0200   -0.0001
   200        0.6978             nan     0.0200   -0.0000
   220        0.6844             nan     0.0200    0.0000
   240        0.6713             nan     0.0200   -0.0002
   260        0.6599             nan     0.0200    0.0002
   280        0.6481             nan     0.0200    0.0001
   300        0.6373             nan     0.0200   -0.0003

- Fold02.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2887             nan     0.0200    0.0079
     2        1.2727             nan     0.0200    0.0071
     3        1.2580             nan     0.0200    0.0067
     4        1.2435             nan     0.0200    0.0074
     5        1.2291             nan     0.0200    0.0060
     6        1.2145             nan     0.0200    0.0057
     7        1.2020             nan     0.0200    0.0051
     8        1.1882             nan     0.0200    0.0055
     9        1.1749             nan     0.0200    0.0057
    10        1.1617             nan     0.0200    0.0056
    20        1.0542             nan     0.0200    0.0036
    40        0.9105             nan     0.0200    0.0023
    60        0.8200             nan     0.0200    0.0012
    80        0.7552             nan     0.0200    0.0005
   100        0.7086             nan     0.0200   -0.0004
   120        0.6710             nan     0.0200    0.0000
   140        0.6374             nan     0.0200    0.0002
   160        0.6111             nan     0.0200   -0.0000
   180        0.5862             nan     0.0200   -0.0005
   200        0.5641             nan     0.0200   -0.0002
   220        0.5444             nan     0.0200   -0.0001
   240        0.5271             nan     0.0200   -0.0003
   260        0.5089             nan     0.0200   -0.0003
   280        0.4921             nan     0.0200    0.0000
   300        0.4765             nan     0.0200   -0.0004

- Fold02.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold02.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2886             nan     0.0200    0.0081
     2        1.2719             nan     0.0200    0.0067
     3        1.2550             nan     0.0200    0.0077
     4        1.2372             nan     0.0200    0.0074
     5        1.2201             nan     0.0200    0.0067
     6        1.2050             nan     0.0200    0.0068
     7        1.1901             nan     0.0200    0.0062
     8        1.1763             nan     0.0200    0.0055
     9        1.1618             nan     0.0200    0.0056
    10        1.1475             nan     0.0200    0.0049
    20        1.0314             nan     0.0200    0.0038
    40        0.8786             nan     0.0200    0.0020
    60        0.7777             nan     0.0200    0.0008
    80        0.7046             nan     0.0200    0.0008
   100        0.6457             nan     0.0200    0.0003
   120        0.6011             nan     0.0200    0.0002
   140        0.5632             nan     0.0200   -0.0003
   160        0.5323             nan     0.0200    0.0002
   180        0.5049             nan     0.0200   -0.0004
   200        0.4805             nan     0.0200   -0.0002
   220        0.4582             nan     0.0200   -0.0004
   240        0.4374             nan     0.0200    0.0001
   260        0.4165             nan     0.0200   -0.0003
   280        0.3991             nan     0.0200   -0.0003
   300        0.3797             nan     0.0200   -0.0003

- Fold02.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3053             nan     0.0010    0.0004
     2        1.3045             nan     0.0010    0.0003
     3        1.3036             nan     0.0010    0.0004
     4        1.3029             nan     0.0010    0.0004
     5        1.3021             nan     0.0010    0.0003
     6        1.3014             nan     0.0010    0.0004
     7        1.3006             nan     0.0010    0.0003
     8        1.2999             nan     0.0010    0.0004
     9        1.2991             nan     0.0010    0.0004
    10        1.2983             nan     0.0010    0.0003
    20        1.2907             nan     0.0010    0.0003
    40        1.2760             nan     0.0010    0.0003
    60        1.2617             nan     0.0010    0.0003
    80        1.2484             nan     0.0010    0.0003
   100        1.2354             nan     0.0010    0.0003
   120        1.2226             nan     0.0010    0.0003
   140        1.2103             nan     0.0010    0.0003
   160        1.1983             nan     0.0010    0.0003
   180        1.1867             nan     0.0010    0.0002
   200        1.1755             nan     0.0010    0.0002
   220        1.1648             nan     0.0010    0.0002
   240        1.1543             nan     0.0010    0.0002
   260        1.1444             nan     0.0010    0.0002
   280        1.1346             nan     0.0010    0.0002
   300        1.1254             nan     0.0010    0.0002

- Fold03.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3051             nan     0.0010    0.0004
     2        1.3042             nan     0.0010    0.0004
     3        1.3034             nan     0.0010    0.0004
     4        1.3026             nan     0.0010    0.0003
     5        1.3018             nan     0.0010    0.0004
     6        1.3010             nan     0.0010    0.0004
     7        1.3001             nan     0.0010    0.0004
     8        1.2993             nan     0.0010    0.0004
     9        1.2984             nan     0.0010    0.0004
    10        1.2976             nan     0.0010    0.0004
    20        1.2891             nan     0.0010    0.0004
    40        1.2727             nan     0.0010    0.0004
    60        1.2565             nan     0.0010    0.0004
    80        1.2407             nan     0.0010    0.0004
   100        1.2261             nan     0.0010    0.0003
   120        1.2114             nan     0.0010    0.0003
   140        1.1973             nan     0.0010    0.0003
   160        1.1838             nan     0.0010    0.0003
   180        1.1705             nan     0.0010    0.0003
   200        1.1580             nan     0.0010    0.0002
   220        1.1459             nan     0.0010    0.0003
   240        1.1338             nan     0.0010    0.0003
   260        1.1223             nan     0.0010    0.0002
   280        1.1113             nan     0.0010    0.0002
   300        1.1006             nan     0.0010    0.0002

- Fold03.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3050             nan     0.0010    0.0005
     2        1.3040             nan     0.0010    0.0004
     3        1.3031             nan     0.0010    0.0004
     4        1.3022             nan     0.0010    0.0004
     5        1.3013             nan     0.0010    0.0004
     6        1.3004             nan     0.0010    0.0004
     7        1.2994             nan     0.0010    0.0004
     8        1.2984             nan     0.0010    0.0004
     9        1.2975             nan     0.0010    0.0004
    10        1.2966             nan     0.0010    0.0004
    20        1.2874             nan     0.0010    0.0004
    40        1.2694             nan     0.0010    0.0004
    60        1.2521             nan     0.0010    0.0004
    80        1.2351             nan     0.0010    0.0004
   100        1.2192             nan     0.0010    0.0003
   120        1.2038             nan     0.0010    0.0003
   140        1.1888             nan     0.0010    0.0003
   160        1.1743             nan     0.0010    0.0003
   180        1.1603             nan     0.0010    0.0003
   200        1.1469             nan     0.0010    0.0003
   220        1.1337             nan     0.0010    0.0003
   240        1.1211             nan     0.0010    0.0003
   260        1.1087             nan     0.0010    0.0002
   280        1.0969             nan     0.0010    0.0002
   300        1.0850             nan     0.0010    0.0002

- Fold03.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2979             nan     0.0100    0.0036
     2        1.2898             nan     0.0100    0.0036
     3        1.2824             nan     0.0100    0.0033
     4        1.2758             nan     0.0100    0.0030
     5        1.2688             nan     0.0100    0.0030
     6        1.2616             nan     0.0100    0.0034
     7        1.2546             nan     0.0100    0.0033
     8        1.2478             nan     0.0100    0.0032
     9        1.2412             nan     0.0100    0.0029
    10        1.2341             nan     0.0100    0.0031
    20        1.1756             nan     0.0100    0.0024
    40        1.0818             nan     0.0100    0.0016
    60        1.0100             nan     0.0100    0.0011
    80        0.9578             nan     0.0100    0.0008
   100        0.9125             nan     0.0100    0.0008
   120        0.8788             nan     0.0100    0.0007
   140        0.8502             nan     0.0100    0.0005
   160        0.8260             nan     0.0100    0.0004
   180        0.8061             nan     0.0100    0.0002
   200        0.7888             nan     0.0100    0.0003
   220        0.7718             nan     0.0100    0.0002
   240        0.7576             nan     0.0100    0.0001
   260        0.7447             nan     0.0100    0.0001
   280        0.7337             nan     0.0100    0.0000
   300        0.7239             nan     0.0100   -0.0001

- Fold03.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2972             nan     0.0100    0.0040
     2        1.2887             nan     0.0100    0.0038
     3        1.2804             nan     0.0100    0.0041
     4        1.2714             nan     0.0100    0.0041
     5        1.2627             nan     0.0100    0.0039
     6        1.2547             nan     0.0100    0.0033
     7        1.2466             nan     0.0100    0.0038
     8        1.2391             nan     0.0100    0.0034
     9        1.2310             nan     0.0100    0.0032
    10        1.2238             nan     0.0100    0.0031
    20        1.1564             nan     0.0100    0.0027
    40        1.0515             nan     0.0100    0.0018
    60        0.9697             nan     0.0100    0.0017
    80        0.9072             nan     0.0100    0.0009
   100        0.8576             nan     0.0100    0.0008
   120        0.8164             nan     0.0100    0.0005
   140        0.7832             nan     0.0100    0.0005
   160        0.7507             nan     0.0100    0.0005
   180        0.7257             nan     0.0100    0.0001
   200        0.7034             nan     0.0100    0.0005
   220        0.6840             nan     0.0100    0.0001
   240        0.6667             nan     0.0100    0.0000
   260        0.6510             nan     0.0100    0.0000
   280        0.6362             nan     0.0100    0.0000
   300        0.6229             nan     0.0100    0.0000

- Fold03.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2969             nan     0.0100    0.0037
     2        1.2871             nan     0.0100    0.0045
     3        1.2776             nan     0.0100    0.0043
     4        1.2689             nan     0.0100    0.0037
     5        1.2601             nan     0.0100    0.0039
     6        1.2514             nan     0.0100    0.0038
     7        1.2434             nan     0.0100    0.0035
     8        1.2348             nan     0.0100    0.0036
     9        1.2263             nan     0.0100    0.0037
    10        1.2190             nan     0.0100    0.0028
    20        1.1450             nan     0.0100    0.0029
    40        1.0286             nan     0.0100    0.0020
    60        0.9434             nan     0.0100    0.0014
    80        0.8753             nan     0.0100    0.0009
   100        0.8180             nan     0.0100    0.0008
   120        0.7722             nan     0.0100    0.0006
   140        0.7338             nan     0.0100    0.0003
   160        0.7015             nan     0.0100    0.0003
   180        0.6725             nan     0.0100    0.0003
   200        0.6487             nan     0.0100    0.0003
   220        0.6255             nan     0.0100    0.0002
   240        0.6036             nan     0.0100    0.0002
   260        0.5846             nan     0.0100    0.0001
   280        0.5668             nan     0.0100   -0.0002
   300        0.5506             nan     0.0100   -0.0000

- Fold03.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2914             nan     0.0200    0.0074
     2        1.2770             nan     0.0200    0.0073
     3        1.2630             nan     0.0200    0.0066
     4        1.2492             nan     0.0200    0.0068
     5        1.2359             nan     0.0200    0.0063
     6        1.2226             nan     0.0200    0.0057
     7        1.2088             nan     0.0200    0.0055
     8        1.1977             nan     0.0200    0.0055
     9        1.1868             nan     0.0200    0.0046
    10        1.1756             nan     0.0200    0.0053
    20        1.0823             nan     0.0200    0.0040
    40        0.9563             nan     0.0200    0.0023
    60        0.8794             nan     0.0200    0.0012
    80        0.8255             nan     0.0200    0.0008
   100        0.7882             nan     0.0200    0.0003
   120        0.7583             nan     0.0200    0.0004
   140        0.7352             nan     0.0200    0.0001
   160        0.7156             nan     0.0200    0.0001
   180        0.6984             nan     0.0200   -0.0001
   200        0.6852             nan     0.0200   -0.0005
   220        0.6712             nan     0.0200   -0.0000
   240        0.6592             nan     0.0200    0.0000
   260        0.6464             nan     0.0200   -0.0002
   280        0.6335             nan     0.0200    0.0001
   300        0.6225             nan     0.0200   -0.0002

- Fold03.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2892             nan     0.0200    0.0078
     2        1.2731             nan     0.0200    0.0073
     3        1.2564             nan     0.0200    0.0076
     4        1.2411             nan     0.0200    0.0069
     5        1.2270             nan     0.0200    0.0067
     6        1.2114             nan     0.0200    0.0063
     7        1.1987             nan     0.0200    0.0057
     8        1.1846             nan     0.0200    0.0063
     9        1.1710             nan     0.0200    0.0060
    10        1.1599             nan     0.0200    0.0046
    20        1.0502             nan     0.0200    0.0045
    40        0.9036             nan     0.0200    0.0022
    60        0.8124             nan     0.0200    0.0010
    80        0.7534             nan     0.0200    0.0003
   100        0.7080             nan     0.0200    0.0004
   120        0.6703             nan     0.0200   -0.0000
   140        0.6392             nan     0.0200    0.0001
   160        0.6107             nan     0.0200    0.0000
   180        0.5867             nan     0.0200   -0.0002
   200        0.5640             nan     0.0200   -0.0000
   220        0.5465             nan     0.0200   -0.0002
   240        0.5255             nan     0.0200   -0.0003
   260        0.5078             nan     0.0200    0.0000
   280        0.4909             nan     0.0200   -0.0001
   300        0.4760             nan     0.0200   -0.0003

- Fold03.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold03.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2872             nan     0.0200    0.0086
     2        1.2708             nan     0.0200    0.0066
     3        1.2532             nan     0.0200    0.0078
     4        1.2371             nan     0.0200    0.0071
     5        1.2226             nan     0.0200    0.0064
     6        1.2061             nan     0.0200    0.0071
     7        1.1906             nan     0.0200    0.0062
     8        1.1774             nan     0.0200    0.0060
     9        1.1635             nan     0.0200    0.0058
    10        1.1493             nan     0.0200    0.0056
    20        1.0284             nan     0.0200    0.0037
    40        0.8743             nan     0.0200    0.0023
    60        0.7730             nan     0.0200    0.0016
    80        0.7019             nan     0.0200    0.0005
   100        0.6489             nan     0.0200    0.0002
   120        0.6058             nan     0.0200    0.0005
   140        0.5710             nan     0.0200   -0.0004
   160        0.5394             nan     0.0200   -0.0002
   180        0.5110             nan     0.0200   -0.0002
   200        0.4862             nan     0.0200   -0.0004
   220        0.4612             nan     0.0200   -0.0002
   240        0.4378             nan     0.0200   -0.0001
   260        0.4166             nan     0.0200   -0.0003
   280        0.3976             nan     0.0200   -0.0003
   300        0.3781             nan     0.0200   -0.0002

- Fold03.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3058             nan     0.0010    0.0004
     2        1.3051             nan     0.0010    0.0003
     3        1.3043             nan     0.0010    0.0004
     4        1.3035             nan     0.0010    0.0003
     5        1.3027             nan     0.0010    0.0003
     6        1.3020             nan     0.0010    0.0004
     7        1.3012             nan     0.0010    0.0004
     8        1.3005             nan     0.0010    0.0003
     9        1.2997             nan     0.0010    0.0004
    10        1.2989             nan     0.0010    0.0004
    20        1.2914             nan     0.0010    0.0003
    40        1.2766             nan     0.0010    0.0003
    60        1.2621             nan     0.0010    0.0003
    80        1.2484             nan     0.0010    0.0003
   100        1.2351             nan     0.0010    0.0003
   120        1.2221             nan     0.0010    0.0003
   140        1.2095             nan     0.0010    0.0003
   160        1.1973             nan     0.0010    0.0003
   180        1.1856             nan     0.0010    0.0003
   200        1.1743             nan     0.0010    0.0003
   220        1.1634             nan     0.0010    0.0003
   240        1.1531             nan     0.0010    0.0002
   260        1.1430             nan     0.0010    0.0002
   280        1.1329             nan     0.0010    0.0002
   300        1.1233             nan     0.0010    0.0002

- Fold04.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3057             nan     0.0010    0.0004
     2        1.3049             nan     0.0010    0.0004
     3        1.3039             nan     0.0010    0.0004
     4        1.3031             nan     0.0010    0.0004
     5        1.3022             nan     0.0010    0.0004
     6        1.3014             nan     0.0010    0.0004
     7        1.3005             nan     0.0010    0.0004
     8        1.2997             nan     0.0010    0.0004
     9        1.2988             nan     0.0010    0.0004
    10        1.2979             nan     0.0010    0.0004
    20        1.2895             nan     0.0010    0.0004
    40        1.2727             nan     0.0010    0.0004
    60        1.2566             nan     0.0010    0.0003
    80        1.2411             nan     0.0010    0.0003
   100        1.2261             nan     0.0010    0.0003
   120        1.2116             nan     0.0010    0.0003
   140        1.1976             nan     0.0010    0.0003
   160        1.1840             nan     0.0010    0.0003
   180        1.1710             nan     0.0010    0.0003
   200        1.1583             nan     0.0010    0.0003
   220        1.1458             nan     0.0010    0.0003
   240        1.1339             nan     0.0010    0.0002
   260        1.1220             nan     0.0010    0.0003
   280        1.1110             nan     0.0010    0.0002
   300        1.1002             nan     0.0010    0.0002

- Fold04.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3057             nan     0.0010    0.0004
     2        1.3047             nan     0.0010    0.0004
     3        1.3038             nan     0.0010    0.0004
     4        1.3029             nan     0.0010    0.0004
     5        1.3019             nan     0.0010    0.0004
     6        1.3009             nan     0.0010    0.0004
     7        1.3000             nan     0.0010    0.0004
     8        1.2991             nan     0.0010    0.0004
     9        1.2982             nan     0.0010    0.0004
    10        1.2973             nan     0.0010    0.0004
    20        1.2880             nan     0.0010    0.0004
    40        1.2700             nan     0.0010    0.0004
    60        1.2527             nan     0.0010    0.0004
    80        1.2358             nan     0.0010    0.0004
   100        1.2195             nan     0.0010    0.0003
   120        1.2038             nan     0.0010    0.0004
   140        1.1887             nan     0.0010    0.0003
   160        1.1738             nan     0.0010    0.0003
   180        1.1597             nan     0.0010    0.0003
   200        1.1461             nan     0.0010    0.0003
   220        1.1331             nan     0.0010    0.0003
   240        1.1204             nan     0.0010    0.0003
   260        1.1079             nan     0.0010    0.0002
   280        1.0960             nan     0.0010    0.0002
   300        1.0844             nan     0.0010    0.0002

- Fold04.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2993             nan     0.0100    0.0032
     2        1.2917             nan     0.0100    0.0038
     3        1.2840             nan     0.0100    0.0033
     4        1.2770             nan     0.0100    0.0034
     5        1.2700             nan     0.0100    0.0035
     6        1.2632             nan     0.0100    0.0032
     7        1.2566             nan     0.0100    0.0033
     8        1.2501             nan     0.0100    0.0032
     9        1.2440             nan     0.0100    0.0027
    10        1.2371             nan     0.0100    0.0035
    20        1.1764             nan     0.0100    0.0028
    40        1.0793             nan     0.0100    0.0016
    60        1.0092             nan     0.0100    0.0013
    80        0.9547             nan     0.0100    0.0011
   100        0.9119             nan     0.0100    0.0006
   120        0.8774             nan     0.0100    0.0004
   140        0.8491             nan     0.0100    0.0004
   160        0.8266             nan     0.0100    0.0002
   180        0.8073             nan     0.0100    0.0003
   200        0.7905             nan     0.0100    0.0001
   220        0.7763             nan     0.0100    0.0001
   240        0.7628             nan     0.0100   -0.0001
   260        0.7493             nan     0.0100   -0.0000
   280        0.7376             nan     0.0100    0.0000
   300        0.7266             nan     0.0100    0.0002

- Fold04.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2969             nan     0.0100    0.0040
     2        1.2879             nan     0.0100    0.0041
     3        1.2792             nan     0.0100    0.0034
     4        1.2713             nan     0.0100    0.0035
     5        1.2628             nan     0.0100    0.0033
     6        1.2556             nan     0.0100    0.0034
     7        1.2479             nan     0.0100    0.0034
     8        1.2397             nan     0.0100    0.0037
     9        1.2320             nan     0.0100    0.0034
    10        1.2246             nan     0.0100    0.0030
    20        1.1559             nan     0.0100    0.0028
    40        1.0499             nan     0.0100    0.0017
    60        0.9675             nan     0.0100    0.0013
    80        0.9042             nan     0.0100    0.0009
   100        0.8553             nan     0.0100    0.0007
   120        0.8148             nan     0.0100    0.0008
   140        0.7817             nan     0.0100    0.0005
   160        0.7539             nan     0.0100    0.0003
   180        0.7291             nan     0.0100    0.0003
   200        0.7068             nan     0.0100    0.0001
   220        0.6865             nan     0.0100    0.0001
   240        0.6691             nan     0.0100    0.0001
   260        0.6521             nan     0.0100    0.0002
   280        0.6374             nan     0.0100    0.0001
   300        0.6240             nan     0.0100   -0.0002

- Fold04.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2967             nan     0.0100    0.0041
     2        1.2867             nan     0.0100    0.0042
     3        1.2773             nan     0.0100    0.0039
     4        1.2679             nan     0.0100    0.0042
     5        1.2594             nan     0.0100    0.0035
     6        1.2511             nan     0.0100    0.0035
     7        1.2426             nan     0.0100    0.0033
     8        1.2341             nan     0.0100    0.0036
     9        1.2264             nan     0.0100    0.0032
    10        1.2181             nan     0.0100    0.0030
    20        1.1457             nan     0.0100    0.0029
    40        1.0291             nan     0.0100    0.0019
    60        0.9436             nan     0.0100    0.0015
    80        0.8741             nan     0.0100    0.0011
   100        0.8199             nan     0.0100    0.0007
   120        0.7760             nan     0.0100    0.0004
   140        0.7372             nan     0.0100    0.0000
   160        0.7021             nan     0.0100    0.0003
   180        0.6729             nan     0.0100    0.0004
   200        0.6473             nan     0.0100    0.0004
   220        0.6247             nan     0.0100   -0.0001
   240        0.6042             nan     0.0100   -0.0000
   260        0.5839             nan     0.0100    0.0000
   280        0.5674             nan     0.0100   -0.0001
   300        0.5514             nan     0.0100   -0.0000

- Fold04.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2898             nan     0.0200    0.0072
     2        1.2749             nan     0.0200    0.0067
     3        1.2607             nan     0.0200    0.0067
     4        1.2467             nan     0.0200    0.0064
     5        1.2331             nan     0.0200    0.0062
     6        1.2199             nan     0.0200    0.0057
     7        1.2079             nan     0.0200    0.0054
     8        1.1959             nan     0.0200    0.0058
     9        1.1831             nan     0.0200    0.0050
    10        1.1714             nan     0.0200    0.0055
    20        1.0785             nan     0.0200    0.0037
    40        0.9534             nan     0.0200    0.0018
    60        0.8740             nan     0.0200    0.0007
    80        0.8217             nan     0.0200    0.0004
   100        0.7843             nan     0.0200    0.0003
   120        0.7563             nan     0.0200    0.0002
   140        0.7340             nan     0.0200    0.0001
   160        0.7151             nan     0.0200    0.0001
   180        0.6971             nan     0.0200   -0.0000
   200        0.6819             nan     0.0200   -0.0001
   220        0.6671             nan     0.0200   -0.0002
   240        0.6543             nan     0.0200   -0.0001
   260        0.6415             nan     0.0200   -0.0001
   280        0.6299             nan     0.0200    0.0001
   300        0.6187             nan     0.0200   -0.0002

- Fold04.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2886             nan     0.0200    0.0081
     2        1.2714             nan     0.0200    0.0077
     3        1.2558             nan     0.0200    0.0070
     4        1.2409             nan     0.0200    0.0060
     5        1.2257             nan     0.0200    0.0077
     6        1.2112             nan     0.0200    0.0057
     7        1.1976             nan     0.0200    0.0061
     8        1.1835             nan     0.0200    0.0060
     9        1.1702             nan     0.0200    0.0057
    10        1.1571             nan     0.0200    0.0050
    20        1.0495             nan     0.0200    0.0046
    40        0.9108             nan     0.0200    0.0025
    60        0.8201             nan     0.0200    0.0011
    80        0.7584             nan     0.0200    0.0005
   100        0.7101             nan     0.0200    0.0001
   120        0.6721             nan     0.0200    0.0004
   140        0.6399             nan     0.0200   -0.0000
   160        0.6132             nan     0.0200   -0.0002
   180        0.5867             nan     0.0200   -0.0000
   200        0.5652             nan     0.0200   -0.0001
   220        0.5450             nan     0.0200   -0.0003
   240        0.5261             nan     0.0200   -0.0002
   260        0.5093             nan     0.0200   -0.0003
   280        0.4925             nan     0.0200   -0.0001
   300        0.4764             nan     0.0200   -0.0002

- Fold04.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold04.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2881             nan     0.0200    0.0078
     2        1.2701             nan     0.0200    0.0079
     3        1.2523             nan     0.0200    0.0075
     4        1.2349             nan     0.0200    0.0071
     5        1.2169             nan     0.0200    0.0074
     6        1.2015             nan     0.0200    0.0057
     7        1.1866             nan     0.0200    0.0069
     8        1.1715             nan     0.0200    0.0067
     9        1.1574             nan     0.0200    0.0065
    10        1.1430             nan     0.0200    0.0062
    20        1.0276             nan     0.0200    0.0041
    40        0.8742             nan     0.0200    0.0018
    60        0.7741             nan     0.0200    0.0011
    80        0.7047             nan     0.0200    0.0005
   100        0.6518             nan     0.0200    0.0005
   120        0.6082             nan     0.0200    0.0003
   140        0.5732             nan     0.0200   -0.0000
   160        0.5424             nan     0.0200   -0.0002
   180        0.5120             nan     0.0200    0.0001
   200        0.4830             nan     0.0200   -0.0002
   220        0.4609             nan     0.0200   -0.0001
   240        0.4374             nan     0.0200   -0.0004
   260        0.4194             nan     0.0200   -0.0002
   280        0.3980             nan     0.0200   -0.0003
   300        0.3799             nan     0.0200   -0.0003

- Fold04.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3063             nan     0.0010    0.0004
     2        1.3054             nan     0.0010    0.0004
     3        1.3045             nan     0.0010    0.0004
     4        1.3037             nan     0.0010    0.0004
     5        1.3029             nan     0.0010    0.0004
     6        1.3021             nan     0.0010    0.0004
     7        1.3012             nan     0.0010    0.0004
     8        1.3004             nan     0.0010    0.0004
     9        1.2996             nan     0.0010    0.0004
    10        1.2988             nan     0.0010    0.0004
    20        1.2908             nan     0.0010    0.0004
    40        1.2757             nan     0.0010    0.0003
    60        1.2610             nan     0.0010    0.0003
    80        1.2472             nan     0.0010    0.0003
   100        1.2337             nan     0.0010    0.0003
   120        1.2208             nan     0.0010    0.0003
   140        1.2083             nan     0.0010    0.0003
   160        1.1958             nan     0.0010    0.0003
   180        1.1839             nan     0.0010    0.0003
   200        1.1723             nan     0.0010    0.0002
   220        1.1611             nan     0.0010    0.0003
   240        1.1503             nan     0.0010    0.0002
   260        1.1397             nan     0.0010    0.0002
   280        1.1296             nan     0.0010    0.0002
   300        1.1199             nan     0.0010    0.0002

- Fold05.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3062             nan     0.0010    0.0004
     2        1.3052             nan     0.0010    0.0004
     3        1.3043             nan     0.0010    0.0004
     4        1.3034             nan     0.0010    0.0004
     5        1.3025             nan     0.0010    0.0004
     6        1.3016             nan     0.0010    0.0004
     7        1.3007             nan     0.0010    0.0004
     8        1.2999             nan     0.0010    0.0004
     9        1.2990             nan     0.0010    0.0004
    10        1.2981             nan     0.0010    0.0004
    20        1.2892             nan     0.0010    0.0004
    40        1.2720             nan     0.0010    0.0004
    60        1.2552             nan     0.0010    0.0004
    80        1.2392             nan     0.0010    0.0004
   100        1.2239             nan     0.0010    0.0003
   120        1.2090             nan     0.0010    0.0003
   140        1.1946             nan     0.0010    0.0003
   160        1.1807             nan     0.0010    0.0003
   180        1.1671             nan     0.0010    0.0003
   200        1.1542             nan     0.0010    0.0003
   220        1.1416             nan     0.0010    0.0003
   240        1.1292             nan     0.0010    0.0003
   260        1.1173             nan     0.0010    0.0002
   280        1.1057             nan     0.0010    0.0003
   300        1.0944             nan     0.0010    0.0002

- Fold05.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3062             nan     0.0010    0.0004
     2        1.3053             nan     0.0010    0.0004
     3        1.3043             nan     0.0010    0.0004
     4        1.3033             nan     0.0010    0.0004
     5        1.3024             nan     0.0010    0.0004
     6        1.3015             nan     0.0010    0.0004
     7        1.3006             nan     0.0010    0.0004
     8        1.2996             nan     0.0010    0.0004
     9        1.2986             nan     0.0010    0.0004
    10        1.2977             nan     0.0010    0.0004
    20        1.2879             nan     0.0010    0.0004
    40        1.2696             nan     0.0010    0.0004
    60        1.2517             nan     0.0010    0.0004
    80        1.2346             nan     0.0010    0.0004
   100        1.2178             nan     0.0010    0.0003
   120        1.2020             nan     0.0010    0.0003
   140        1.1863             nan     0.0010    0.0003
   160        1.1711             nan     0.0010    0.0003
   180        1.1569             nan     0.0010    0.0003
   200        1.1429             nan     0.0010    0.0003
   220        1.1291             nan     0.0010    0.0003
   240        1.1158             nan     0.0010    0.0003
   260        1.1029             nan     0.0010    0.0003
   280        1.0905             nan     0.0010    0.0003
   300        1.0785             nan     0.0010    0.0002

- Fold05.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2989             nan     0.0100    0.0040
     2        1.2917             nan     0.0100    0.0035
     3        1.2840             nan     0.0100    0.0034
     4        1.2768             nan     0.0100    0.0035
     5        1.2693             nan     0.0100    0.0035
     6        1.2624             nan     0.0100    0.0034
     7        1.2553             nan     0.0100    0.0033
     8        1.2488             nan     0.0100    0.0031
     9        1.2418             nan     0.0100    0.0029
    10        1.2351             nan     0.0100    0.0033
    20        1.1730             nan     0.0100    0.0026
    40        1.0771             nan     0.0100    0.0016
    60        1.0027             nan     0.0100    0.0011
    80        0.9450             nan     0.0100    0.0010
   100        0.8997             nan     0.0100    0.0007
   120        0.8634             nan     0.0100    0.0008
   140        0.8331             nan     0.0100    0.0005
   160        0.8088             nan     0.0100    0.0003
   180        0.7885             nan     0.0100    0.0002
   200        0.7704             nan     0.0100    0.0001
   220        0.7544             nan     0.0100    0.0000
   240        0.7407             nan     0.0100    0.0001
   260        0.7273             nan     0.0100    0.0002
   280        0.7151             nan     0.0100   -0.0000
   300        0.7046             nan     0.0100    0.0000

- Fold05.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2973             nan     0.0100    0.0045
     2        1.2880             nan     0.0100    0.0038
     3        1.2791             nan     0.0100    0.0039
     4        1.2706             nan     0.0100    0.0038
     5        1.2624             nan     0.0100    0.0036
     6        1.2550             nan     0.0100    0.0037
     7        1.2474             nan     0.0100    0.0032
     8        1.2396             nan     0.0100    0.0037
     9        1.2319             nan     0.0100    0.0035
    10        1.2241             nan     0.0100    0.0031
    20        1.1533             nan     0.0100    0.0029
    40        1.0440             nan     0.0100    0.0019
    60        0.9600             nan     0.0100    0.0015
    80        0.8946             nan     0.0100    0.0010
   100        0.8418             nan     0.0100    0.0010
   120        0.8000             nan     0.0100    0.0009
   140        0.7633             nan     0.0100    0.0005
   160        0.7313             nan     0.0100    0.0005
   180        0.7074             nan     0.0100   -0.0001
   200        0.6854             nan     0.0100    0.0000
   220        0.6658             nan     0.0100    0.0001
   240        0.6477             nan     0.0100    0.0001
   260        0.6311             nan     0.0100    0.0000
   280        0.6158             nan     0.0100    0.0001
   300        0.6026             nan     0.0100   -0.0001

- Fold05.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2971             nan     0.0100    0.0046
     2        1.2868             nan     0.0100    0.0041
     3        1.2772             nan     0.0100    0.0040
     4        1.2680             nan     0.0100    0.0043
     5        1.2594             nan     0.0100    0.0039
     6        1.2505             nan     0.0100    0.0040
     7        1.2420             nan     0.0100    0.0034
     8        1.2341             nan     0.0100    0.0034
     9        1.2258             nan     0.0100    0.0034
    10        1.2176             nan     0.0100    0.0034
    20        1.1423             nan     0.0100    0.0027
    40        1.0228             nan     0.0100    0.0019
    60        0.9303             nan     0.0100    0.0012
    80        0.8589             nan     0.0100    0.0013
   100        0.8032             nan     0.0100    0.0010
   120        0.7563             nan     0.0100    0.0006
   140        0.7171             nan     0.0100    0.0005
   160        0.6832             nan     0.0100    0.0006
   180        0.6520             nan     0.0100    0.0005
   200        0.6255             nan     0.0100    0.0001
   220        0.6019             nan     0.0100    0.0002
   240        0.5815             nan     0.0100    0.0000
   260        0.5631             nan     0.0100   -0.0000
   280        0.5463             nan     0.0100    0.0000
   300        0.5301             nan     0.0100   -0.0001

- Fold05.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2913             nan     0.0200    0.0069
     2        1.2761             nan     0.0200    0.0071
     3        1.2610             nan     0.0200    0.0069
     4        1.2479             nan     0.0200    0.0062
     5        1.2351             nan     0.0200    0.0059
     6        1.2219             nan     0.0200    0.0059
     7        1.2088             nan     0.0200    0.0063
     8        1.1958             nan     0.0200    0.0061
     9        1.1844             nan     0.0200    0.0057
    10        1.1732             nan     0.0200    0.0055
    20        1.0738             nan     0.0200    0.0037
    40        0.9459             nan     0.0200    0.0012
    60        0.8636             nan     0.0200    0.0012
    80        0.8131             nan     0.0200    0.0006
   100        0.7748             nan     0.0200    0.0003
   120        0.7439             nan     0.0200   -0.0000
   140        0.7207             nan     0.0200   -0.0000
   160        0.6992             nan     0.0200    0.0001
   180        0.6817             nan     0.0200    0.0000
   200        0.6658             nan     0.0200    0.0001
   220        0.6520             nan     0.0200   -0.0000
   240        0.6377             nan     0.0200    0.0000
   260        0.6253             nan     0.0200   -0.0001
   280        0.6133             nan     0.0200    0.0001
   300        0.6020             nan     0.0200   -0.0002

- Fold05.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2908             nan     0.0200    0.0079
     2        1.2741             nan     0.0200    0.0068
     3        1.2575             nan     0.0200    0.0072
     4        1.2424             nan     0.0200    0.0066
     5        1.2262             nan     0.0200    0.0073
     6        1.2108             nan     0.0200    0.0060
     7        1.1952             nan     0.0200    0.0065
     8        1.1809             nan     0.0200    0.0066
     9        1.1679             nan     0.0200    0.0062
    10        1.1546             nan     0.0200    0.0052
    20        1.0447             nan     0.0200    0.0034
    40        0.8951             nan     0.0200    0.0017
    60        0.8019             nan     0.0200    0.0011
    80        0.7365             nan     0.0200    0.0009
   100        0.6869             nan     0.0200    0.0004
   120        0.6480             nan     0.0200   -0.0000
   140        0.6175             nan     0.0200    0.0001
   160        0.5897             nan     0.0200   -0.0004
   180        0.5661             nan     0.0200    0.0001
   200        0.5456             nan     0.0200   -0.0002
   220        0.5257             nan     0.0200   -0.0004
   240        0.5076             nan     0.0200    0.0001
   260        0.4894             nan     0.0200   -0.0002
   280        0.4721             nan     0.0200   -0.0002
   300        0.4566             nan     0.0200   -0.0004

- Fold05.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold05.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2868             nan     0.0200    0.0087
     2        1.2673             nan     0.0200    0.0084
     3        1.2492             nan     0.0200    0.0077
     4        1.2318             nan     0.0200    0.0074
     5        1.2150             nan     0.0200    0.0065
     6        1.1997             nan     0.0200    0.0065
     7        1.1822             nan     0.0200    0.0070
     8        1.1677             nan     0.0200    0.0061
     9        1.1527             nan     0.0200    0.0060
    10        1.1383             nan     0.0200    0.0065
    20        1.0187             nan     0.0200    0.0042
    40        0.8649             nan     0.0200    0.0026
    60        0.7609             nan     0.0200    0.0011
    80        0.6883             nan     0.0200    0.0001
   100        0.6322             nan     0.0200   -0.0003
   120        0.5872             nan     0.0200    0.0003
   140        0.5486             nan     0.0200   -0.0002
   160        0.5144             nan     0.0200   -0.0002
   180        0.4846             nan     0.0200   -0.0002
   200        0.4591             nan     0.0200   -0.0001
   220        0.4370             nan     0.0200   -0.0002
   240        0.4139             nan     0.0200   -0.0001
   260        0.3936             nan     0.0200   -0.0000
   280        0.3749             nan     0.0200   -0.0006
   300        0.3587             nan     0.0200   -0.0004

- Fold05.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3063             nan     0.0010    0.0004
     2        1.3056             nan     0.0010    0.0003
     3        1.3048             nan     0.0010    0.0004
     4        1.3040             nan     0.0010    0.0003
     5        1.3033             nan     0.0010    0.0003
     6        1.3025             nan     0.0010    0.0003
     7        1.3017             nan     0.0010    0.0004
     8        1.3010             nan     0.0010    0.0004
     9        1.3003             nan     0.0010    0.0004
    10        1.2995             nan     0.0010    0.0004
    20        1.2917             nan     0.0010    0.0003
    40        1.2771             nan     0.0010    0.0003
    60        1.2631             nan     0.0010    0.0003
    80        1.2491             nan     0.0010    0.0003
   100        1.2361             nan     0.0010    0.0003
   120        1.2232             nan     0.0010    0.0003
   140        1.2110             nan     0.0010    0.0003
   160        1.1989             nan     0.0010    0.0003
   180        1.1872             nan     0.0010    0.0003
   200        1.1758             nan     0.0010    0.0003
   220        1.1652             nan     0.0010    0.0002
   240        1.1547             nan     0.0010    0.0002
   260        1.1446             nan     0.0010    0.0002
   280        1.1346             nan     0.0010    0.0002
   300        1.1248             nan     0.0010    0.0002

- Fold06.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3062             nan     0.0010    0.0004
     2        1.3053             nan     0.0010    0.0004
     3        1.3044             nan     0.0010    0.0004
     4        1.3035             nan     0.0010    0.0004
     5        1.3027             nan     0.0010    0.0004
     6        1.3018             nan     0.0010    0.0004
     7        1.3009             nan     0.0010    0.0004
     8        1.3000             nan     0.0010    0.0004
     9        1.2992             nan     0.0010    0.0004
    10        1.2983             nan     0.0010    0.0004
    20        1.2896             nan     0.0010    0.0004
    40        1.2728             nan     0.0010    0.0004
    60        1.2567             nan     0.0010    0.0004
    80        1.2409             nan     0.0010    0.0003
   100        1.2257             nan     0.0010    0.0003
   120        1.2111             nan     0.0010    0.0003
   140        1.1969             nan     0.0010    0.0003
   160        1.1834             nan     0.0010    0.0003
   180        1.1698             nan     0.0010    0.0003
   200        1.1567             nan     0.0010    0.0003
   220        1.1443             nan     0.0010    0.0002
   240        1.1322             nan     0.0010    0.0003
   260        1.1205             nan     0.0010    0.0002
   280        1.1091             nan     0.0010    0.0002
   300        1.0980             nan     0.0010    0.0002

- Fold06.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3062             nan     0.0010    0.0004
     2        1.3053             nan     0.0010    0.0004
     3        1.3043             nan     0.0010    0.0004
     4        1.3034             nan     0.0010    0.0004
     5        1.3025             nan     0.0010    0.0004
     6        1.3015             nan     0.0010    0.0004
     7        1.3005             nan     0.0010    0.0004
     8        1.2995             nan     0.0010    0.0004
     9        1.2986             nan     0.0010    0.0004
    10        1.2977             nan     0.0010    0.0003
    20        1.2886             nan     0.0010    0.0004
    40        1.2703             nan     0.0010    0.0004
    60        1.2528             nan     0.0010    0.0004
    80        1.2357             nan     0.0010    0.0004
   100        1.2192             nan     0.0010    0.0004
   120        1.2034             nan     0.0010    0.0003
   140        1.1883             nan     0.0010    0.0003
   160        1.1735             nan     0.0010    0.0003
   180        1.1589             nan     0.0010    0.0003
   200        1.1450             nan     0.0010    0.0003
   220        1.1312             nan     0.0010    0.0002
   240        1.1183             nan     0.0010    0.0002
   260        1.1054             nan     0.0010    0.0003
   280        1.0929             nan     0.0010    0.0002
   300        1.0807             nan     0.0010    0.0002

- Fold06.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2994             nan     0.0100    0.0034
     2        1.2914             nan     0.0100    0.0034
     3        1.2836             nan     0.0100    0.0031
     4        1.2762             nan     0.0100    0.0033
     5        1.2694             nan     0.0100    0.0031
     6        1.2624             nan     0.0100    0.0033
     7        1.2552             nan     0.0100    0.0030
     8        1.2485             nan     0.0100    0.0034
     9        1.2415             nan     0.0100    0.0031
    10        1.2346             nan     0.0100    0.0031
    20        1.1745             nan     0.0100    0.0027
    40        1.0783             nan     0.0100    0.0018
    60        1.0069             nan     0.0100    0.0014
    80        0.9497             nan     0.0100    0.0009
   100        0.9053             nan     0.0100    0.0005
   120        0.8684             nan     0.0100    0.0007
   140        0.8376             nan     0.0100    0.0003
   160        0.8122             nan     0.0100    0.0003
   180        0.7909             nan     0.0100    0.0002
   200        0.7720             nan     0.0100    0.0003
   220        0.7561             nan     0.0100    0.0002
   240        0.7405             nan     0.0100    0.0000
   260        0.7280             nan     0.0100    0.0001
   280        0.7169             nan     0.0100    0.0001
   300        0.7070             nan     0.0100   -0.0000

- Fold06.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2984             nan     0.0100    0.0043
     2        1.2894             nan     0.0100    0.0038
     3        1.2806             nan     0.0100    0.0038
     4        1.2723             nan     0.0100    0.0036
     5        1.2631             nan     0.0100    0.0039
     6        1.2552             nan     0.0100    0.0034
     7        1.2468             nan     0.0100    0.0034
     8        1.2383             nan     0.0100    0.0037
     9        1.2300             nan     0.0100    0.0036
    10        1.2223             nan     0.0100    0.0034
    20        1.1542             nan     0.0100    0.0031
    40        1.0443             nan     0.0100    0.0019
    60        0.9603             nan     0.0100    0.0012
    80        0.8948             nan     0.0100    0.0009
   100        0.8442             nan     0.0100    0.0006
   120        0.8029             nan     0.0100    0.0006
   140        0.7665             nan     0.0100    0.0005
   160        0.7385             nan     0.0100    0.0003
   180        0.7129             nan     0.0100    0.0000
   200        0.6912             nan     0.0100    0.0003
   220        0.6705             nan     0.0100   -0.0000
   240        0.6515             nan     0.0100    0.0002
   260        0.6346             nan     0.0100   -0.0000
   280        0.6200             nan     0.0100   -0.0001
   300        0.6064             nan     0.0100    0.0001

- Fold06.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2978             nan     0.0100    0.0037
     2        1.2886             nan     0.0100    0.0038
     3        1.2797             nan     0.0100    0.0038
     4        1.2702             nan     0.0100    0.0041
     5        1.2618             nan     0.0100    0.0035
     6        1.2529             nan     0.0100    0.0035
     7        1.2443             nan     0.0100    0.0035
     8        1.2355             nan     0.0100    0.0036
     9        1.2272             nan     0.0100    0.0034
    10        1.2191             nan     0.0100    0.0032
    20        1.1433             nan     0.0100    0.0027
    40        1.0241             nan     0.0100    0.0020
    60        0.9338             nan     0.0100    0.0012
    80        0.8628             nan     0.0100    0.0013
   100        0.8046             nan     0.0100    0.0005
   120        0.7567             nan     0.0100    0.0005
   140        0.7179             nan     0.0100    0.0005
   160        0.6856             nan     0.0100    0.0004
   180        0.6567             nan     0.0100    0.0000
   200        0.6321             nan     0.0100    0.0002
   220        0.6093             nan     0.0100    0.0000
   240        0.5869             nan     0.0100    0.0002
   260        0.5684             nan     0.0100    0.0001
   280        0.5507             nan     0.0100   -0.0000
   300        0.5345             nan     0.0100    0.0000

- Fold06.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2908             nan     0.0200    0.0079
     2        1.2760             nan     0.0200    0.0071
     3        1.2621             nan     0.0200    0.0065
     4        1.2492             nan     0.0200    0.0060
     5        1.2338             nan     0.0200    0.0059
     6        1.2202             nan     0.0200    0.0060
     7        1.2075             nan     0.0200    0.0057
     8        1.1959             nan     0.0200    0.0057
     9        1.1843             nan     0.0200    0.0052
    10        1.1729             nan     0.0200    0.0049
    20        1.0824             nan     0.0200    0.0038
    40        0.9544             nan     0.0200    0.0017
    60        0.8745             nan     0.0200    0.0011
    80        0.8190             nan     0.0200    0.0008
   100        0.7781             nan     0.0200    0.0003
   120        0.7467             nan     0.0200    0.0001
   140        0.7209             nan     0.0200    0.0001
   160        0.7011             nan     0.0200    0.0000
   180        0.6853             nan     0.0200    0.0001
   200        0.6687             nan     0.0200    0.0000
   220        0.6536             nan     0.0200   -0.0002
   240        0.6405             nan     0.0200   -0.0001
   260        0.6291             nan     0.0200   -0.0001
   280        0.6178             nan     0.0200   -0.0000
   300        0.6079             nan     0.0200   -0.0003

- Fold06.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2892             nan     0.0200    0.0069
     2        1.2709             nan     0.0200    0.0082
     3        1.2541             nan     0.0200    0.0074
     4        1.2386             nan     0.0200    0.0068
     5        1.2223             nan     0.0200    0.0075
     6        1.2083             nan     0.0200    0.0056
     7        1.1933             nan     0.0200    0.0066
     8        1.1799             nan     0.0200    0.0059
     9        1.1657             nan     0.0200    0.0063
    10        1.1535             nan     0.0200    0.0056
    20        1.0442             nan     0.0200    0.0038
    40        0.8918             nan     0.0200    0.0027
    60        0.7978             nan     0.0200    0.0005
    80        0.7312             nan     0.0200    0.0008
   100        0.6811             nan     0.0200    0.0002
   120        0.6455             nan     0.0200    0.0002
   140        0.6183             nan     0.0200    0.0002
   160        0.5929             nan     0.0200   -0.0003
   180        0.5702             nan     0.0200   -0.0002
   200        0.5493             nan     0.0200   -0.0001
   220        0.5294             nan     0.0200   -0.0002
   240        0.5107             nan     0.0200   -0.0003
   260        0.4929             nan     0.0200   -0.0002
   280        0.4748             nan     0.0200   -0.0001
   300        0.4594             nan     0.0200   -0.0004

- Fold06.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold06.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2876             nan     0.0200    0.0087
     2        1.2702             nan     0.0200    0.0079
     3        1.2518             nan     0.0200    0.0074
     4        1.2334             nan     0.0200    0.0081
     5        1.2176             nan     0.0200    0.0076
     6        1.2030             nan     0.0200    0.0063
     7        1.1879             nan     0.0200    0.0064
     8        1.1718             nan     0.0200    0.0068
     9        1.1558             nan     0.0200    0.0064
    10        1.1411             nan     0.0200    0.0061
    20        1.0219             nan     0.0200    0.0041
    40        0.8614             nan     0.0200    0.0021
    60        0.7610             nan     0.0200    0.0006
    80        0.6906             nan     0.0200    0.0007
   100        0.6343             nan     0.0200    0.0005
   120        0.5925             nan     0.0200    0.0001
   140        0.5569             nan     0.0200    0.0001
   160        0.5243             nan     0.0200   -0.0002
   180        0.4948             nan     0.0200   -0.0000
   200        0.4700             nan     0.0200   -0.0002
   220        0.4459             nan     0.0200   -0.0003
   240        0.4224             nan     0.0200   -0.0003
   260        0.4028             nan     0.0200   -0.0001
   280        0.3842             nan     0.0200   -0.0002
   300        0.3674             nan     0.0200   -0.0001

- Fold06.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3059             nan     0.0010    0.0003
     2        1.3052             nan     0.0010    0.0004
     3        1.3044             nan     0.0010    0.0003
     4        1.3036             nan     0.0010    0.0003
     5        1.3029             nan     0.0010    0.0003
     6        1.3020             nan     0.0010    0.0004
     7        1.3013             nan     0.0010    0.0004
     8        1.3006             nan     0.0010    0.0003
     9        1.2998             nan     0.0010    0.0003
    10        1.2990             nan     0.0010    0.0003
    20        1.2915             nan     0.0010    0.0003
    40        1.2774             nan     0.0010    0.0003
    60        1.2638             nan     0.0010    0.0003
    80        1.2504             nan     0.0010    0.0003
   100        1.2375             nan     0.0010    0.0003
   120        1.2251             nan     0.0010    0.0003
   140        1.2131             nan     0.0010    0.0003
   160        1.2013             nan     0.0010    0.0003
   180        1.1901             nan     0.0010    0.0003
   200        1.1792             nan     0.0010    0.0003
   220        1.1690             nan     0.0010    0.0002
   240        1.1587             nan     0.0010    0.0002
   260        1.1489             nan     0.0010    0.0002
   280        1.1394             nan     0.0010    0.0002
   300        1.1299             nan     0.0010    0.0002

- Fold07.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3058             nan     0.0010    0.0004
     2        1.3049             nan     0.0010    0.0004
     3        1.3041             nan     0.0010    0.0004
     4        1.3031             nan     0.0010    0.0004
     5        1.3022             nan     0.0010    0.0004
     6        1.3014             nan     0.0010    0.0004
     7        1.3007             nan     0.0010    0.0003
     8        1.2997             nan     0.0010    0.0004
     9        1.2989             nan     0.0010    0.0004
    10        1.2980             nan     0.0010    0.0004
    20        1.2898             nan     0.0010    0.0004
    40        1.2732             nan     0.0010    0.0004
    60        1.2571             nan     0.0010    0.0004
    80        1.2421             nan     0.0010    0.0003
   100        1.2274             nan     0.0010    0.0003
   120        1.2132             nan     0.0010    0.0003
   140        1.1996             nan     0.0010    0.0003
   160        1.1861             nan     0.0010    0.0003
   180        1.1731             nan     0.0010    0.0003
   200        1.1608             nan     0.0010    0.0003
   220        1.1486             nan     0.0010    0.0002
   240        1.1375             nan     0.0010    0.0002
   260        1.1262             nan     0.0010    0.0002
   280        1.1152             nan     0.0010    0.0002
   300        1.1046             nan     0.0010    0.0002

- Fold07.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3057             nan     0.0010    0.0004
     2        1.3048             nan     0.0010    0.0004
     3        1.3039             nan     0.0010    0.0004
     4        1.3029             nan     0.0010    0.0004
     5        1.3020             nan     0.0010    0.0004
     6        1.3012             nan     0.0010    0.0004
     7        1.3003             nan     0.0010    0.0004
     8        1.2994             nan     0.0010    0.0004
     9        1.2985             nan     0.0010    0.0004
    10        1.2975             nan     0.0010    0.0004
    20        1.2883             nan     0.0010    0.0004
    40        1.2705             nan     0.0010    0.0004
    60        1.2535             nan     0.0010    0.0004
    80        1.2372             nan     0.0010    0.0003
   100        1.2213             nan     0.0010    0.0003
   120        1.2064             nan     0.0010    0.0003
   140        1.1918             nan     0.0010    0.0003
   160        1.1776             nan     0.0010    0.0003
   180        1.1634             nan     0.0010    0.0003
   200        1.1497             nan     0.0010    0.0003
   220        1.1368             nan     0.0010    0.0002
   240        1.1239             nan     0.0010    0.0003
   260        1.1114             nan     0.0010    0.0002
   280        1.0995             nan     0.0010    0.0003
   300        1.0881             nan     0.0010    0.0002

- Fold07.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2993             nan     0.0100    0.0034
     2        1.2920             nan     0.0100    0.0035
     3        1.2857             nan     0.0100    0.0031
     4        1.2791             nan     0.0100    0.0034
     5        1.2724             nan     0.0100    0.0032
     6        1.2661             nan     0.0100    0.0031
     7        1.2602             nan     0.0100    0.0027
     8        1.2534             nan     0.0100    0.0032
     9        1.2478             nan     0.0100    0.0029
    10        1.2406             nan     0.0100    0.0034
    20        1.1813             nan     0.0100    0.0024
    40        1.0890             nan     0.0100    0.0020
    60        1.0192             nan     0.0100    0.0013
    80        0.9659             nan     0.0100    0.0013
   100        0.9222             nan     0.0100    0.0006
   120        0.8890             nan     0.0100    0.0006
   140        0.8606             nan     0.0100    0.0005
   160        0.8361             nan     0.0100    0.0002
   180        0.8158             nan     0.0100    0.0001
   200        0.7995             nan     0.0100    0.0001
   220        0.7846             nan     0.0100    0.0001
   240        0.7714             nan     0.0100    0.0001
   260        0.7587             nan     0.0100    0.0001
   280        0.7476             nan     0.0100   -0.0000
   300        0.7383             nan     0.0100    0.0001

- Fold07.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2980             nan     0.0100    0.0037
     2        1.2889             nan     0.0100    0.0040
     3        1.2806             nan     0.0100    0.0039
     4        1.2726             nan     0.0100    0.0032
     5        1.2652             nan     0.0100    0.0031
     6        1.2573             nan     0.0100    0.0035
     7        1.2496             nan     0.0100    0.0034
     8        1.2422             nan     0.0100    0.0034
     9        1.2347             nan     0.0100    0.0034
    10        1.2277             nan     0.0100    0.0031
    20        1.1612             nan     0.0100    0.0023
    40        1.0544             nan     0.0100    0.0019
    60        0.9746             nan     0.0100    0.0013
    80        0.9137             nan     0.0100    0.0011
   100        0.8631             nan     0.0100    0.0006
   120        0.8225             nan     0.0100    0.0004
   140        0.7897             nan     0.0100    0.0005
   160        0.7625             nan     0.0100    0.0003
   180        0.7369             nan     0.0100    0.0001
   200        0.7140             nan     0.0100    0.0002
   220        0.6952             nan     0.0100    0.0000
   240        0.6774             nan     0.0100    0.0000
   260        0.6616             nan     0.0100    0.0001
   280        0.6468             nan     0.0100    0.0001
   300        0.6338             nan     0.0100    0.0001

- Fold07.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2977             nan     0.0100    0.0037
     2        1.2891             nan     0.0100    0.0038
     3        1.2804             nan     0.0100    0.0034
     4        1.2718             nan     0.0100    0.0038
     5        1.2634             nan     0.0100    0.0038
     6        1.2556             nan     0.0100    0.0034
     7        1.2468             nan     0.0100    0.0037
     8        1.2384             nan     0.0100    0.0038
     9        1.2311             nan     0.0100    0.0031
    10        1.2228             nan     0.0100    0.0036
    20        1.1521             nan     0.0100    0.0028
    40        1.0376             nan     0.0100    0.0022
    60        0.9491             nan     0.0100    0.0016
    80        0.8809             nan     0.0100    0.0009
   100        0.8255             nan     0.0100    0.0008
   120        0.7800             nan     0.0100    0.0003
   140        0.7413             nan     0.0100    0.0006
   160        0.7084             nan     0.0100    0.0004
   180        0.6809             nan     0.0100   -0.0000
   200        0.6548             nan     0.0100    0.0002
   220        0.6310             nan     0.0100    0.0001
   240        0.6087             nan     0.0100   -0.0001
   260        0.5892             nan     0.0100    0.0000
   280        0.5716             nan     0.0100   -0.0001
   300        0.5559             nan     0.0100    0.0000

- Fold07.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2901             nan     0.0200    0.0069
     2        1.2763             nan     0.0200    0.0066
     3        1.2623             nan     0.0200    0.0062
     4        1.2493             nan     0.0200    0.0059
     5        1.2365             nan     0.0200    0.0055
     6        1.2236             nan     0.0200    0.0058
     7        1.2117             nan     0.0200    0.0054
     8        1.2007             nan     0.0200    0.0056
     9        1.1891             nan     0.0200    0.0054
    10        1.1780             nan     0.0200    0.0052
    20        1.0869             nan     0.0200    0.0030
    40        0.9646             nan     0.0200    0.0018
    60        0.8876             nan     0.0200    0.0013
    80        0.8377             nan     0.0200    0.0005
   100        0.7994             nan     0.0200    0.0003
   120        0.7718             nan     0.0200    0.0003
   140        0.7498             nan     0.0200    0.0002
   160        0.7289             nan     0.0200   -0.0001
   180        0.7115             nan     0.0200   -0.0001
   200        0.6954             nan     0.0200    0.0000
   220        0.6815             nan     0.0200   -0.0001
   240        0.6692             nan     0.0200   -0.0001
   260        0.6571             nan     0.0200   -0.0001
   280        0.6456             nan     0.0200    0.0000
   300        0.6329             nan     0.0200   -0.0001

- Fold07.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2899             nan     0.0200    0.0064
     2        1.2731             nan     0.0200    0.0079
     3        1.2567             nan     0.0200    0.0074
     4        1.2421             nan     0.0200    0.0063
     5        1.2276             nan     0.0200    0.0055
     6        1.2148             nan     0.0200    0.0063
     7        1.2009             nan     0.0200    0.0060
     8        1.1871             nan     0.0200    0.0058
     9        1.1745             nan     0.0200    0.0055
    10        1.1614             nan     0.0200    0.0061
    20        1.0553             nan     0.0200    0.0049
    40        0.9134             nan     0.0200    0.0016
    60        0.8215             nan     0.0200    0.0008
    80        0.7610             nan     0.0200    0.0011
   100        0.7146             nan     0.0200    0.0002
   120        0.6777             nan     0.0200    0.0002
   140        0.6468             nan     0.0200   -0.0000
   160        0.6203             nan     0.0200    0.0000
   180        0.5966             nan     0.0200   -0.0002
   200        0.5745             nan     0.0200   -0.0002
   220        0.5540             nan     0.0200    0.0000
   240        0.5365             nan     0.0200   -0.0002
   260        0.5173             nan     0.0200   -0.0004
   280        0.5018             nan     0.0200   -0.0005
   300        0.4862             nan     0.0200   -0.0002

- Fold07.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold07.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2882             nan     0.0200    0.0080
     2        1.2709             nan     0.0200    0.0078
     3        1.2538             nan     0.0200    0.0075
     4        1.2373             nan     0.0200    0.0065
     5        1.2202             nan     0.0200    0.0073
     6        1.2067             nan     0.0200    0.0053
     7        1.1921             nan     0.0200    0.0065
     8        1.1776             nan     0.0200    0.0062
     9        1.1643             nan     0.0200    0.0057
    10        1.1510             nan     0.0200    0.0054
    20        1.0356             nan     0.0200    0.0038
    40        0.8778             nan     0.0200    0.0020
    60        0.7796             nan     0.0200    0.0012
    80        0.7116             nan     0.0200    0.0005
   100        0.6574             nan     0.0200    0.0003
   120        0.6158             nan     0.0200   -0.0001
   140        0.5767             nan     0.0200   -0.0000
   160        0.5459             nan     0.0200   -0.0000
   180        0.5174             nan     0.0200   -0.0002
   200        0.4918             nan     0.0200   -0.0002
   220        0.4682             nan     0.0200   -0.0004
   240        0.4445             nan     0.0200    0.0001
   260        0.4241             nan     0.0200   -0.0001
   280        0.4041             nan     0.0200   -0.0002
   300        0.3851             nan     0.0200   -0.0003

- Fold07.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3053             nan     0.0010    0.0003
     2        1.3045             nan     0.0010    0.0004
     3        1.3037             nan     0.0010    0.0004
     4        1.3030             nan     0.0010    0.0003
     5        1.3022             nan     0.0010    0.0003
     6        1.3015             nan     0.0010    0.0004
     7        1.3009             nan     0.0010    0.0003
     8        1.3001             nan     0.0010    0.0004
     9        1.2993             nan     0.0010    0.0003
    10        1.2986             nan     0.0010    0.0003
    20        1.2911             nan     0.0010    0.0003
    40        1.2769             nan     0.0010    0.0003
    60        1.2631             nan     0.0010    0.0003
    80        1.2496             nan     0.0010    0.0003
   100        1.2365             nan     0.0010    0.0003
   120        1.2242             nan     0.0010    0.0003
   140        1.2119             nan     0.0010    0.0003
   160        1.2002             nan     0.0010    0.0003
   180        1.1890             nan     0.0010    0.0003
   200        1.1775             nan     0.0010    0.0002
   220        1.1669             nan     0.0010    0.0003
   240        1.1566             nan     0.0010    0.0002
   260        1.1466             nan     0.0010    0.0002
   280        1.1371             nan     0.0010    0.0002
   300        1.1278             nan     0.0010    0.0002

- Fold08.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3052             nan     0.0010    0.0004
     2        1.3043             nan     0.0010    0.0004
     3        1.3034             nan     0.0010    0.0003
     4        1.3025             nan     0.0010    0.0004
     5        1.3017             nan     0.0010    0.0004
     6        1.3008             nan     0.0010    0.0004
     7        1.3000             nan     0.0010    0.0004
     8        1.2992             nan     0.0010    0.0004
     9        1.2984             nan     0.0010    0.0004
    10        1.2975             nan     0.0010    0.0004
    20        1.2892             nan     0.0010    0.0004
    40        1.2727             nan     0.0010    0.0003
    60        1.2568             nan     0.0010    0.0004
    80        1.2412             nan     0.0010    0.0004
   100        1.2262             nan     0.0010    0.0003
   120        1.2119             nan     0.0010    0.0003
   140        1.1983             nan     0.0010    0.0003
   160        1.1849             nan     0.0010    0.0003
   180        1.1720             nan     0.0010    0.0003
   200        1.1594             nan     0.0010    0.0002
   220        1.1474             nan     0.0010    0.0003
   240        1.1359             nan     0.0010    0.0002
   260        1.1244             nan     0.0010    0.0002
   280        1.1133             nan     0.0010    0.0002
   300        1.1025             nan     0.0010    0.0003

- Fold08.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3051             nan     0.0010    0.0004
     2        1.3041             nan     0.0010    0.0004
     3        1.3032             nan     0.0010    0.0004
     4        1.3022             nan     0.0010    0.0004
     5        1.3011             nan     0.0010    0.0005
     6        1.3002             nan     0.0010    0.0004
     7        1.2992             nan     0.0010    0.0004
     8        1.2981             nan     0.0010    0.0004
     9        1.2972             nan     0.0010    0.0004
    10        1.2963             nan     0.0010    0.0004
    20        1.2873             nan     0.0010    0.0004
    40        1.2696             nan     0.0010    0.0003
    60        1.2521             nan     0.0010    0.0004
    80        1.2356             nan     0.0010    0.0003
   100        1.2196             nan     0.0010    0.0003
   120        1.2042             nan     0.0010    0.0003
   140        1.1894             nan     0.0010    0.0003
   160        1.1747             nan     0.0010    0.0003
   180        1.1607             nan     0.0010    0.0003
   200        1.1471             nan     0.0010    0.0004
   220        1.1338             nan     0.0010    0.0003
   240        1.1212             nan     0.0010    0.0003
   260        1.1089             nan     0.0010    0.0002
   280        1.0964             nan     0.0010    0.0002
   300        1.0847             nan     0.0010    0.0002

- Fold08.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2978             nan     0.0100    0.0034
     2        1.2905             nan     0.0100    0.0034
     3        1.2837             nan     0.0100    0.0036
     4        1.2766             nan     0.0100    0.0032
     5        1.2703             nan     0.0100    0.0030
     6        1.2639             nan     0.0100    0.0029
     7        1.2566             nan     0.0100    0.0032
     8        1.2493             nan     0.0100    0.0034
     9        1.2428             nan     0.0100    0.0030
    10        1.2366             nan     0.0100    0.0029
    20        1.1760             nan     0.0100    0.0021
    40        1.0839             nan     0.0100    0.0017
    60        1.0134             nan     0.0100    0.0014
    80        0.9603             nan     0.0100    0.0009
   100        0.9183             nan     0.0100    0.0007
   120        0.8843             nan     0.0100    0.0005
   140        0.8571             nan     0.0100    0.0005
   160        0.8334             nan     0.0100    0.0005
   180        0.8116             nan     0.0100    0.0003
   200        0.7946             nan     0.0100    0.0001
   220        0.7798             nan     0.0100    0.0001
   240        0.7646             nan     0.0100    0.0000
   260        0.7520             nan     0.0100    0.0001
   280        0.7400             nan     0.0100   -0.0000
   300        0.7299             nan     0.0100    0.0000

- Fold08.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2973             nan     0.0100    0.0038
     2        1.2891             nan     0.0100    0.0038
     3        1.2811             nan     0.0100    0.0033
     4        1.2724             nan     0.0100    0.0037
     5        1.2645             nan     0.0100    0.0032
     6        1.2572             nan     0.0100    0.0032
     7        1.2491             nan     0.0100    0.0032
     8        1.2414             nan     0.0100    0.0035
     9        1.2343             nan     0.0100    0.0033
    10        1.2268             nan     0.0100    0.0032
    20        1.1587             nan     0.0100    0.0027
    40        1.0523             nan     0.0100    0.0023
    60        0.9695             nan     0.0100    0.0013
    80        0.9071             nan     0.0100    0.0011
   100        0.8562             nan     0.0100    0.0009
   120        0.8160             nan     0.0100    0.0004
   140        0.7821             nan     0.0100    0.0004
   160        0.7535             nan     0.0100    0.0005
   180        0.7294             nan     0.0100    0.0001
   200        0.7071             nan     0.0100    0.0003
   220        0.6886             nan     0.0100    0.0001
   240        0.6714             nan     0.0100    0.0000
   260        0.6550             nan     0.0100    0.0002
   280        0.6416             nan     0.0100    0.0001
   300        0.6286             nan     0.0100   -0.0001

- Fold08.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2969             nan     0.0100    0.0037
     2        1.2880             nan     0.0100    0.0039
     3        1.2791             nan     0.0100    0.0036
     4        1.2697             nan     0.0100    0.0038
     5        1.2606             nan     0.0100    0.0040
     6        1.2526             nan     0.0100    0.0034
     7        1.2440             nan     0.0100    0.0037
     8        1.2362             nan     0.0100    0.0039
     9        1.2285             nan     0.0100    0.0031
    10        1.2200             nan     0.0100    0.0035
    20        1.1468             nan     0.0100    0.0029
    40        1.0292             nan     0.0100    0.0020
    60        0.9438             nan     0.0100    0.0015
    80        0.8733             nan     0.0100    0.0012
   100        0.8186             nan     0.0100    0.0008
   120        0.7740             nan     0.0100    0.0007
   140        0.7350             nan     0.0100    0.0003
   160        0.7015             nan     0.0100    0.0002
   180        0.6725             nan     0.0100    0.0001
   200        0.6469             nan     0.0100    0.0002
   220        0.6245             nan     0.0100   -0.0000
   240        0.6029             nan     0.0100    0.0001
   260        0.5847             nan     0.0100    0.0000
   280        0.5684             nan     0.0100   -0.0000
   300        0.5510             nan     0.0100    0.0001

- Fold08.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2924             nan     0.0200    0.0051
     2        1.2767             nan     0.0200    0.0070
     3        1.2630             nan     0.0200    0.0066
     4        1.2490             nan     0.0200    0.0063
     5        1.2363             nan     0.0200    0.0058
     6        1.2238             nan     0.0200    0.0065
     7        1.2121             nan     0.0200    0.0054
     8        1.2007             nan     0.0200    0.0053
     9        1.1894             nan     0.0200    0.0052
    10        1.1787             nan     0.0200    0.0055
    20        1.0845             nan     0.0200    0.0031
    40        0.9578             nan     0.0200    0.0015
    60        0.8791             nan     0.0200    0.0011
    80        0.8283             nan     0.0200    0.0004
   100        0.7892             nan     0.0200    0.0003
   120        0.7618             nan     0.0200    0.0004
   140        0.7370             nan     0.0200   -0.0001
   160        0.7182             nan     0.0200   -0.0002
   180        0.7022             nan     0.0200   -0.0002
   200        0.6865             nan     0.0200    0.0001
   220        0.6733             nan     0.0200   -0.0001
   240        0.6614             nan     0.0200   -0.0003
   260        0.6488             nan     0.0200   -0.0002
   280        0.6373             nan     0.0200   -0.0003
   300        0.6276             nan     0.0200   -0.0003

- Fold08.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2889             nan     0.0200    0.0076
     2        1.2706             nan     0.0200    0.0078
     3        1.2548             nan     0.0200    0.0073
     4        1.2399             nan     0.0200    0.0064
     5        1.2237             nan     0.0200    0.0073
     6        1.2098             nan     0.0200    0.0055
     7        1.1961             nan     0.0200    0.0068
     8        1.1831             nan     0.0200    0.0054
     9        1.1708             nan     0.0200    0.0049
    10        1.1586             nan     0.0200    0.0055
    20        1.0507             nan     0.0200    0.0041
    40        0.9066             nan     0.0200    0.0026
    60        0.8165             nan     0.0200    0.0008
    80        0.7563             nan     0.0200    0.0009
   100        0.7071             nan     0.0200    0.0005
   120        0.6685             nan     0.0200    0.0004
   140        0.6388             nan     0.0200   -0.0002
   160        0.6119             nan     0.0200    0.0001
   180        0.5907             nan     0.0200   -0.0002
   200        0.5705             nan     0.0200   -0.0002
   220        0.5499             nan     0.0200    0.0002
   240        0.5312             nan     0.0200    0.0002
   260        0.5131             nan     0.0200   -0.0001
   280        0.4965             nan     0.0200   -0.0003
   300        0.4815             nan     0.0200   -0.0000

- Fold08.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold08.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2875             nan     0.0200    0.0076
     2        1.2677             nan     0.0200    0.0082
     3        1.2508             nan     0.0200    0.0066
     4        1.2359             nan     0.0200    0.0066
     5        1.2204             nan     0.0200    0.0072
     6        1.2032             nan     0.0200    0.0075
     7        1.1871             nan     0.0200    0.0076
     8        1.1711             nan     0.0200    0.0070
     9        1.1562             nan     0.0200    0.0064
    10        1.1434             nan     0.0200    0.0047
    20        1.0240             nan     0.0200    0.0046
    40        0.8663             nan     0.0200    0.0023
    60        0.7700             nan     0.0200    0.0010
    80        0.6996             nan     0.0200    0.0008
   100        0.6473             nan     0.0200    0.0004
   120        0.6046             nan     0.0200    0.0001
   140        0.5704             nan     0.0200   -0.0003
   160        0.5385             nan     0.0200   -0.0003
   180        0.5101             nan     0.0200   -0.0005
   200        0.4848             nan     0.0200   -0.0001
   220        0.4619             nan     0.0200   -0.0005
   240        0.4392             nan     0.0200   -0.0003
   260        0.4191             nan     0.0200   -0.0002
   280        0.4002             nan     0.0200   -0.0003
   300        0.3822             nan     0.0200   -0.0003

- Fold08.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3058             nan     0.0010    0.0004
     2        1.3051             nan     0.0010    0.0004
     3        1.3043             nan     0.0010    0.0004
     4        1.3035             nan     0.0010    0.0003
     5        1.3029             nan     0.0010    0.0003
     6        1.3022             nan     0.0010    0.0003
     7        1.3014             nan     0.0010    0.0003
     8        1.3007             nan     0.0010    0.0003
     9        1.3000             nan     0.0010    0.0004
    10        1.2992             nan     0.0010    0.0003
    20        1.2915             nan     0.0010    0.0003
    40        1.2772             nan     0.0010    0.0003
    60        1.2631             nan     0.0010    0.0003
    80        1.2493             nan     0.0010    0.0003
   100        1.2360             nan     0.0010    0.0003
   120        1.2231             nan     0.0010    0.0003
   140        1.2109             nan     0.0010    0.0003
   160        1.1990             nan     0.0010    0.0002
   180        1.1876             nan     0.0010    0.0003
   200        1.1763             nan     0.0010    0.0003
   220        1.1656             nan     0.0010    0.0002
   240        1.1552             nan     0.0010    0.0002
   260        1.1451             nan     0.0010    0.0002
   280        1.1354             nan     0.0010    0.0002
   300        1.1257             nan     0.0010    0.0002

- Fold09.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3057             nan     0.0010    0.0004
     2        1.3048             nan     0.0010    0.0004
     3        1.3040             nan     0.0010    0.0004
     4        1.3031             nan     0.0010    0.0004
     5        1.3021             nan     0.0010    0.0004
     6        1.3012             nan     0.0010    0.0004
     7        1.3002             nan     0.0010    0.0004
     8        1.2994             nan     0.0010    0.0004
     9        1.2986             nan     0.0010    0.0004
    10        1.2977             nan     0.0010    0.0004
    20        1.2892             nan     0.0010    0.0004
    40        1.2726             nan     0.0010    0.0004
    60        1.2566             nan     0.0010    0.0003
    80        1.2410             nan     0.0010    0.0004
   100        1.2258             nan     0.0010    0.0003
   120        1.2113             nan     0.0010    0.0003
   140        1.1970             nan     0.0010    0.0003
   160        1.1836             nan     0.0010    0.0003
   180        1.1702             nan     0.0010    0.0003
   200        1.1578             nan     0.0010    0.0003
   220        1.1453             nan     0.0010    0.0003
   240        1.1335             nan     0.0010    0.0003
   260        1.1218             nan     0.0010    0.0003
   280        1.1104             nan     0.0010    0.0002
   300        1.0996             nan     0.0010    0.0002

- Fold09.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3057             nan     0.0010    0.0004
     2        1.3048             nan     0.0010    0.0004
     3        1.3039             nan     0.0010    0.0004
     4        1.3030             nan     0.0010    0.0004
     5        1.3021             nan     0.0010    0.0004
     6        1.3011             nan     0.0010    0.0004
     7        1.3001             nan     0.0010    0.0005
     8        1.2991             nan     0.0010    0.0004
     9        1.2981             nan     0.0010    0.0004
    10        1.2972             nan     0.0010    0.0005
    20        1.2879             nan     0.0010    0.0004
    40        1.2697             nan     0.0010    0.0004
    60        1.2525             nan     0.0010    0.0004
    80        1.2358             nan     0.0010    0.0003
   100        1.2193             nan     0.0010    0.0004
   120        1.2035             nan     0.0010    0.0003
   140        1.1885             nan     0.0010    0.0003
   160        1.1739             nan     0.0010    0.0003
   180        1.1595             nan     0.0010    0.0003
   200        1.1458             nan     0.0010    0.0003
   220        1.1324             nan     0.0010    0.0003
   240        1.1194             nan     0.0010    0.0003
   260        1.1068             nan     0.0010    0.0003
   280        1.0945             nan     0.0010    0.0003
   300        1.0829             nan     0.0010    0.0002

- Fold09.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2991             nan     0.0100    0.0033
     2        1.2921             nan     0.0100    0.0033
     3        1.2849             nan     0.0100    0.0033
     4        1.2778             nan     0.0100    0.0032
     5        1.2714             nan     0.0100    0.0034
     6        1.2642             nan     0.0100    0.0033
     7        1.2579             nan     0.0100    0.0028
     8        1.2513             nan     0.0100    0.0028
     9        1.2447             nan     0.0100    0.0028
    10        1.2377             nan     0.0100    0.0031
    20        1.1765             nan     0.0100    0.0023
    40        1.0816             nan     0.0100    0.0018
    60        1.0137             nan     0.0100    0.0014
    80        0.9581             nan     0.0100    0.0011
   100        0.9144             nan     0.0100    0.0007
   120        0.8771             nan     0.0100    0.0006
   140        0.8478             nan     0.0100    0.0006
   160        0.8232             nan     0.0100    0.0004
   180        0.8019             nan     0.0100    0.0002
   200        0.7840             nan     0.0100    0.0001
   220        0.7686             nan     0.0100    0.0000
   240        0.7542             nan     0.0100    0.0001
   260        0.7411             nan     0.0100    0.0003
   280        0.7289             nan     0.0100    0.0001
   300        0.7182             nan     0.0100   -0.0000

- Fold09.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2985             nan     0.0100    0.0038
     2        1.2900             nan     0.0100    0.0038
     3        1.2816             nan     0.0100    0.0040
     4        1.2735             nan     0.0100    0.0033
     5        1.2656             nan     0.0100    0.0035
     6        1.2577             nan     0.0100    0.0038
     7        1.2501             nan     0.0100    0.0035
     8        1.2426             nan     0.0100    0.0034
     9        1.2352             nan     0.0100    0.0034
    10        1.2272             nan     0.0100    0.0037
    20        1.1590             nan     0.0100    0.0027
    40        1.0485             nan     0.0100    0.0019
    60        0.9677             nan     0.0100    0.0018
    80        0.9031             nan     0.0100    0.0007
   100        0.8508             nan     0.0100    0.0011
   120        0.8104             nan     0.0100    0.0006
   140        0.7769             nan     0.0100    0.0005
   160        0.7464             nan     0.0100    0.0004
   180        0.7212             nan     0.0100    0.0003
   200        0.6988             nan     0.0100    0.0001
   220        0.6778             nan     0.0100    0.0000
   240        0.6597             nan     0.0100    0.0000
   260        0.6429             nan     0.0100    0.0000
   280        0.6275             nan     0.0100    0.0000
   300        0.6140             nan     0.0100    0.0000

- Fold09.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2974             nan     0.0100    0.0038
     2        1.2881             nan     0.0100    0.0042
     3        1.2790             nan     0.0100    0.0041
     4        1.2703             nan     0.0100    0.0037
     5        1.2617             nan     0.0100    0.0040
     6        1.2537             nan     0.0100    0.0037
     7        1.2450             nan     0.0100    0.0036
     8        1.2373             nan     0.0100    0.0037
     9        1.2288             nan     0.0100    0.0035
    10        1.2207             nan     0.0100    0.0035
    20        1.1460             nan     0.0100    0.0028
    40        1.0271             nan     0.0100    0.0021
    60        0.9373             nan     0.0100    0.0014
    80        0.8660             nan     0.0100    0.0011
   100        0.8085             nan     0.0100    0.0005
   120        0.7633             nan     0.0100    0.0007
   140        0.7252             nan     0.0100    0.0005
   160        0.6913             nan     0.0100    0.0003
   180        0.6611             nan     0.0100    0.0002
   200        0.6350             nan     0.0100    0.0002
   220        0.6117             nan     0.0100   -0.0001
   240        0.5898             nan     0.0100    0.0000
   260        0.5715             nan     0.0100    0.0000
   280        0.5536             nan     0.0100   -0.0001
   300        0.5365             nan     0.0100   -0.0003

- Fold09.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2924             nan     0.0200    0.0070
     2        1.2780             nan     0.0200    0.0065
     3        1.2638             nan     0.0200    0.0066
     4        1.2487             nan     0.0200    0.0066
     5        1.2348             nan     0.0200    0.0064
     6        1.2217             nan     0.0200    0.0057
     7        1.2094             nan     0.0200    0.0056
     8        1.1965             nan     0.0200    0.0057
     9        1.1848             nan     0.0200    0.0055
    10        1.1741             nan     0.0200    0.0051
    20        1.0797             nan     0.0200    0.0035
    40        0.9565             nan     0.0200    0.0016
    60        0.8821             nan     0.0200    0.0009
    80        0.8277             nan     0.0200    0.0005
   100        0.7888             nan     0.0200    0.0003
   120        0.7583             nan     0.0200    0.0001
   140        0.7320             nan     0.0200    0.0000
   160        0.7104             nan     0.0200    0.0001
   180        0.6920             nan     0.0200   -0.0006
   200        0.6752             nan     0.0200   -0.0001
   220        0.6598             nan     0.0200    0.0000
   240        0.6456             nan     0.0200   -0.0003
   260        0.6328             nan     0.0200   -0.0000
   280        0.6200             nan     0.0200   -0.0001
   300        0.6084             nan     0.0200   -0.0003

- Fold09.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2899             nan     0.0200    0.0076
     2        1.2732             nan     0.0200    0.0070
     3        1.2584             nan     0.0200    0.0069
     4        1.2424             nan     0.0200    0.0066
     5        1.2283             nan     0.0200    0.0061
     6        1.2129             nan     0.0200    0.0075
     7        1.1995             nan     0.0200    0.0061
     8        1.1874             nan     0.0200    0.0053
     9        1.1741             nan     0.0200    0.0053
    10        1.1608             nan     0.0200    0.0056
    20        1.0493             nan     0.0200    0.0037
    40        0.9052             nan     0.0200    0.0023
    60        0.8117             nan     0.0200    0.0007
    80        0.7430             nan     0.0200    0.0007
   100        0.6944             nan     0.0200    0.0004
   120        0.6585             nan     0.0200    0.0003
   140        0.6259             nan     0.0200    0.0001
   160        0.5981             nan     0.0200    0.0002
   180        0.5745             nan     0.0200    0.0001
   200        0.5518             nan     0.0200   -0.0003
   220        0.5314             nan     0.0200   -0.0000
   240        0.5115             nan     0.0200   -0.0002
   260        0.4937             nan     0.0200    0.0004
   280        0.4764             nan     0.0200    0.0003
   300        0.4613             nan     0.0200   -0.0001

- Fold09.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold09.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2876             nan     0.0200    0.0083
     2        1.2685             nan     0.0200    0.0084
     3        1.2499             nan     0.0200    0.0082
     4        1.2313             nan     0.0200    0.0078
     5        1.2150             nan     0.0200    0.0067
     6        1.1996             nan     0.0200    0.0060
     7        1.1851             nan     0.0200    0.0063
     8        1.1711             nan     0.0200    0.0063
     9        1.1560             nan     0.0200    0.0062
    10        1.1429             nan     0.0200    0.0056
    20        1.0277             nan     0.0200    0.0037
    40        0.8678             nan     0.0200    0.0020
    60        0.7657             nan     0.0200    0.0009
    80        0.6917             nan     0.0200    0.0010
   100        0.6367             nan     0.0200    0.0001
   120        0.5911             nan     0.0200    0.0004
   140        0.5562             nan     0.0200   -0.0003
   160        0.5237             nan     0.0200   -0.0002
   180        0.4943             nan     0.0200   -0.0004
   200        0.4661             nan     0.0200   -0.0001
   220        0.4428             nan     0.0200   -0.0003
   240        0.4188             nan     0.0200   -0.0003
   260        0.3972             nan     0.0200   -0.0003
   280        0.3793             nan     0.0200    0.0001
   300        0.3608             nan     0.0200   -0.0002

- Fold09.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3064             nan     0.0010    0.0003
     2        1.3057             nan     0.0010    0.0003
     3        1.3050             nan     0.0010    0.0004
     4        1.3042             nan     0.0010    0.0004
     5        1.3035             nan     0.0010    0.0004
     6        1.3027             nan     0.0010    0.0004
     7        1.3020             nan     0.0010    0.0003
     8        1.3012             nan     0.0010    0.0003
     9        1.3005             nan     0.0010    0.0003
    10        1.2997             nan     0.0010    0.0003
    20        1.2924             nan     0.0010    0.0003
    40        1.2779             nan     0.0010    0.0003
    60        1.2642             nan     0.0010    0.0003
    80        1.2508             nan     0.0010    0.0003
   100        1.2379             nan     0.0010    0.0003
   120        1.2253             nan     0.0010    0.0003
   140        1.2131             nan     0.0010    0.0003
   160        1.2017             nan     0.0010    0.0003
   180        1.1901             nan     0.0010    0.0002
   200        1.1792             nan     0.0010    0.0002
   220        1.1684             nan     0.0010    0.0002
   240        1.1583             nan     0.0010    0.0002
   260        1.1482             nan     0.0010    0.0002
   280        1.1383             nan     0.0010    0.0002
   300        1.1288             nan     0.0010    0.0002

- Fold10.Rep1: shrinkage=0.001, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3061             nan     0.0010    0.0004
     2        1.3053             nan     0.0010    0.0004
     3        1.3044             nan     0.0010    0.0003
     4        1.3036             nan     0.0010    0.0004
     5        1.3028             nan     0.0010    0.0004
     6        1.3019             nan     0.0010    0.0004
     7        1.3011             nan     0.0010    0.0004
     8        1.3002             nan     0.0010    0.0004
     9        1.2993             nan     0.0010    0.0004
    10        1.2985             nan     0.0010    0.0003
    20        1.2902             nan     0.0010    0.0004
    40        1.2737             nan     0.0010    0.0004
    60        1.2576             nan     0.0010    0.0004
    80        1.2423             nan     0.0010    0.0004
   100        1.2277             nan     0.0010    0.0003
   120        1.2135             nan     0.0010    0.0003
   140        1.1995             nan     0.0010    0.0003
   160        1.1862             nan     0.0010    0.0003
   180        1.1731             nan     0.0010    0.0002
   200        1.1609             nan     0.0010    0.0003
   220        1.1487             nan     0.0010    0.0003
   240        1.1369             nan     0.0010    0.0003
   260        1.1253             nan     0.0010    0.0003
   280        1.1144             nan     0.0010    0.0002
   300        1.1038             nan     0.0010    0.0002

- Fold10.Rep1: shrinkage=0.001, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3061             nan     0.0010    0.0004
     2        1.3051             nan     0.0010    0.0004
     3        1.3041             nan     0.0010    0.0004
     4        1.3031             nan     0.0010    0.0004
     5        1.3022             nan     0.0010    0.0004
     6        1.3013             nan     0.0010    0.0004
     7        1.3003             nan     0.0010    0.0004
     8        1.2994             nan     0.0010    0.0004
     9        1.2985             nan     0.0010    0.0004
    10        1.2977             nan     0.0010    0.0004
    20        1.2885             nan     0.0010    0.0004
    40        1.2708             nan     0.0010    0.0004
    60        1.2539             nan     0.0010    0.0003
    80        1.2376             nan     0.0010    0.0003
   100        1.2217             nan     0.0010    0.0004
   120        1.2061             nan     0.0010    0.0004
   140        1.1912             nan     0.0010    0.0003
   160        1.1766             nan     0.0010    0.0003
   180        1.1624             nan     0.0010    0.0003
   200        1.1486             nan     0.0010    0.0003
   220        1.1351             nan     0.0010    0.0003
   240        1.1224             nan     0.0010    0.0002
   260        1.1103             nan     0.0010    0.0003
   280        1.0985             nan     0.0010    0.0002
   300        1.0866             nan     0.0010    0.0003

- Fold10.Rep1: shrinkage=0.001, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2996             nan     0.0100    0.0034
     2        1.2922             nan     0.0100    0.0036
     3        1.2852             nan     0.0100    0.0033
     4        1.2780             nan     0.0100    0.0032
     5        1.2706             nan     0.0100    0.0031
     6        1.2639             nan     0.0100    0.0033
     7        1.2571             nan     0.0100    0.0032
     8        1.2509             nan     0.0100    0.0031
     9        1.2442             nan     0.0100    0.0032
    10        1.2377             nan     0.0100    0.0032
    20        1.1793             nan     0.0100    0.0025
    40        1.0848             nan     0.0100    0.0018
    60        1.0153             nan     0.0100    0.0010
    80        0.9602             nan     0.0100    0.0009
   100        0.9178             nan     0.0100    0.0007
   120        0.8838             nan     0.0100    0.0006
   140        0.8571             nan     0.0100    0.0005
   160        0.8335             nan     0.0100    0.0002
   180        0.8143             nan     0.0100    0.0003
   200        0.7969             nan     0.0100    0.0002
   220        0.7819             nan     0.0100    0.0002
   240        0.7679             nan     0.0100    0.0002
   260        0.7560             nan     0.0100    0.0002
   280        0.7448             nan     0.0100    0.0001
   300        0.7336             nan     0.0100    0.0002

- Fold10.Rep1: shrinkage=0.010, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2985             nan     0.0100    0.0040
     2        1.2898             nan     0.0100    0.0035
     3        1.2808             nan     0.0100    0.0040
     4        1.2726             nan     0.0100    0.0038
     5        1.2643             nan     0.0100    0.0032
     6        1.2570             nan     0.0100    0.0034
     7        1.2495             nan     0.0100    0.0033
     8        1.2414             nan     0.0100    0.0037
     9        1.2339             nan     0.0100    0.0033
    10        1.2266             nan     0.0100    0.0032
    20        1.1609             nan     0.0100    0.0025
    40        1.0534             nan     0.0100    0.0021
    60        0.9713             nan     0.0100    0.0017
    80        0.9097             nan     0.0100    0.0011
   100        0.8597             nan     0.0100    0.0008
   120        0.8177             nan     0.0100    0.0006
   140        0.7845             nan     0.0100    0.0004
   160        0.7554             nan     0.0100    0.0002
   180        0.7297             nan     0.0100    0.0003
   200        0.7077             nan     0.0100    0.0003
   220        0.6879             nan     0.0100    0.0000
   240        0.6698             nan     0.0100    0.0002
   260        0.6525             nan     0.0100    0.0001
   280        0.6374             nan     0.0100   -0.0001
   300        0.6229             nan     0.0100   -0.0001

- Fold10.Rep1: shrinkage=0.010, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2975             nan     0.0100    0.0040
     2        1.2884             nan     0.0100    0.0042
     3        1.2786             nan     0.0100    0.0044
     4        1.2695             nan     0.0100    0.0039
     5        1.2612             nan     0.0100    0.0037
     6        1.2539             nan     0.0100    0.0033
     7        1.2456             nan     0.0100    0.0038
     8        1.2370             nan     0.0100    0.0033
     9        1.2293             nan     0.0100    0.0027
    10        1.2213             nan     0.0100    0.0035
    20        1.1477             nan     0.0100    0.0026
    40        1.0315             nan     0.0100    0.0020
    60        0.9451             nan     0.0100    0.0015
    80        0.8776             nan     0.0100    0.0010
   100        0.8228             nan     0.0100    0.0005
   120        0.7761             nan     0.0100    0.0008
   140        0.7379             nan     0.0100    0.0005
   160        0.7046             nan     0.0100    0.0002
   180        0.6745             nan     0.0100    0.0001
   200        0.6496             nan     0.0100    0.0002
   220        0.6268             nan     0.0100    0.0002
   240        0.6056             nan     0.0100    0.0001
   260        0.5867             nan     0.0100    0.0002
   280        0.5691             nan     0.0100    0.0001
   300        0.5523             nan     0.0100   -0.0002

- Fold10.Rep1: shrinkage=0.010, interaction.depth=6, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2923             nan     0.0200    0.0068
     2        1.2778             nan     0.0200    0.0063
     3        1.2626             nan     0.0200    0.0072
     4        1.2494             nan     0.0200    0.0062
     5        1.2362             nan     0.0200    0.0063
     6        1.2238             nan     0.0200    0.0056
     7        1.2127             nan     0.0200    0.0054
     8        1.2023             nan     0.0200    0.0053
     9        1.1909             nan     0.0200    0.0056
    10        1.1812             nan     0.0200    0.0049
    20        1.0889             nan     0.0200    0.0037
    40        0.9640             nan     0.0200    0.0023
    60        0.8868             nan     0.0200    0.0013
    80        0.8351             nan     0.0200    0.0008
   100        0.7974             nan     0.0200    0.0001
   120        0.7678             nan     0.0200    0.0003
   140        0.7447             nan     0.0200    0.0001
   160        0.7240             nan     0.0200    0.0002
   180        0.7077             nan     0.0200   -0.0001
   200        0.6919             nan     0.0200    0.0001
   220        0.6780             nan     0.0200   -0.0002
   240        0.6636             nan     0.0200   -0.0001
   260        0.6519             nan     0.0200    0.0002
   280        0.6402             nan     0.0200   -0.0001
   300        0.6284             nan     0.0200    0.0003

- Fold10.Rep1: shrinkage=0.020, interaction.depth=2, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2896             nan     0.0200    0.0083
     2        1.2736             nan     0.0200    0.0075
     3        1.2591             nan     0.0200    0.0065
     4        1.2441             nan     0.0200    0.0063
     5        1.2298             nan     0.0200    0.0058
     6        1.2152             nan     0.0200    0.0072
     7        1.2008             nan     0.0200    0.0066
     8        1.1867             nan     0.0200    0.0057
     9        1.1734             nan     0.0200    0.0055
    10        1.1604             nan     0.0200    0.0055
    20        1.0553             nan     0.0200    0.0034
    40        0.9083             nan     0.0200    0.0025
    60        0.8187             nan     0.0200    0.0012
    80        0.7564             nan     0.0200    0.0005
   100        0.7100             nan     0.0200    0.0002
   120        0.6702             nan     0.0200    0.0001
   140        0.6400             nan     0.0200   -0.0003
   160        0.6124             nan     0.0200    0.0003
   180        0.5876             nan     0.0200    0.0002
   200        0.5673             nan     0.0200   -0.0001
   220        0.5484             nan     0.0200   -0.0003
   240        0.5303             nan     0.0200   -0.0003
   260        0.5130             nan     0.0200   -0.0003
   280        0.4957             nan     0.0200   -0.0002
   300        0.4800             nan     0.0200   -0.0003

- Fold10.Rep1: shrinkage=0.020, interaction.depth=4, n.minobsinnode=10, n.trees=300 
+ Fold10.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2899             nan     0.0200    0.0080
     2        1.2719             nan     0.0200    0.0085
     3        1.2548             nan     0.0200    0.0070
     4        1.2368             nan     0.0200    0.0076
     5        1.2203             nan     0.0200    0.0074
     6        1.2040             nan     0.0200    0.0072
     7        1.1886             nan     0.0200    0.0067
     8        1.1747             nan     0.0200    0.0060
     9        1.1600             nan     0.0200    0.0063
    10        1.1474             nan     0.0200    0.0054
    20        1.0348             nan     0.0200    0.0037
    40        0.8768             nan     0.0200    0.0021
    60        0.7780             nan     0.0200    0.0008
    80        0.7031             nan     0.0200    0.0007
   100        0.6496             nan     0.0200    0.0004
   120        0.6051             nan     0.0200    0.0000
   140        0.5676             nan     0.0200    0.0001
   160        0.5346             nan     0.0200   -0.0001
   180        0.5053             nan     0.0200   -0.0005
   200        0.4788             nan     0.0200   -0.0001
   220        0.4544             nan     0.0200   -0.0001
   240        0.4340             nan     0.0200   -0.0003
   260        0.4128             nan     0.0200    0.0000
   280        0.3919             nan     0.0200   -0.0003
   300        0.3739             nan     0.0200   -0.0004

- Fold10.Rep1: shrinkage=0.020, interaction.depth=6, n.minobsinnode=10, n.trees=300 
Aggregating results
Selecting tuning parameters
Fitting n.trees = 300, interaction.depth = 6, shrinkage = 0.01, n.minobsinnode = 10 on full training set
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2979             nan     0.0100    0.0033
     2        1.2882             nan     0.0100    0.0042
     3        1.2799             nan     0.0100    0.0039
     4        1.2711             nan     0.0100    0.0038
     5        1.2627             nan     0.0100    0.0040
     6        1.2544             nan     0.0100    0.0037
     7        1.2459             nan     0.0100    0.0036
     8        1.2380             nan     0.0100    0.0034
     9        1.2302             nan     0.0100    0.0033
    10        1.2223             nan     0.0100    0.0033
    20        1.1497             nan     0.0100    0.0026
    40        1.0349             nan     0.0100    0.0021
    60        0.9486             nan     0.0100    0.0013
    80        0.8795             nan     0.0100    0.0010
   100        0.8234             nan     0.0100    0.0010
   120        0.7783             nan     0.0100    0.0008
   140        0.7392             nan     0.0100    0.0003
   160        0.7083             nan     0.0100    0.0004
   180        0.6798             nan     0.0100    0.0001
   200        0.6553             nan     0.0100    0.0002
   220        0.6343             nan     0.0100    0.0003
   240        0.6126             nan     0.0100    0.0002
   260        0.5933             nan     0.0100    0.0001
   280        0.5765             nan     0.0100    0.0002
   300        0.5607             nan     0.0100   -0.0002

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[302]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">sgb_pred4</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sgb4</span><span class="p">,</span><span class="n">test4</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="n">sgb_error4</span> <span class="o">&lt;-</span> <span class="nf">roc</span><span class="p">(</span><span class="n">test4</span><span class="o">$</span><span class="n">Label</span><span class="p">,</span><span class="n">sgb_pred4</span><span class="p">[,</span><span class="m">1</span><span class="p">])</span><span class="o">$</span><span class="n">auc</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Setting levels: control = objective, case = subjective
Setting direction: controls &gt; cases
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[303]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span><span class="n">AUC_Value</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">lasso_error4</span><span class="p">,</span> <span class="n">dt_error4.1</span><span class="p">,</span> <span class="n">dt_error4.2</span><span class="p">,</span> <span class="n">dt_error4.3</span><span class="p">,</span> <span class="n">rf_error4</span><span class="p">,</span> <span class="n">sgb_error4</span><span class="p">)</span>

<span class="n">table4</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span><span class="n">AUC_Value</span><span class="p">)</span>
<span class="n">table4</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<table>
<thead><tr><th scope=col>Model</th><th scope=col>AUC_Value</th></tr></thead>
<tbody>
	<tr><td>Lasso Reg        </td><td>0.8423496        </td></tr>
	<tr><td>Decision Tree 1  </td><td>0.7628841        </td></tr>
	<tr><td>Decision Tree 2  </td><td>0.7751280        </td></tr>
	<tr><td>Decision Tree 3  </td><td>0.7751280        </td></tr>
	<tr><td>Random Forest    </td><td>0.8540333        </td></tr>
	<tr><td>Gradient Boosting</td><td>0.8597151        </td></tr>
</tbody>
</table>

</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Since AUC has the highest value for gradient boosting model, it is the best option for data set 4 according to this metric.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-r"><pre><span></span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>







</html>
